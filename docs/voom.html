<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2020-06-22 Mon 19:09 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>An improved voom transform for scRNA-seq data</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="bootstrap.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="htmlize.css"/>
<link rel="stylesheet" type="text/css" href="main.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">An improved voom transform for scRNA-seq data</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orga658581">Introduction</a></li>
<li><a href="#setup">Setup</a></li>
<li><a href="#org3e4ab9d">Methods</a>
<ul>
<li><a href="#org8a4c1a0">Standard error of point mass expression model</a></li>
<li><a href="#org618f456">Variance of Gamma expression model</a></li>
<li><a href="#orgdaf9c29">Controlling FDR</a></li>
<li><a href="#orgc7d2b9a">Simulation</a></li>
</ul>
</li>
<li><a href="#org9652fb0">Results</a>
<ul>
<li><a href="#orga144bdf">Accuracy of estimation</a></li>
<li><a href="#org1638472">Estimation of true effect size distribution</a></li>
<li><a href="#org05839be">Type 1 error rate (single cells as units)</a></li>
<li><a href="#org6fff017">Power (single cells as units)</a></li>
<li><a href="#org3aa1007">Type 1 error rate (donors as units)</a></li>
<li><a href="#org9c356fb">Power (donors as units)</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orga658581" class="outline-2">
<h2 id="orga658581">Introduction</h2>
<div class="outline-text-2" id="text-orga658581">
<p>
The key idea of limma-voom (Law et al. 2014) is to transform a count matrix
generated by bulk RNA-seq into two matrices, representing the mean and
variance of true (log) gene expression. These matrices can then be analyzed
using (heteroscedastic) Gaussian methods. However, limma-voom was developed
before the development of scRNA-seq, and therefore before it was possible to
measure the variance of gene expression between cells from a single donor. To
address this limitation, Law et al. instead proposed to pool information
across both donors and genes, estimating a LOESS trend between the mean and
variance of true gene expression values across donors. \(
  \DeclareMathOperator\E{E}
  \DeclareMathOperator\Gam{Gamma}
  \DeclareMathOperator\Poi{Poisson}
  \DeclareMathOperator\V{V}
  \DeclareMathOperator\digamma{\psi}
  \DeclareMathOperator\trigamma{\psi^{(1)}}
  \newcommand\vb{\mathbf{b}}
  \newcommand\vc{\mathbf{c}}
  \newcommand\xiplus{x_{i+}}
  \)
</p>

<p>
Now suppose we have observed scRNA-seq data \(x_{ij}\), where \(x_{ij}\)
denotes the number of molecules from gene \(j\) observed in cell \(i\). Then,
there are two possible DE analysis we might be interested in. First, we might
divide (some subset of) cells into two groups, and ask whether genes are
differentially expressed between groups. Second, we might divide donors into
groups, and test whether genes (in some subset of cells, per donor) are
differentially expressed between groups. The key distinction is that single
cells are the units in the first case, and donors are the units in the second
case.
</p>

<p>
We can apply limma-voom without modification to the first case, because the
typical log transformation corresponds to an MLE
</p>

\begin{align}
  x_{ij} \mid \xiplus, \theta_{ij} &\sim \Poi(\xiplus \exp(\theta_{ij}))\\
  \ell \triangleq \ln p(x_{ij} \mid \xiplus, \theta_{ij}) &= x_{ij} (\ln \xiplus + \theta_{ij}) - \xiplus \exp(\theta_{ij}) + \mathrm{const}\\
  \frac{\partial \ell}{\partial \theta_{ij}} &= x_{ij} - \xiplus \exp(\theta_{ij})\\
  \hat\theta_{ij} &= \ln\left(\frac{x_{ij}}{\xiplus}\right).
\end{align}

<p>
This simple theoretical argument and empirical studies have demonstrated that
applying limma-voom to scRNA-seq data can work (Soneson and Robinson 2018,
Hsiao 2019). However, unlike the bulk RNA-seq case, now the notion of
&ldquo;variance of gene expression&rdquo; within a single unit no longer makes
sense. Therefore, it is unclear what precisely limma-voom is fitting in this
case.
</p>

<p>
Applying limma-voom to the second case also works, because we can estimate a
point mass expression model for the cells from each donor \(k\)
</p>

\begin{align}
  x_{ij} \mid \xiplus, \theta_j &\sim \Poi(\xiplus \exp(\theta_j))\\
  \ell \triangleq \sum_i \ln p(x_{ij} \mid \xiplus, \theta_j) &= \sum_i x_{ij} (\ln \xiplus + \theta_j) - \xiplus \exp(\theta_j) + \mathrm{const}\\
  \frac{\partial \ell}{\partial \theta_j} &= \sum_i x_{ij} - \xiplus \exp(\theta_j)\\
  \theta_j &= \ln\left(\frac{\sum_i x_{ij}}{\sum_i \xiplus}\right)\\
\end{align}

<p>
where \(\xiplus \triangleq \sum_j x_{ij}\) (Sarkar and Stephens 2020). This
approach is equivalent to constructing pseudobulk data \(y_{kj} \triangleq
  \sum_i x_{ij} z_{ik}\), where \(z_{ik}\) indicates whether cell \(i\) came
from donor \(k\), and using \(\ln(y_{kj} / y_{k+})\) as the estimated mean of
true log gene expression, where \(y_{k+} \triangleq \sum_j y_{kj}\). However,
the relationship between the voom-estimated variance and the true gene
expression variance is unclear because the variance used by voom is between
individuals, not within an individual (although there is
<a href="mpebpm.html#org677b3e2">some
evidence that the two are highly correlated</a>). Further, it is unlikely that
a point mass expression model will be supported by the data.
</p>

<p>
We previously developed a method to efficiently estimate more complex
expression models in large-scale scRNA-seq data sets (Sarkar et
al. 2019). Here, we use that method to investigate two new possibilities for
a precision weight derived from fitted expression models: (1) the inverse
squared standard error of a point mass model, or (2) the inverse variance of
the log true expression under a Gamma model. Specifically, we ask whether
these alterantive approaches improve the power or robustness of DE analysis
in scRNA-seq data.
</p>
</div>
</div>

<div id="outline-container-org3b4cae3" class="outline-2">
<h2 id="setup"><a id="org3b4cae3"></a>Setup</h2>
<div class="outline-text-2" id="text-setup">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> anndata
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> mpebpm
<span class="org-keyword">import</span> pandas <span class="org-keyword">as</span> pd
<span class="org-keyword">import</span> scanpy <span class="org-keyword">as</span> sc
<span class="org-keyword">import</span> rpy2.robjects.packages
<span class="org-keyword">import</span> rpy2.robjects.pandas2ri
<span class="org-keyword">import</span> scipy.special <span class="org-keyword">as</span> sp
<span class="org-keyword">import</span> scipy.sparse <span class="org-keyword">as</span> ss
<span class="org-keyword">import</span> scipy.stats <span class="org-keyword">as</span> st
<span class="org-keyword">import</span> sqlite3
<span class="org-keyword">import</span> scqtl

<span class="org-variable-name">ashr</span> = rpy2.robjects.packages.importr(<span class="org-string">'ashr'</span>)
<span class="org-variable-name">limma</span> = rpy2.robjects.packages.importr(<span class="org-string">'limma'</span>)
rpy2.robjects.pandas2ri.activate()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%matplotlib inline
%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'retina'</span>])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'figure.facecolor'</span>] = <span class="org-string">'w'</span>
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'font.family'</span>] = <span class="org-string">'Nimbus Sans'</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org3e4ab9d" class="outline-2">
<h2 id="org3e4ab9d">Methods</h2>
<div class="outline-text-2" id="text-org3e4ab9d">
</div>
<div id="outline-container-org8a4c1a0" class="outline-3">
<h3 id="org8a4c1a0">Standard error of point mass expression model</h3>
<div class="outline-text-3" id="text-org8a4c1a0">
<p>
The standard error of \(\hat\theta_j\) is analytic
</p>

\begin{align}
  \frac{\partial^2 \ell}{\partial \theta_j^2} &= -\sum_i \xiplus \exp(\theta_j)\\
  \mathcal{I}(\mu_j) &= -\E\left[\frac{\partial^2 \ell}{\partial \mu_j^2}\right] = \sum_i \xiplus \exp(\theta_j)\\
  s_j^2 &= \frac{1}{\sum_i \xiplus \exp(\theta_j)},
\end{align}

<p>
where we have treated \(\xiplus\) as fixed. This treatment is justified by
the fact that the Poisson measurement model for each gene arises from a
Multinomial measurement model for all genes jointly, in which the total
number of molecules observed is fixed rather than a sum of random
variables. As an illustrative example, plot the bootstrap distribution of the
\(\hat\theta_j\) against a normal density with mean \(\theta_j\) and variance
\(s_j^2\) for a simple simulation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">rng</span> = np.random.default_rng(1)
<span class="org-variable-name">n_trials</span> = 1000
<span class="org-variable-name">n</span> = 100
<span class="org-variable-name">s</span> = 1e4
<span class="org-variable-name">theta</span> = -10
<span class="org-variable-name">thetahat</span> = []
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
  <span class="org-variable-name">x</span> = rng.poisson(s * np.exp(theta), size=n)
  thetahat.append(np.log(x.<span class="org-builtin">sum</span>()) - np.log(n) - np.log(s))
<span class="org-variable-name">thetahat</span> = np.array(thetahat)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.hist(thetahat, bins=16, density=<span class="org-constant">True</span>, color=<span class="org-string">'0.7'</span>)
<span class="org-variable-name">grid</span> = np.linspace(thetahat.<span class="org-builtin">min</span>(), thetahat.<span class="org-builtin">max</span>(), 1000)
plt.plot(grid, st.norm(loc=theta, scale=np.sqrt(1 / (np.exp(theta) * n * s))).pdf(grid), lw=1, c=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'Est ln mean gene expression'</span>)
plt.ylabel(<span class="org-string">'Density'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/analytic-se-log-link.png" alt="analytic-se-log-link.png">
</p>
</div>

<p>
After introducing multiplicative effects \(\vb_j\) for observed technical
covariates \(\vc_i\) into the measurement model
</p>

\begin{equation}
  x_{ij} \mid \xiplus, \vc_i, \vb_j, \theta_j \sim \Poi(\xiplus \exp(\vc_i' \vb_j + \theta_j)),
\end{equation}

<p>
the standard error of \(\hat\theta_j\) also depends on \(\vc_i'\vb_j\). In
contrast, if we assume the identity link
</p>

\begin{align}
  x_{ij} \mid \xiplus, \mu_j &\sim \Poi(\xiplus \mu_j)\\
  \ell \triangleq \sum_i \ln p(x_{ij} \mid \xiplus, \mu_j) &= \sum_i x_{ij} \ln(\xiplus \mu_j) - \xiplus \mu_j + \mathrm{const}\\
  \frac{\partial \ell}{\partial \mu_j} &= \sum_i \frac{x_{ij}}{\mu_j} - \xiplus\\
  \hat\mu_j &= \frac{\sum_i x_{ij}}{\sum_i \xiplus}\\
  \frac{\partial^2 \ell}{\partial \mu_j^2} &= -\sum_i \frac{x_{ij}}{\mu_j^2}\\
  \mathcal{I}(\mu_j) &= -\E\left[\frac{\partial^2 \ell}{\partial \mu_j^2}\right] = \frac{\E[\sum_i x_{ij}]}{\mu_j^2} = \frac{\sum_i \xiplus}{\mu_j}\\
  s_j^2 &= \frac{\mu_j}{\sum_i \xiplus},
\end{align}

<p>
where we have used the fact that \(\sum_i x_{ij} \sim \Poi(\mu_j \sum_i
   \xiplus)\). Surprisingly, \(\ln \hat\mu_j = \hat\theta_j\), the standard
error of \(\hat\mu_j\) increases as \(\mu_j\) increases, and the standard
error does not depend on technical covariates or their effects. As a sanity
check, plot the bootstrap distribution of \(\hat\mu_j\) against a normal
density with mean \(\theta_j\) and variance \(s_j^2\) for a simple
simulation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">rng</span> = np.random.default_rng(2)
<span class="org-variable-name">n_trials</span> = 500
<span class="org-variable-name">n</span> = 100
<span class="org-variable-name">s</span> = 1e4
<span class="org-variable-name">log_mu</span> = -10
<span class="org-variable-name">muhat</span> = []
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
  <span class="org-variable-name">x</span> = rng.poisson(s * np.exp(log_mu), size=n)
  muhat.append(x.<span class="org-builtin">sum</span>() / (n * s))
<span class="org-variable-name">muhat</span> = np.array(muhat)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.hist(muhat, bins=14, density=<span class="org-constant">True</span>, color=<span class="org-string">'0.7'</span>)
<span class="org-variable-name">grid</span> = np.linspace(muhat.<span class="org-builtin">min</span>(), muhat.<span class="org-builtin">max</span>(), 1000)
plt.plot(grid, st.norm(loc=muhat.mean(), scale=np.sqrt(muhat[0] / (n * s))).pdf(grid), lw=1, c=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'Est mean gene expression'</span>)
plt.ylabel(<span class="org-string">'Density'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/analytic-se-identity-link.png" alt="analytic-se-identity-link.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org618f456" class="outline-3">
<h3 id="org618f456">Variance of Gamma expression model</h3>
<div class="outline-text-3" id="text-org618f456">
<p>
Assuming a Gamma expression model
</p>

\begin{align}
  \lambda_{ij} &\sim \Gam(\phi_j^{-1}, \mu_j^{-1} \phi_j^{-1})\\
  \E[\ln \lambda_{ij}] &= \digamma(\phi_j^{-1}) + \ln(\mu_j \phi_j)\\
  \V[\ln \lambda_{ij}] &= \trigamma(\phi_j^{-1}),
\end{align}

<p>
where the Gamma distribution is parameterized by shape and rate,
\(\digamma(\cdot)\) denotes the digamma function, and \(\trigamma(\cdot)\)
denotes the trigamma function. We previously noted that robustly estimating
\(\phi_j\) is difficult, even from hundreds of cells per condition; despite
this difficulty, our method can still accurately estimate the variance of
true gene expression.
</p>
</div>
</div>

<div id="outline-container-orgdaf9c29" class="outline-3">
<h3 id="orgdaf9c29">Controlling FDR</h3>
<div class="outline-text-3" id="text-orgdaf9c29">
<p>
Given transformed data and standard errors, DE analysis is performed in two
steps:
</p>

<ol class="org-ol">
<li>Estimate the effect of the covariate of interest by GLS</li>
<li>Estimate moderated test statistics and \(p\)-values by EB treatment of
the standard errors from (1)</li>
<li>Control FDR by applying e.g., the BH procedure to the \(p\)-values from
(2)</li>
</ol>

<p>
<a href="https://arxiv.org/abs/1901.10679">Lu and Stephens 2019</a> describe a more
powerful approach to solve (3).
</p>
</div>
</div>

<div id="outline-container-orgc7d2b9a" class="outline-3">
<h3 id="orgc7d2b9a">Simulation</h3>
<div class="outline-text-3" id="text-orgc7d2b9a">
<p>
Implement a simplified
<a href="https://stephenslab.github.io/dsc-log-fold-change">DSC</a>.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org1888ed1"><span class="org-keyword">def</span> <span class="org-function-name">simulate_null</span>(dat, n_donors=2, n_cells=100, to_array=<span class="org-constant">True</span>, to_dense=<span class="org-constant">False</span>, min_counts=1, seed=0):
  <span class="org-doc">"""Return counts and labels</span>

<span class="org-doc">  counts - matrix [n_donors * n_cells, n_genes]</span>
<span class="org-doc">  labels - CSR matrix [n_donors * n_cells, n_donors]</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">query</span> = sc.pp.subsample(dat, n_obs=n_donors * n_cells, random_state=seed, copy=<span class="org-constant">True</span>)
  sc.pp.filter_genes(query, min_counts=min_counts)
  <span class="org-keyword">if</span> <span class="org-keyword">not</span> ss.isspmatrix_csr(query.X):
    <span class="org-variable-name">query.X</span> = query.X.tocsr()
  <span class="org-variable-name">onehot</span> = ss.coo_matrix((np.ones(query.shape[0]), (np.arange(query.shape[0]), np.repeat(np.arange(n_donors), n_cells)))).tocsr()
  <span class="org-keyword">if</span> <span class="org-keyword">not</span> to_array:
    <span class="org-keyword">return</span> query, onehot
  <span class="org-keyword">elif</span> to_dense:
    <span class="org-keyword">return</span> query.X.A, onehot.A
  <span class="org-keyword">else</span>:
    <span class="org-keyword">return</span> query.X, onehot

<span class="org-keyword">def</span> <span class="org-function-name">estimate_limma_voom</span>(x, onehot, design=<span class="org-constant">None</span>, **kwargs):
  <span class="org-doc">"""Return DataFrame of bhat, se"""</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: limma expects genes x samples</span>
  <span class="org-keyword">if</span> design <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">design</span> = np.vstack([onehot[:,0], np.ones(x.shape[0])]).T
    <span class="org-variable-name">y</span> = limma.voom(x.T, design)
  <span class="org-keyword">else</span>:
    <span class="org-variable-name">y</span> = limma.voom(x.T @ onehot, design)
  <span class="org-variable-name">fit</span> = limma.lmFit(y, design)
  <span class="org-keyword">return</span> fit

<span class="org-keyword">def</span> <span class="org-function-name">estimate_wls_point</span>(x, onehot, design=<span class="org-constant">None</span>, **kwargs):
  <span class="org-doc">"""Return DataFrame of bhat, se</span>

<span class="org-doc">  Instead of voom, estimate &#952;_j = log &#956;_j under a point mass expression model</span>
<span class="org-doc">  and its sampling variance, and use those as input to WLS.</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">s</span> = x.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
  <span class="org-keyword">if</span> design <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">log_mean</span> = np.log(x + 1) - np.log(s)
    <span class="org-comment-delimiter"># </span><span class="org-comment">Important: this only reduces when there are no techncial covariates in</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">the measurement model</span>
    <span class="org-variable-name">w</span> = x + 1
    <span class="org-variable-name">design</span> = np.vstack([onehot[:,0], np.ones(x.shape[0])]).T
  <span class="org-keyword">else</span>:
    <span class="org-variable-name">log_mean</span> = np.log(onehot.T @ x + 1) - np.log(onehot.T @ s)
    <span class="org-variable-name">w</span> = onehot.T @ x + 1
  <span class="org-variable-name">fit</span> = limma.lm_series(log_mean.T, design=design, weights=w.T)
  <span class="org-keyword">return</span> fit

<span class="org-keyword">def</span> <span class="org-function-name">estimate_wls_gamma</span>(x, onehot, design, lr=1e-2, num_epochs=40, batch_size=64, shuffle=<span class="org-constant">True</span>, log_dir=<span class="org-constant">None</span>, **kwargs):
  <span class="org-doc">"""Return DataFrame of bhat, se</span>

<span class="org-doc">  Instead of voom, estimate E[log &#955;_{ij}] and V[log &#955;_{ij}] under a Gamma</span>
<span class="org-doc">  model, and use those as input to WLS.</span>

<span class="org-doc">  Important: this only makes sense when donors are units</span>

<span class="org-doc">  """</span>
  <span class="org-keyword">import</span> torch
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: this will be too slow on CPU</span>
  <span class="org-keyword">assert</span> torch.cuda.is_available()
  <span class="org-variable-name">s</span> = x.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
  <span class="org-variable-name">log_mean</span>, <span class="org-variable-name">log_inv_disp</span> = mpebpm.ebpm_gamma(
    x,
    s=s,
    onehot=onehot,
    lr=lr,
    num_epochs=num_epochs,
    batch_size=batch_size,
    shuffle=shuffle,
    log_dir=log_dir)
  <span class="org-comment-delimiter"># </span><span class="org-comment">[n_donors, n_genes]</span>
  <span class="org-variable-name">m</span> = sp.digamma(np.exp(log_inv_disp)) + log_mean - log_inv_disp
  <span class="org-variable-name">w</span> = 1 / sp.polygamma(1, np.exp(log_inv_disp))
  <span class="org-variable-name">fit</span> = limma.lm_series(m.T, design=design, weights=w.T)
  <span class="org-keyword">return</span> fit

<span class="org-keyword">def</span> <span class="org-function-name">estimate_moderated_t</span>(fit):
  <span class="org-variable-name">fit</span> = limma.eBayes(fit)
  <span class="org-keyword">return</span> fit.rx2(<span class="org-string">'p.value'</span>)[:,0]

<span class="org-keyword">def</span> <span class="org-function-name">estimate_z</span>(fit):
  <span class="org-variable-name">sf</span> = st.chi2(1).sf
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: this has estimates for the intercept also</span>
  <span class="org-variable-name">stat</span> = fit.rx2(<span class="org-string">'coefficients'</span>) / fit.rx2(<span class="org-string">'stdev.unscaled'</span>)
  <span class="org-variable-name">pval</span> = sf(np.square(stat))
  <span class="org-keyword">return</span> pval[:,0]

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_power</span>(dat, b=<span class="org-constant">None</span>, alpha=0.01, n_cells=100, n_trials=1, min_counts=10):
  <span class="org-keyword">if</span> b <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">b</span> = -np.log(1.5)
  <span class="org-keyword">elif</span> b &gt; 0:
    <span class="org-variable-name">b</span> = -b
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
    <span class="org-comment-delimiter"># </span><span class="org-comment">Important: keep this sparse to make downsampling non-zeros easier</span>
    <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span> = simulate_null(dat, n_cells=n_cells, to_dense=<span class="org-constant">False</span>, min_counts=min_counts, seed=i)
    <span class="org-variable-name">temp</span> = x[:n_cells].astype(<span class="org-builtin">int</span>)
    <span class="org-variable-name">y</span> = ss.csr_matrix((st.binom(n=temp.data, p=np.exp(b)).rvs().astype(<span class="org-builtin">float</span>), temp.indices, temp.indptr), shape=temp.shape)
    <span class="org-variable-name">x</span> = ss.vstack((y, x[n_cells:]), <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>).A
    <span class="org-variable-name">onehot</span> = onehot.A
    <span class="org-comment-delimiter"># </span><span class="org-comment">Heuristic: fix total number of updates</span>
    <span class="org-variable-name">num_epochs</span> = 6000 * 64 // x.shape[0]
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'limma_voom'</span>, <span class="org-string">'wls_point'</span>):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, batch_size=64, num_epochs=num_epochs)
      <span class="org-keyword">for</span> test <span class="org-keyword">in</span> (<span class="org-string">'moderated_t'</span>, <span class="org-string">'z'</span>):
        <span class="org-variable-name">pval</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{test}'</span>](fit)
        result.append((b, n_cells, method, test, i, (pval &lt; alpha).mean()))
  <span class="org-variable-name">result</span> = pd.DataFrame(result, columns=[<span class="org-string">'b'</span>, <span class="org-string">'n_cells'</span>, <span class="org-string">'method'</span>, <span class="org-string">'test'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'tpr'</span>])
  <span class="org-keyword">return</span> result

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_type1</span>(dat, alpha=0.01, n_cells=100, n_trials=1, min_counts=10):
  <span class="org-variable-name">result</span> = (evaluate_power(dat, b=0, alpha=alpha, n_cells=n_cells, n_trials=n_trials, min_counts=min_counts)
            .rename({<span class="org-string">'tpr'</span>: <span class="org-string">'fpr'</span>}, axis=1))
  <span class="org-keyword">return</span> result

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_power_by_donor</span>(dat, b=<span class="org-constant">None</span>, alpha=0.01, n_donors=4, n_cells=100, n_trials=1, min_counts=10):
  <span class="org-keyword">assert</span> n_donors * n_cells &lt;= dat.shape[0]
  <span class="org-keyword">if</span> b <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">b</span> = -np.log(1.5)
  <span class="org-keyword">elif</span> b &gt; 0:
    <span class="org-variable-name">b</span> = -b
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
    <span class="org-comment-delimiter"># </span><span class="org-comment">Important: keep this sparse to make downsampling non-zeros easier</span>
    <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span> = simulate_null(dat, n_donors=2 * n_donors, n_cells=n_cells, to_dense=<span class="org-constant">False</span>, min_counts=min_counts, seed=i)
    <span class="org-variable-name">temp</span> = x[:n_donors * n_cells].astype(<span class="org-builtin">int</span>)
    <span class="org-variable-name">y</span> = ss.csr_matrix((st.binom(n=temp.data, p=np.exp(b)).rvs().astype(<span class="org-builtin">float</span>), temp.indices, temp.indptr), shape=temp.shape)
    <span class="org-variable-name">x</span> = ss.vstack((y, x[n_donors * n_cells:]), <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>).A
    <span class="org-variable-name">design</span> = np.ones((2 * n_donors, 2))
    <span class="org-variable-name">design</span>[:n_donors,0] = 0
    <span class="org-comment-delimiter"># </span><span class="org-comment">Heuristic: fix total number of updates</span>
    <span class="org-variable-name">num_epochs</span> = 6000 * 64 // x.shape[0]
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'limma_voom'</span>, <span class="org-string">'wls_point'</span>):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, design=design, batch_size=64, num_epochs=num_epochs)
      <span class="org-keyword">for</span> test <span class="org-keyword">in</span> (<span class="org-string">'moderated_t'</span>, <span class="org-string">'z'</span>):
        <span class="org-variable-name">pval</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{test}'</span>](fit)
        result.append((b, n_cells, method, test, i, (pval &lt; alpha).mean()))
  <span class="org-variable-name">result</span> = pd.DataFrame(result, columns=[<span class="org-string">'b'</span>, <span class="org-string">'n_cells'</span>, <span class="org-string">'method'</span>, <span class="org-string">'test'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'tpr'</span>])
  <span class="org-keyword">return</span> result

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_type1_by_donor</span>(dat, alpha=0.01, n_trials=1, n_donors=4, n_cells=100, min_counts=10):
  <span class="org-variable-name">result</span> = (evaluate_power_by_donor(dat, b=0, alpha=alpha, n_trials=n_trials, n_donors=n_donors, min_counts=min_counts)
            .rename({<span class="org-string">'tpr'</span>: <span class="org-string">'fpr'</span>}, axis=1))
  <span class="org-keyword">return</span> result

<span class="org-keyword">def</span> <span class="org-function-name">estimate_lfsr</span>(fit):
  <span class="org-variable-name">fit1</span> = ashr.ash(
    betahat=pd.Series(fit.rx2(<span class="org-string">'coefficients'</span>)[:,0]),
    sebetahat=pd.Series(np.sqrt(((fit.rx2(<span class="org-string">'df.total'</span>) - fit.rx2(<span class="org-string">'df.residual'</span>)) * fit.rx2(<span class="org-string">'s2.prior'</span>) + fit.rx2(<span class="org-string">'df.residual'</span>) * fit.rx2(<span class="org-string">'stdev.unscaled'</span>)[:,0]) / fit.rx2(<span class="org-string">'df.total'</span>))),
    df=fit.rx2(<span class="org-string">'df.total'</span>)[0],
    mixcompdist=<span class="org-string">'halfuniform'</span>)
  <span class="org-keyword">return</span> ashr.get_lfsr(fit1)

<span class="org-keyword">def</span> <span class="org-function-name">estimate_fdr_bh</span>(fit):
  <span class="org-keyword">return</span> rpy2.robjects.r[<span class="org-string">'p.adjust'</span>](fit.rx2(<span class="org-string">'p.value'</span>)[:,0], method=<span class="org-string">'BH'</span>)

<span class="org-keyword">def</span> <span class="org-function-name">simulate_study_by_donor</span>(dat, pi0=0.9, n_donors=4, n_cells=100, min_counts=10, seed=0):
  <span class="org-keyword">assert</span> n_donors * n_cells &lt;= dat.shape[0]
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: keep this sparse to make downsampling non-zeros easier</span>
  <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span> = simulate_null(dat, n_donors=2 * n_donors, n_cells=n_cells, to_dense=<span class="org-constant">False</span>, min_counts=min_counts, seed=seed)
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: taken from real data</span>
  <span class="org-variable-name">g</span> = st.t(scale=0.1, df=2.5)
  <span class="org-comment-delimiter"># </span><span class="org-comment">Simulate effects symmetrically about zero, then convert to negative</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">effects in the appropriate group</span>
  <span class="org-variable-name">b</span> = np.zeros(x.shape[1])
  <span class="org-variable-name">effect</span> = np.random.uniform(size=x.shape[1]) &gt; pi0
  <span class="org-variable-name">b</span>[effect] = g.rvs(size=effect.<span class="org-builtin">sum</span>())
  <span class="org-comment-delimiter"># </span><span class="org-comment">Convert to CSC to deal with half the cells at a time</span>
  <span class="org-variable-name">y</span> = x.tocsc()
  <span class="org-variable-name">data</span> = y.data.copy()
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(y.shape[0]):
    <span class="org-keyword">if</span> b[i] &gt; 0:
      <span class="org-variable-name">idx</span> = y.indptr[i] + np.where(y.indices[y.indptr[i]:y.indptr[i+1]] &gt; n_donors * n_cells)[0]
      <span class="org-variable-name">data</span>[idx] = st.binom(n=y.data[idx].astype(<span class="org-builtin">int</span>), p=np.exp(-b[i])).rvs(size=<span class="org-builtin">len</span>(idx)).astype(<span class="org-builtin">float</span>)
    <span class="org-keyword">elif</span> b[i] &lt; 0:
      <span class="org-variable-name">idx</span> = y.indptr[i] + np.where(y.indices[y.indptr[i]:y.indptr[i+1]] &lt; n_donors * n_cells)[0]
      <span class="org-variable-name">data</span>[idx] = st.binom(n=y.data[idx].astype(<span class="org-builtin">int</span>), p=np.exp(b[i])).rvs(size=<span class="org-builtin">len</span>(idx)).astype(<span class="org-builtin">float</span>)
  <span class="org-variable-name">design</span> = np.ones((2 * n_donors, 2))
  <span class="org-variable-name">design</span>[:n_donors,0] = 0
  <span class="org-keyword">return</span> ss.csc_matrix((data, y.indices, y.indptr)).A, onehot, design, b

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_power_by_donor_fdr</span>(dat, pi0=0.9, fdr=0.1, n_trials=1, n_donors=4, n_cells=100, min_counts=10):
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
    <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span>, <span class="org-variable-name">design</span>, <span class="org-variable-name">b</span> = simulate_study_by_donor(dat, pi0=pi0, n_donors=n_donors, n_cells=n_cells, min_counts=min_counts, seed=i)
    <span class="org-comment-delimiter"># </span><span class="org-comment">Heuristic: fix total number of updates</span>
    <span class="org-variable-name">num_epochs</span> = 6000 * 64 // x.shape[0]
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'limma_voom'</span>, <span class="org-string">'wls_point'</span>):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, design=design, batch_size=64, num_epochs=num_epochs)
      <span class="org-comment-delimiter"># </span><span class="org-comment">Important: always use moderated t test</span>
      <span class="org-variable-name">fit</span> = limma.eBayes(fit)
      <span class="org-keyword">for</span> fdr_method <span class="org-keyword">in</span> (<span class="org-string">'fdr_bh'</span>, <span class="org-string">'lfsr'</span>):
        <span class="org-variable-name">score</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{fdr_method}'</span>](fit)
        <span class="org-variable-name">fdp</span> = ((score &lt; fdr) &amp; np.isclose(b, 0)).mean()
        <span class="org-variable-name">power</span> = ((score &lt; fdr) &amp; ~np.isclose(b, 0)).mean()
        result.append((pi0, fdr, n_donors, n_cells, method, fdr_method, i, fdp, power))
  <span class="org-variable-name">result</span> = pd.DataFrame(result, columns=[<span class="org-string">'pi0'</span>, <span class="org-string">'fdr'</span>, <span class="org-string">'n_donors'</span>, <span class="org-string">'n_cells'</span>, <span class="org-string">'method'</span>, <span class="org-string">'fdr_method'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'fdp'</span>, <span class="org-string">'power'</span>])
  <span class="org-keyword">return</span> result
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org9652fb0" class="outline-2">
<h2 id="org9652fb0">Results</h2>
<div class="outline-text-2" id="text-org9652fb0">
</div>
<div id="outline-container-orga144bdf" class="outline-3">
<h3 id="orga144bdf">Accuracy of estimation</h3>
<div class="outline-text-3" id="text-orga144bdf">
<p>
We previously evaluated <code>mpebpm</code> <a href="mpebpm.html#accuracy">by simulating
from a point-Gamma expression model</a>. Now, simulate from a Gamma model, and
evaluate the accuracy of estimating \(\E[\ln\lambda_{ij}]\) and
\(\V[\ln\lambda_{ij}]\).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">evaluate</span>(num_samples, num_mols, num_trials=10, **kwargs):
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: generate all of the samples for each trial in one shot, and use</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">one-hot encoding to get separate estimates</span>
  <span class="org-variable-name">args</span> = [(num_samples * num_trials, num_mols, log_mu, log_phi, -1000, <span class="org-constant">None</span>, <span class="org-constant">None</span>, <span class="org-constant">None</span>)
          <span class="org-keyword">for</span> log_mu <span class="org-keyword">in</span> np.linspace(-12, -6, 7)
          <span class="org-keyword">for</span> log_phi <span class="org-keyword">in</span> np.linspace(-4, 0, 5)]
  <span class="org-variable-name">x</span> = np.concatenate([scqtl.simulation.simulate(*a)[0][:,:1] <span class="org-keyword">for</span> a <span class="org-keyword">in</span> args], axis=1)
  <span class="org-variable-name">x</span> = ss.csr_matrix(x)
  <span class="org-variable-name">s</span> = num_mols * np.ones((x.shape[0], 1))
  <span class="org-variable-name">onehot</span> = np.zeros((num_samples * num_trials, num_trials))
  onehot[np.arange(onehot.shape[0]), np.arange(onehot.shape[0]) // num_samples] = 1
  <span class="org-variable-name">onehot</span> = ss.csr_matrix(onehot)

  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: this is analytic</span>
  <span class="org-variable-name">theta</span> = mpebpm.sgd.ebpm_point(x.A, s=s, onehot=onehot.A)
  <span class="org-variable-name">log_mu</span>, <span class="org-variable-name">neg_log_phi</span> = mpebpm.sgd.ebpm_gamma(x, s=s, onehot=onehot, **kwargs)
  <span class="org-variable-name">result</span> = pd.DataFrame(
    [(a[0] // num_trials, <span class="org-builtin">int</span>(a[1]), <span class="org-builtin">int</span>(a[2]), <span class="org-builtin">int</span>(a[3]), <span class="org-builtin">int</span>(a[4]), a[-1], trial)
     <span class="org-keyword">for</span> a <span class="org-keyword">in</span> args
     <span class="org-keyword">for</span> trial <span class="org-keyword">in</span> <span class="org-builtin">range</span>(num_trials)],
    columns=[<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>, <span class="org-string">'log_mu'</span>, <span class="org-string">'log_phi'</span>, <span class="org-string">'logodds'</span>, <span class="org-string">'fold'</span>, <span class="org-string">'trial'</span>])
  <span class="org-variable-name">result</span>[<span class="org-string">'theta_hat'</span>] = theta.ravel(order=<span class="org-string">'F'</span>)
  <span class="org-variable-name">result</span>[<span class="org-string">'log_mu_hat'</span>] = log_mu.ravel(order=<span class="org-string">'F'</span>)
  <span class="org-variable-name">result</span>[<span class="org-string">'log_phi_hat'</span>] = -neg_log_phi.ravel(order=<span class="org-string">'F'</span>)
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: sign flipped in scqtl.simulation.simulate</span>
  <span class="org-variable-name">result</span>[<span class="org-string">'mean_log'</span>] = sp.digamma(np.exp(-query[<span class="org-string">'log_phi'</span>])) + query[<span class="org-string">'log_mu'</span>] + query[<span class="org-string">'log_phi'</span>]
  <span class="org-variable-name">result</span>[<span class="org-string">'var_log'</span>] = sp.polygamma(1, np.exp(-result[<span class="org-string">'log_phi'</span>]))
  <span class="org-variable-name">result</span>[<span class="org-string">'mean_log_hat'</span>] = sp.digamma(np.exp(-result[<span class="org-string">'log_phi_hat'</span>])) + result[<span class="org-string">'log_mu_hat'</span>] + result[<span class="org-string">'log_phi_hat'</span>]
  <span class="org-variable-name">result</span>[<span class="org-string">'var_log_hat'</span>] = sp.polygamma(1, np.exp(-result[<span class="org-string">'log_phi_hat'</span>]))
  <span class="org-keyword">return</span> result
</pre>
</div>

<p>
Run the simulation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = [evaluate(num_samples=num_samples,
                   num_mols=num_mols,
                   batch_size=32,
                   num_epochs=num_epochs,
                   log_dir=f<span class="org-string">'runs/mpebpm/gamma-sim-{num_mols}-{num_samples}/'</span>)
          <span class="org-keyword">for</span> num_mols <span class="org-keyword">in</span> (10000, 100000)
          <span class="org-comment-delimiter"># </span><span class="org-comment">Important: for fixed batch size, having more samples means more</span>
          <span class="org-comment-delimiter"># </span><span class="org-comment">updates to each parameter per epoch</span>
          <span class="org-keyword">for</span> num_samples, num_epochs <span class="org-keyword">in</span> <span class="org-builtin">zip</span>((100, 1000), (400, 40))]
pd.concat(result).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/ideas/mpebpm-gamma-sim.txt.gz'</span>, sep=<span class="org-string">'\t'</span>)
</pre>
</div>

<p>
Read the results.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = pd.read_csv(<span class="org-string">'/scratch/midway2/aksarkar/ideas/mpebpm-gamma-sim.txt.gz'</span>, sep=<span class="org-string">'\t'</span>, index_col=0)
</pre>
</div>

<p>
Compare the estimated \(\E[\ln\lambda_{ij}]\) to the ground truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4.5, 4.5)
<span class="org-variable-name">lim</span> = [-20, -5]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), result.groupby([<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>])):
  a.scatter(sp.digamma(np.exp(-g[<span class="org-string">'log_phi'</span>])) + g[<span class="org-string">'log_mu'</span>] + g[<span class="org-string">'log_phi'</span>],
            sp.digamma(np.exp(-g[<span class="org-string">'log_phi_hat'</span>])) + g[<span class="org-string">'log_mu_hat'</span>] + g[<span class="org-string">'log_phi_hat'</span>], s=1, c=<span class="org-string">'k'</span>, alpha=0.3)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(f<span class="org-string">'$n$={k[0]}, $s$={k[1]}'</span>)
  a.set_xlabel(<span class="org-string">'True $\mathrm{E}[\ln\ \lambda]$'</span>)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a[0].set_ylabel(<span class="org-string">'Estimated $\mathrm{E}[\ln\ \lambda]$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-mean-log.png" alt="sim-mean-log.png">
</p>
</div>

<p>
Estimate \(\E[\ln\lambda_{ij}]\) under a point mass expression model, and
compare to the ground truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4.5, 4.5)
<span class="org-variable-name">lim</span> = [-15, -5]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), result.groupby([<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>])):
  a.scatter(sp.digamma(np.exp(-g[<span class="org-string">'log_phi'</span>])) + g[<span class="org-string">'log_mu'</span>] + g[<span class="org-string">'log_phi'</span>], g[<span class="org-string">'theta_hat'</span>], s=1, c=<span class="org-string">'k'</span>, alpha=0.3)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(f<span class="org-string">'$n$={k[0]}, $s$={k[1]}'</span>)
  a.set_xlabel(<span class="org-string">'True $\mathrm{E}[\ln\ \lambda]$'</span>)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a[0].set_ylabel(<span class="org-string">'Estimated $\mathrm{E}[\ln\ \lambda]$'</span>)
fig.tight_layout()

</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-gam-vs-point.png" alt="sim-gam-vs-point.png">
</p>
</div>

<p>
Compare the estimated \(\V[\ln\lambda_{ij}]\) to the ground truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4.5, 4.5)
<span class="org-variable-name">lim</span> = [1e-4, 1e2]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), result.groupby([<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>])):
  <span class="org-variable-name">query</span> = g
  a.set_xscale(<span class="org-string">'log'</span>)
  a.set_yscale(<span class="org-string">'log'</span>)
  a.scatter(query[<span class="org-string">'var_log'</span>], query[<span class="org-string">'var_log_hat'</span>], s=1, c=<span class="org-string">'k'</span>, alpha=0.2)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(f<span class="org-string">'$n$={k[0]}, $s$={k[1]}'</span>)
  a.set_xlabel(<span class="org-string">'True $\mathrm{V}[\ln\ \lambda]$'</span>)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a[0].set_ylabel(<span class="org-string">'Estimated $\mathrm{V}[\ln\ \lambda]$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-var-log.png" alt="sim-var-log.png">
</p>
</div>

<p>
Compare the estimated \(\V[\ln\lambda_{ij}]\) to the ground truth,
restricting to genes with \(\ln\mu > -11\).
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4.5, 4.5)
<span class="org-variable-name">lim</span> = [1e-4, 1e2]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), result.groupby([<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>])):
  <span class="org-variable-name">query</span> = g[g[<span class="org-string">'log_mu'</span>] &gt; -10]
  a.set_xscale(<span class="org-string">'log'</span>)
  a.set_yscale(<span class="org-string">'log'</span>)
  a.scatter(query[<span class="org-string">'var_log'</span>], query[<span class="org-string">'var_log_hat'</span>], s=1, c=<span class="org-string">'k'</span>, alpha=0.2)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(f<span class="org-string">'$n$={k[0]}, $s$={k[1]}'</span>)
  a.set_xlabel(<span class="org-string">'True $\mathrm{V}[\ln\ \lambda]$'</span>)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a[0].set_ylabel(<span class="org-string">'Estimated $\mathrm{V}[\ln\ \lambda]$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-var-log-mu-pass.png" alt="sim-var-log-mu-pass.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org1638472" class="outline-3">
<h3 id="org1638472">Estimation of true effect size distribution</h3>
<div class="outline-text-3" id="text-org1638472">
<p>
To estimate power controlling FDR, we need to make an assumption about the
true distribution of effect sizes. We will make a data-driven assumption by
estimating the true distribution of effect sizes, given observed effect
sizes and standard errors output by limma-voom on a constructed problem
using <code>ashr</code>.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way.h5ad'</span>)
</pre>
</div>

<p>
Construct a problem comparing B cells to cytotoxic T cells. Randomly assign
50 sorted cells to each of 128 donors within each cell type.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x1</span>, <span class="org-variable-name">onehot1</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=128, n_cells=50, min_counts=1, to_array=<span class="org-constant">False</span>)
<span class="org-variable-name">x2</span>, <span class="org-variable-name">onehot2</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'cytotoxic_t'</span>], n_donors=128, n_cells=50, min_counts=1, to_array=<span class="org-constant">False</span>)
<span class="org-variable-name">mix</span> = x1.concatenate(x2)
sc.pp.filter_genes(mix, min_counts=10)
<span class="org-variable-name">onehot</span> = ss.block_diag([onehot1, onehot2], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">design</span> = np.ones((256, 2))
<span class="org-variable-name">design</span>[:128,0] = 0
</pre>
</div>

<p>
Fit <code>limma-voom</code>, followed by EB shrinkage of standard errors.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit0</span> = limma.eBayes(estimate_limma_voom(mix.X.A, onehot, design))
</pre>
</div>

<p>
Fit <code>ashr</code>, using the moderated standard errors and degrees of freedom.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">ashr</span> = rpy2.robjects.packages.importr(<span class="org-string">'ashr'</span>)
<span class="org-variable-name">fit1</span> = ashr.ash(
  betahat=pd.Series(fit0.rx2(<span class="org-string">'coefficients'</span>)[:,0]),
  sebetahat=pd.Series(np.sqrt((fit0.rx2(<span class="org-string">"df.prior"</span>) * fit0.rx2(<span class="org-string">"s2.prior"</span>) + fit0.rx2(<span class="org-string">"df.residual"</span>) * fit0.rx2(<span class="org-string">"stdev.unscaled"</span>)[:,0]) / fit0.rx2(<span class="org-string">"df.total"</span>))),
  df=fit0.rx2(<span class="org-string">'df.total'</span>)[0],
  mixcompdist=<span class="org-string">'halfuniform'</span>)
</pre>
</div>

<p>
Look at the fitted prior distribution of true effects. Find an analytic
distribution whose tail behavior is close enough.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Paired'</span>)
<span class="org-variable-name">grid</span> = np.linspace(-3, 3, 1000)
<span class="org-variable-name">F</span> = ashr.cdf_ash(fit1, grid).rx2(<span class="org-string">'y'</span>).ravel()
<span class="org-variable-name">F2</span> = st.t(scale=0.1, df=1).cdf(grid)
plt.clf()
plt.gcf().set_size_inches(4.5, 2.5)
plt.plot(grid, F, lw=1, c=cm(0), label=<span class="org-string">'ashr'</span>)
plt.plot(grid, F2, lw=1, c=cm(1), label=f<span class="org-string">'$t_1(0, 0.1^2)$'</span>)
plt.axvline(x=0, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'0.5'</span>)
plt.legend(frameon=<span class="org-constant">False</span>)
plt.xlabel(<span class="org-string">'Prior effect size'</span>)
plt.ylabel(<span class="org-string">'CDF'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/b_cells-cytotoxic_t-fitted_g.png" alt="b_cells-cytotoxic_t-fitted_g.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org05839be" class="outline-3">
<h3 id="org05839be">Type 1 error rate (single cells as units)</h3>
<div class="outline-text-3" id="text-org05839be">
<p>
To generate null data, randomly sample cells from a homogeneous population,
and randomly assign labels. Use
<a href="https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/pbmc_10k_v3">10X
v3 PBMC data</a>, which has more molecules observed per sample on average.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/modes/10k_pbmc_v3.h5ad'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = evaluate_type1(dat, min_counts=20, n_trials=10)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2)
fig.set_size_inches(4.5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'PM-EB'</span>, <span class="org-string">'PM-Z'</span>]
<span class="org-keyword">for</span> i, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(result.groupby([<span class="org-string">'method'</span>, <span class="org-string">'test'</span>])):
  ax[0].boxplot(g[<span class="org-string">'fpr'</span>], positions=[i], widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
  ax[1].boxplot(g[<span class="org-string">'fpr'</span>], positions=[i], widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[1].set_ylim(0, 0.02)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a.axhline(y=0.01, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
  a.set_xticks(<span class="org-builtin">range</span>(<span class="org-builtin">len</span>(labels)))
  a.set_xticklabels(labels, rotation=90)
  a.set_xlabel(<span class="org-string">'Method'</span>)
ax[0].set_ylabel(<span class="org-string">'Type 1 error rate'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/fpr.png" alt="fpr.png">
</p>
</div>
</div>

<div id="outline-container-org541743d" class="outline-4">
<h4 id="org541743d">Unequal size factors</h4>
<div class="outline-text-4" id="text-org541743d">
<p>
To generate single cells with unequal size factors, combine simulated
doublets from sorted cells in one group.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way.h5ad'</span>)
<span class="org-variable-name">n_cells</span> = 100
<span class="org-variable-name">x1</span>, <span class="org-variable-name">onehot1</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=1, n_cells=n_cells, min_counts=0, to_dense=<span class="org-constant">False</span>)
<span class="org-variable-name">x2</span>, <span class="org-variable-name">onehot2</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=n_cells, n_cells=2, min_counts=0, to_dense=<span class="org-constant">False</span>)
<span class="org-variable-name">mix</span> = ss.vstack([x1, onehot2.T @ x2], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">mix</span> = anndata.AnnData(mix)
<span class="org-comment-delimiter"># </span><span class="org-comment">Estimate the global mean for filtering genes</span>
<span class="org-variable-name">thetahat</span> = np.log(mix.X.A.<span class="org-builtin">sum</span>(axis=0) + 1) - np.log(mix.X.<span class="org-builtin">sum</span>())
<span class="org-variable-name">onehot</span> = ss.block_diag([onehot1, np.ones((100, 1))], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
</pre>
</div>

<p>
Fit <code>limma-voom</code>, followed by EB shrinkage of standard errors. Report the
number of false positives (\(\alpha < 0.01\)), and the number of genes
tested.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">query</span> = thetahat &gt; -11
(estimate_moderated_t(estimate_limma_voom(mix[:,query].X.A, onehot.A)) &lt; 0.01).mean(), query.<span class="org-builtin">sum</span>()
</pre>
</div>

<pre class="example">
(0.9590070598952403, 4391)

</pre>

<p>
Repeat the analysis for a larger number of cells.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">n_cells</span> = 1000
<span class="org-variable-name">x1</span>, <span class="org-variable-name">onehot1</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=1, n_cells=n_cells, min_counts=0, to_dense=<span class="org-constant">False</span>)
<span class="org-variable-name">x2</span>, <span class="org-variable-name">onehot2</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=n_cells, n_cells=2, min_counts=0, to_dense=<span class="org-constant">False</span>)
<span class="org-variable-name">mix</span> = ss.vstack([x1, onehot2.T @ x2], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">mix</span> = anndata.AnnData(mix)
<span class="org-comment-delimiter"># </span><span class="org-comment">Estimate the global mean for filtering genes</span>
<span class="org-variable-name">thetahat</span> = np.log(mix.X.A.<span class="org-builtin">sum</span>(axis=0) + 1) - np.log(mix.X.<span class="org-builtin">sum</span>())
<span class="org-variable-name">onehot</span> = ss.block_diag([onehot1, np.ones((n_cells, 1))], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">query</span> = thetahat &gt; -11
(estimate_moderated_t(estimate_limma_voom(mix[:,query].X.A, onehot.A)) &lt; 0.01).mean(), query.<span class="org-builtin">sum</span>()
</pre>
</div>

<pre class="example">
(0.96875, 4096)

</pre>

<p>
Fit a point mass expression model to each group.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">theta</span> = np.log(onehot.T @ mix.X[:,query].A + 1) - np.log(onehot.T @ mix.X.<span class="org-builtin">sum</span>(axis=1))
</pre>
</div>

<p>
Fit a Gamma expression model to each group.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">log_mu</span>, <span class="org-variable-name">neg_log_phi</span> = mpebpm.sgd.ebpm_gamma(
  mix.X[:,query].A,
  s=mix.X.<span class="org-builtin">sum</span>(axis=1).A,
  onehot=onehot.A,
  batch_size=32,
  num_epochs=1000,
  log_dir=<span class="org-string">'runs/mpebpm/b_cells-sim-unequal-s'</span>)
</pre>
</div>

<p>
Compare the estimated mean log expression for each gene under the Gamma
model to the estimate under the point mass model.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4, 2.5)
<span class="org-variable-name">lim</span> = [-12, -2]
<span class="org-keyword">for</span> a, y, t <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax, [theta.A, log_mu], [<span class="org-string">'Point mass'</span>, <span class="org-string">'Gamma'</span>]):
  a.scatter(y[0], y[1], c=<span class="org-string">'k'</span>, s=1, alpha=0.1)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(t)
  a.set_xlabel(<span class="org-string">'$\mathrm{E}[\ln\ \lambda]$ (size $s$)'</span>)
ax[0].set_ylabel(<span class="org-string">'$\mathrm{E}[\ln\ \lambda]$ (size $2s$)'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/b_cells-sim-unequal-s.png" alt="b_cells-sim-unequal-s.png">
</p>
</div>

<p>
The problem seems to be that in <code>limma</code>, observed \(x_{ij} = 0\) are
treated as having \(\ln\lambda_{ij} = -\ln\xiplus\) in group 1, and
\(\ln\lambda_{ij} = -\ln (2\xiplus)\) in group 2. This problem cannot be
solved by using the posterior mean of gene expression under e.g., Gamma
models for each group instead, because the posterior mean is
</p>

\begin{equation}
  \E[\ln\lambda_{ij} \mid x_{ij}, \xiplus, g_{jk}] = \psi(x_{ij} + \phi_{jk}^{-1}) + \ln(x_{ij} + \phi_{jk}^{-1}) + \ln(\xiplus + \mu_{jk}^{-1}\phi_{jk}^{-1}),
\end{equation}

<p>
and we have shown empirically that \(\mu_{jk}\) and \(\phi_{jk}\) are
nearly equal between the two groups \(k\).
</p>
</div>
</div>
</div>

<div id="outline-container-org6fff017" class="outline-3">
<h3 id="org6fff017">Power (single cells as units)</h3>
<div class="outline-text-3" id="text-org6fff017">
<p>
To generate true positives treating cells as units, randomly sample cells
from a homogeneous population, randomly assign labels, and then use binomial
thinning (Gerard 2019) to introduce effects of a given magnitude.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = []
<span class="org-keyword">for</span> b <span class="org-keyword">in</span> -np.log(np.linspace(1.05, 1.5, 20)):
  result.append(evaluate_power(b_cells, b=b, alpha=0.1, n_trials=1))
<span class="org-variable-name">result</span> = pd.concat(result)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Paired'</span>)
plt.clf()
plt.gcf().set_size_inches(3.5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'PM-EB'</span>, <span class="org-string">'PM-Z'</span>]
<span class="org-keyword">for</span> i, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(result.groupby([<span class="org-string">'method'</span>, <span class="org-string">'test'</span>])):
  plt.plot(np.exp(-g[<span class="org-string">'b'</span>]), g[<span class="org-string">'tpr'</span>], lw=1, c=cm(i), marker=<span class="org-string">'.'</span>, ms=4, label=labels[i])
plt.legend(frameon=<span class="org-constant">False</span>, loc=<span class="org-string">'center left'</span>, bbox_to_anchor=(1, .5))
plt.xlabel(<span class="org-string">'True effect size'</span>)
plt.ylabel(r<span class="org-string">'Power ($\alpha$=0.01)'</span>)
plt.ylim(0, 1)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/power-2-0.01.png" alt="power-2-0.01.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org3aa1007" class="outline-3">
<h3 id="org3aa1007">Type 1 error rate (donors as units)</h3>
<div class="outline-text-3" id="text-org3aa1007">
<p>
To generate null data, first randomly assign cells from a homogeneous sample
to donors, then randomly assign donors to groups.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way.h5ad'</span>)
<span class="org-variable-name">b_cells</span> = dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = evaluate_type1_by_donor(b_cells, min_counts=10, n_trials=50)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2)
fig.set_size_inches(4.5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'GAM-EB'</span>, <span class="org-string">'GAM-Z'</span>, <span class="org-string">'PM-EB'</span>, <span class="org-string">'PM-Z'</span>]
<span class="org-keyword">for</span> i, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(result.groupby([<span class="org-string">'method'</span>, <span class="org-string">'test'</span>])):
  ax[0].boxplot(g[<span class="org-string">'fpr'</span>], positions=[i], widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
  ax[1].boxplot(g[<span class="org-string">'fpr'</span>], positions=[i], widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
ax[1].set_ylim(0, 0.02)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a.axhline(y=0.01, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
  a.set_xticks(<span class="org-builtin">range</span>(<span class="org-builtin">len</span>(labels)))
  a.set_xticklabels(labels, rotation=90)
  a.set_xlabel(<span class="org-string">'Method'</span>)
ax[0].set_ylabel(<span class="org-string">'Type 1 error rate'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/fpr-by-donor.png" alt="fpr-by-donor.png">
</p>
</div>
</div>

<div id="outline-container-org3c05f52" class="outline-4">
<h4 id="org3c05f52">Unequal size factors</h4>
<div class="outline-text-4" id="text-org3c05f52">
<p>
Generate null data with different size factors by assigning different
numbers of cells to different donors.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x1</span>, <span class="org-variable-name">onehot1</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=4, n_cells=50, min_counts=1, to_array=<span class="org-constant">False</span>)
<span class="org-variable-name">x2</span>, <span class="org-variable-name">onehot2</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=4, n_cells=100, min_counts=1, to_array=<span class="org-constant">False</span>)
<span class="org-variable-name">mix</span> = x1.concatenate(x2)
sc.pp.filter_genes(mix, min_counts=10)
<span class="org-variable-name">onehot</span> = ss.block_diag([onehot1, onehot2], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">design</span> = np.ones((8, 2))
<span class="org-variable-name">design</span>[:4,0] = 0
</pre>
</div>

<p>
Look at the distribution of size factors.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.boxplot((onehot.T @ mix.X.<span class="org-builtin">sum</span>(axis=1)).A.reshape(2, -1).T, widths=0.5, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>})
plt.xlabel(<span class="org-string">'Group'</span>)
plt.ylabel(<span class="org-string">'Size factor'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-ex-unequal-s-hist.png" alt="sim-ex-unequal-s-hist.png">
</p>
</div>

<p>
Fit <code>limma-voom</code>, followed by EB shrinkage of standard errors.
</p>

<div class="org-src-container">
<pre class="src src-ipython">(estimate_moderated_t(estimate_limma_voom(mix.X.A, onehot, design)) &lt; 0.01).mean()
</pre>
</div>

<pre class="example">
0.0

</pre>

<p>
Look at the point mass estimates.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">thetahat</span> = np.log((onehot.T @ mix.X).A + 1) - np.log(onehot.T @ mix.X.<span class="org-builtin">sum</span>(axis=1).A)
plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.scatter(thetahat[:4].ravel(), thetahat[4:].ravel(), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
<span class="org-variable-name">lim</span> = [-15, 3]
plt.plot(lim, lim, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
plt.xlim(lim)
plt.ylim(lim)
plt.xlabel(<span class="org-string">'Est mean (50 cells)'</span>)
plt.ylabel(<span class="org-string">'Est mean (100 cells)'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-ex-unequal-s-point-mass.png" alt="sim-ex-unequal-s-point-mass.png">
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org9c356fb" class="outline-3">
<h3 id="org9c356fb">Power (donors as units)</h3>
<div class="outline-text-3" id="text-org9c356fb">
<p>
To generate true positives treating donors as units, randomly sample cells
from a homogeneous population, randomly assign cells to donors, randomly
assign donors to groups, and then thin all cells assigned to the effect
group equally.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = []
<span class="org-keyword">for</span> b <span class="org-keyword">in</span> -np.log(np.linspace(1, 2, 20)):
  result.append(evaluate_power_by_donor(b_cells, b=b, n_donors=64, n_cells=50, alpha=0.01, n_trials=1))
<span class="org-variable-name">result</span> = pd.concat(result)
result.to_csv(<span class="org-string">'/scratch/midway2/aksarkar/singlecell/limma-voom-power-by-donor-40.txt.gz'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Paired'</span>)
plt.clf()
plt.gcf().set_size_inches(3.5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'GAM-EB'</span>, <span class="org-string">'GAM-Z'</span>, <span class="org-string">'PM-EB'</span>, <span class="org-string">'PM-Z'</span>]
<span class="org-keyword">for</span> i, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(result.groupby([<span class="org-string">'method'</span>, <span class="org-string">'test'</span>])):
  plt.plot(np.exp(-g[<span class="org-string">'b'</span>]), g[<span class="org-string">'tpr'</span>], lw=1, c=cm(i), marker=<span class="org-string">'.'</span>, ms=4, label=labels[i])
plt.legend(frameon=<span class="org-constant">False</span>, loc=<span class="org-string">'center left'</span>, bbox_to_anchor=(1, .5))
plt.xlabel(<span class="org-string">'True effect size'</span>)
plt.ylabel(r<span class="org-string">'Power ($\alpha$=0.01)'</span>)
plt.ylim(0, 1)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/power-by-donor.png" alt="power-by-donor.png">
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2020-06-22 Mon 19:09</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
