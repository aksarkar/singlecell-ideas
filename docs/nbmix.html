<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2020-05-15 Fri 00:57 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Model-based clustering of scRNA-seq data</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="bootstrap.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="htmlize.css"/>
<link rel="stylesheet" type="text/css" href="main.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Model-based clustering of scRNA-seq data</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org34e8d5e">Introduction</a></li>
<li><a href="#setup">Setup</a></li>
<li><a href="#org5ee032a">Method</a></li>
<li><a href="#orgdca968c">Results</a>
<ul>
<li><a href="#org9793c6c">Example</a></li>
</ul>
</li>
<li><a href="#org089f29e">Related work</a></li>
</ul>
</div>
</div>

<div id="outline-container-org34e8d5e" class="outline-2">
<h2 id="org34e8d5e">Introduction</h2>
<div class="outline-text-2" id="text-org34e8d5e">
<p>
Two major strategies for clustering scRNA-seq data are:
</p>

<ol class="org-ol">
<li>Building a \(k\)-nearest neighbor graph on the data, and applying a
community detection algorithm (e.g.,
<a href="https://doi.org/10.1088/1742-5468/2008/10/P10008">Blondel et al. 2008</a>,
<a href="https://arxiv.org/abs/1810.08473">Traag et al. 2018</a>)</li>
<li>Fitting a topic model to the data
(e.g., <a href="https://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1006599">Dey
et al. 2017</a>,
<a href="https://www.nature.com/articles/s41592-019-0367-1">Gonzáles-Blas et
al. 2019</a>)</li>
</ol>

<p>
The main disadvantage of strategy (1) is that, as commonly applied to
transformed counts, it does not separate measurement error and biological
variation of interest. The main disadvantage of strategy (2) is that it does
not account for transcriptional noise
(<a href="https://doi.org/10.1016/j.cell.2008.09.050">Raj 2008</a>). Here, we develop
a simple model-based clustering algorithm which addresses both of these
issues.
</p>
</div>
</div>

<div id="outline-container-orgb4dd078" class="outline-2">
<h2 id="setup"><a id="orgb4dd078"></a>Setup</h2>
<div class="outline-text-2" id="text-setup">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> anndata
<span class="org-keyword">import</span> mpebpm.gam_mix
<span class="org-keyword">import</span> mpebpm.sgd
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> pandas <span class="org-keyword">as</span> pd
<span class="org-keyword">import</span> scanpy <span class="org-keyword">as</span> sc
<span class="org-keyword">import</span> scipy.stats <span class="org-keyword">as</span> st
<span class="org-keyword">import</span> torch
<span class="org-keyword">import</span> torch.utils.data <span class="org-keyword">as</span> td
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%matplotlib inline
%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'retina'</span>])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'figure.facecolor'</span>] = <span class="org-string">'w'</span>
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'font.family'</span>] = <span class="org-string">'Nimbus Sans'</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org5ee032a" class="outline-2">
<h2 id="org5ee032a">Method</h2>
<div class="outline-text-2" id="text-org5ee032a">
<p>
We assume \(
  \DeclareMathOperator\Gam{Gamma}
  \DeclareMathOperator\Mult{Multinomial}
  \DeclareMathOperator\N{\mathcal{N}}
  \DeclareMathOperator\Pois{Poisson}
  \newcommand\mi{\mathbf{I}}
  \newcommand\vmu{\boldsymbol{\mu}}
  \newcommand\vphi{\boldsymbol{\phi}}
  \newcommand\vpi{\boldsymbol{\pi}}
  \)
</p>

\begin{align}
  x_{ij} \mid x_{i+}, \lambda_{ij} &\sim \Pois(x_{i+} \lambda_{ij})\\
  \lambda_{ij} \mid \vpi, \vmu, \vphi &\sim \sum_{k=1}^{K} \pi_{ik} \Gam(\phi_{kj}^{-1}, \phi_{kj}^{-1}\mu_{kj}^{-1}),
\end{align}

<p>
where
</p>

<ul class="org-ul">
<li>\(x_{ij}\) denotes the number of molecules of gene \(j\) observed in cell \(i\)</li>
<li>\(x_{i+} \triangleq \sum_j x_{ij}\) denotes the total number of molecules
observed in cell \(i\)</li>
<li>\(\vpi_i\) denotes cluster assignment probabilities for cell \(i\)</li>
<li>\(\vmu_k\) denotes the cluster &ldquo;centroid&rdquo; for cluster \(k\), and
\(\vphi_k\) describes stochastic perturbations within each cluster</li>
</ul>

<p>
The intuition behind this model is that each cluster \(k\) is defined by a
collection of independent Gamma distributions, one per gene \(j\). These
Gamma distributions describe the distribution of true gene expression for
each gene in each cluster
(<a href="https://dx.doi.org/10.1101/2020.04.07.030007">Sarkar and Stephens 2020</a>).
</p>

<p>
We can estimate \(\vpi, \vmu, \vphi\) by maximizing the likelihood using an
EM algorithm. Letting \(z_{ik} \in \{0, 1\}\) indicate whether cell \(i\) is
assigned to cluster \(k\), in the E step
</p>

\begin{equation}
  E[z_{ik}] \propto \sum_j \int_0^{\infty} \Pois(x_{ij}; x_{i+}\lambda) \Gam(\lambda; \phi_{kj}^{-1}, \phi_{kj}^{-1}\mu_{kj}^{-1})\, d\lambda.
\end{equation}

<p>
In the M step, we improve the weighted mixture of negative binomials
likelihood by <a href="mepbpm.html">(batch) gradient descent</a>, implemented in
the Python package <code>mpebpm</code>. To make the model more amenable to stochastic
gradient descent, we can amortize inference by learning a neural network
mapping \(x_{i\cdot} \rightarrow z_{i\cdot}\).
</p>

<p>
The posterior distribution of true gene expression given the data is
</p>

\begin{equation}
  \lambda_{ij} \mid x_{ij}, x_{i+}, \vpi, \vmu, \vphi \sim \sum_{k=1}^{K} \pi_{ik} \Gam(x_{ij} + \phi_{kj}^{-1}, x_{i+} + \phi_{kj}^{-1}\mu_{kj}^{-1}).
\end{equation}
</div>
</div>

<div id="outline-container-orgdca968c" class="outline-2">
<h2 id="orgdca968c">Results</h2>
<div class="outline-text-2" id="text-orgdca968c">
</div>
<div id="outline-container-org9793c6c" class="outline-3">
<h3 id="org9793c6c">Example</h3>
<div class="outline-text-3" id="text-org9793c6c">
<p>
Read sorted immune cell scRNA-seq data
(<a href="https://dx.doi.org/10.1038/ncomms14049">Zheng et al. 2017</a>).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way.h5ad'</span>)
</pre>
</div>

<p>
Get 256 B cells and 256 cytotoxic T cells.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">b_cells</span> = dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>]
<span class="org-comment-delimiter"># </span><span class="org-comment">Important: this has a set seed</span>
sc.pp.subsample(b_cells, n_obs=256)
<span class="org-variable-name">t_cells</span> = dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'cytotoxic_t'</span>]
sc.pp.subsample(t_cells, n_obs=256)
<span class="org-variable-name">temp</span> = b_cells.concatenate(t_cells)
sc.pp.filter_genes(temp, min_counts=1)
</pre>
</div>

<p>
Plot a UMAP embedding of the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython">sc.pp.pca(temp)
sc.pp.neighbors(temp)
sc.tl.umap(temp)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
plt.gcf().set_size_inches(3, 3)
<span class="org-keyword">for</span> i, c <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(temp.obs[<span class="org-string">'cell_type'</span>].unique()):
  plt.plot(*temp[temp.obs[<span class="org-string">'cell_type'</span>] == c].obsm[<span class="org-string">"X_umap"</span>].T, c=cm(i), marker=<span class="org-string">'.'</span>, ms=2, lw=0, label=f<span class="org-string">'{c}'</span>)
plt.legend(frameon=<span class="org-constant">False</span>, markerscale=4, handletextpad=0)
plt.xlabel(<span class="org-string">'UMAP 1'</span>)
plt.ylabel(<span class="org-string">'UMAP 2'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/nbmix.org/sim-ex.png" alt="sim-ex.png">
</p>
</div>

<p>
First, start from the ground truth \(z\) (labels), and estimate the Gamma
expression models.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit</span> = mpebpm.sgd.ebpm_gamma(
  temp.X,
  onehot=pd.get_dummies(temp.obs[<span class="org-string">'cell_type'</span>]).values,
  batch_size=32,
  num_epochs=320,
  shuffle=<span class="org-constant">True</span>,
  log_dir=<span class="org-string">'runs/nbmix/ex4'</span>)
</pre>
</div>

<p>
Estimate the cluster weights.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">L</span> = mpebpm.gam_mix._nb_mix_llik(
  x=torch.tensor(temp.X.A, dtype=torch.<span class="org-builtin">float</span>), 
  s=torch.tensor(temp.X.<span class="org-builtin">sum</span>(axis=1), dtype=torch.<span class="org-builtin">float</span>),
  log_mean=torch.tensor(fit[0], dtype=torch.<span class="org-builtin">float</span>),
  log_inv_disp=torch.tensor(fit[1], dtype=torch.<span class="org-builtin">float</span>)).<span class="org-builtin">sum</span>(dim=-1)
<span class="org-variable-name">zhat</span> = torch.nn.functional.softmax(L, dim=1)
</pre>
</div>

<p>
Compute the cross entropy between the estimated \(\hat{z}\) and the ground
truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">torch.nn.functional.binary_cross_entropy(
  zhat,
  torch.tensor(pd.get_dummies(temp.obs[<span class="org-string">'cell_type'</span>]).values, dtype=torch.<span class="org-builtin">float</span>))
</pre>
</div>

<pre class="example">
tensor(0.)

</pre>

<p>
Compute a weighted log likelihood.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">w</span> = torch.rand([512, 2])
<span class="org-variable-name">w</span> /= w.<span class="org-builtin">sum</span>(dim=1).unsqueeze(-1)
<span class="org-variable-name">m</span>, <span class="org-variable-name">_</span> = L.<span class="org-builtin">max</span>(dim=1, keepdim=<span class="org-constant">True</span>)
(m + torch.log(w * torch.exp(L - m) + 1e-8)).mean()
</pre>
</div>

<pre class="example">
tensor(-1872.6364)

</pre>

<p>
Try fitting the model from a random initialization.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> imp; imp.<span class="org-builtin">reload</span>(mpebpm.gam_mix)
torch.manual_seed(1)
<span class="org-variable-name">fit</span> = mpebpm.gam_mix.ebpm_gam_mix(
  x=temp.X.A,
  s=temp.X.<span class="org-builtin">sum</span>(axis=1),
  y=torch.tensor(pd.get_dummies(temp.obs[<span class="org-string">'cell_type'</span>]).values, dtype=torch.<span class="org-builtin">float</span>).cuda(),
  k=2,
  batch_size=512,
  num_epochs=400,
  max_em_iters=100,
  tol=0.1,
  log_dir=<span class="org-string">'runs/nbmix/test11'</span>)
</pre>
</div>

<p>
Compute the cross entropy between the estimated \(\hat{z}\) and the ground
truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">torch.nn.functional.binary_cross_entropy(
  torch.tensor(1 - fit[-1], dtype=torch.<span class="org-builtin">float</span>),
  torch.tensor(pd.get_dummies(temp.obs[<span class="org-string">'cell_type'</span>]).values, dtype=torch.<span class="org-builtin">float</span>))
</pre>
</div>

<pre class="example">
tensor(0.)

</pre>

<p>
Plot the UMAP, colored by the fitted clusters.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
plt.gcf().set_size_inches(3, 3)
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(fit[-1].shape[1]):
  plt.plot(*temp[fit[-1][:,i].astype(<span class="org-builtin">bool</span>)].obsm[<span class="org-string">"X_umap"</span>].T, c=cm(i), marker=<span class="org-string">'.'</span>, ms=2, lw=0, label=f<span class="org-string">'Cluster {i}'</span>)
plt.legend(frameon=<span class="org-constant">False</span>, markerscale=4, handletextpad=0)
plt.xlabel(<span class="org-string">'UMAP 1'</span>)
plt.ylabel(<span class="org-string">'UMAP 2'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/nbmix.org/sim-ex-fit.png" alt="sim-ex-fit.png">
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org089f29e" class="outline-2">
<h2 id="org089f29e">Related work</h2>
<div class="outline-text-2" id="text-org089f29e">
<p>
scVI (<a href="https://dx.doi.org/10.1038/s41592-018-0229-2">Lopez et al. 2018</a>,
<a href="https://www.biorxiv.org/content/10.1101/532895v2">Xu et al. 2020</a>)
implements a related deep unsupervised (more precisely, semi-supervised)
clustering model (<a href="https://arxiv.org/abs/1406.5298">Kingma et al. 2014</a>,
<a href="https://arxiv.org/abs/1611.02648">Dilokthanakul et al. 2016</a>).
</p>

\begin{align}
  x_{i\cdot} \mid s_i, \lambda_{ij} &\sim \Pois(s_i \lambda_{ij})\\
  \ln s_i &\sim \N(\cdot)\\
  \lambda_{ij} \mid z_{i\cdot} &\sim \Gam(\phi_j^{-1}, (\mu_{\lambda}^{-1}(z_{i\cdot}))_j \phi_j^{-1})\\
  z_{i\cdot} \mid y_i, u_i &\sim \N(\mu_i(u_i, y_i), \sigma^2(u_i, y_i))\\
  y_i &\sim \Mult(1, \vpi)\\
  u_i &\sim \N(0, \mi).
\end{align}

<p>
where
</p>

<ul class="org-ul">
<li>\(y_i\) denotes the cluster assignment for cell \(i\)</li>
<li>\(\mu_i(\cdot), \sigma^2(\cdot)\) are neural networks mapping the latent
cluster variable \(y_i\) and Gaussian noise \(u_i\) to the latent variable
\(z_i\)</li>
<li>\(\mu_{\lambda}(\cdot)\) is a neural network mapping latent variable \(z_i\) to
latent gene expression \(\lambda_{ij}\)</li>
</ul>

<p>
The intuition behind this model is that the prior \(p(z_i)\) (marginalizing
over \(y_i\)) is a mixture of Gaussians, and therefore the model embeds
examples in a space which makes clustering easy, and maps examples to those
clusters simultaneously. To perform variational inference in this model,
Lopez et al. introduce inference networks
</p>

\begin{align}
  q(y_i, z_{i\cdot} \mid x_{i\cdot}) = q(z_{i\cdot} \mid x_{i\cdot})\, q(y_i \mid z_{i\cdot})
\end{align}

<p>
Rui Shu <a href="http://ruishu.io/2016/12/25/gmvae/">proposed an alternative
generative model</a>, which has some practical benefits and can be adapted to
this problem
</p>

\begin{align}
  x_{i\cdot} \mid x_{i+}, \lambda_{ij} &\sim \Pois(x_{i+} \lambda_{ij})\\
  \lambda_{ij} \mid z_{i\cdot} &\sim \Gam(\phi_j^{-1}, (\mu_{\lambda}^{-1}(z_{i\cdot}))_j \phi_j^{-1})\\
  z_{i\cdot} \mid y_i &\sim \N(\mu_i(y_i), \sigma^2(y_i))\\
  y_i &\sim \Mult(1, \vpi)\\
  q(y_i, z_{i\cdot} \mid x_{i\cdot}) &= q(y_i \mid x_{i\cdot})\, q(z_i \mid y_i, x_{i\cdot})
\end{align}
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2020-05-15 Fri 00:57</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
