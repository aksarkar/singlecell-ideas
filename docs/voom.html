<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2020-07-09 Thu 23:44 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>An improved voom transform for scRNA-seq data</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="bootstrap.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="htmlize.css"/>
<link rel="stylesheet" type="text/css" href="main.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">An improved voom transform for scRNA-seq data</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orga658581">Introduction</a></li>
<li><a href="#setup">Setup</a></li>
<li><a href="#org3e4ab9d">Methods</a>
<ul>
<li><a href="#org8a4c1a0">Standard error of point mass expression model</a></li>
<li><a href="#org618f456">Variance of Gamma expression model</a></li>
<li><a href="#orgdaf9c29">Controlling FDR</a></li>
<li><a href="#orgc7d2b9a">Simulation</a></li>
</ul>
</li>
<li><a href="#org9652fb0">Results</a>
<ul>
<li><a href="#orga144bdf">Accuracy of estimation</a></li>
<li><a href="#org1638472">Estimation of true effect size distribution</a></li>
<li><a href="#org403ef73">Simulation sanity check</a></li>
<li><a href="#org05839be">Type 1 error rate (single cells as units)</a></li>
<li><a href="#org6fff017">Power (single cells as units)</a></li>
<li><a href="#org3aa1007">Type 1 error rate (donors as units)</a></li>
<li><a href="#org9c356fb">Power (donors as units)</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orga658581" class="outline-2">
<h2 id="orga658581">Introduction</h2>
<div class="outline-text-2" id="text-orga658581">
<p>
The key idea of limma-voom (Law et al. 2014) is to transform a count matrix
generated by bulk RNA-seq into two matrices, representing the mean and
variance of true (log) gene expression. These matrices can then be analyzed
using (heteroscedastic) Gaussian methods. However, limma-voom was developed
before the development of scRNA-seq, and therefore before it was possible to
measure the variance of gene expression between cells from a single donor. To
address this limitation, Law et al. instead proposed to pool information
across both donors and genes, estimating a LOESS trend between the mean and
variance of true gene expression values across donors. \(
  \DeclareMathOperator\E{E}
  \DeclareMathOperator\Gam{Gamma}
  \DeclareMathOperator\N{\mathcal{N}}
  \DeclareMathOperator\Poi{Poisson}
  \DeclareMathOperator\V{V}
  \DeclareMathOperator\digamma{\psi}
  \DeclareMathOperator\trigamma{\psi^{(1)}}
  \newcommand\vb{\mathbf{b}}
  \newcommand\vc{\mathbf{c}}
  \newcommand\xiplus{x_{i+}}
  \)
</p>

<p>
Now suppose we have observed scRNA-seq data \(x_{ij}\), where \(x_{ij}\)
denotes the number of molecules from gene \(j\) observed in cell \(i\). Then,
there are two possible DE analysis we might be interested in. First, we might
divide (some subset of) cells into two groups, and ask whether genes are
differentially expressed between groups. Second, we might divide donors into
groups, and test whether genes (in some subset of cells, per donor) are
differentially expressed between groups. The key distinction is that single
cells are the units in the first case, and donors are the units in the second
case.
</p>

<p>
We can apply limma-voom without modification to the first case, because the
typical log transformation corresponds to an MLE
</p>

\begin{align}
  x_{ij} \mid \xiplus, \theta_{ij} &\sim \Poi(\xiplus \exp(\theta_{ij}))\\
  \ell \triangleq \ln p(x_{ij} \mid \xiplus, \theta_{ij}) &= x_{ij} (\ln \xiplus + \theta_{ij}) - \xiplus \exp(\theta_{ij}) + \mathrm{const}\\
  \frac{\partial \ell}{\partial \theta_{ij}} &= x_{ij} - \xiplus \exp(\theta_{ij})\\
  \hat\theta_{ij} &= \ln\left(\frac{x_{ij}}{\xiplus}\right).
\end{align}

<p>
This simple theoretical argument and empirical studies have demonstrated that
applying limma-voom to scRNA-seq data can work (Soneson and Robinson 2018,
Hsiao 2019). However, unlike the bulk RNA-seq case, now the notion of
&ldquo;variance of gene expression&rdquo; within a single unit no longer makes
sense. Therefore, it is unclear what precisely limma-voom is fitting in this
case.
</p>

<p>
Applying limma-voom to the second case also works, because we can estimate a
point mass expression model for the cells from each donor \(k\)
</p>

\begin{align}
  x_{ij} \mid \xiplus, \theta_j &\sim \Poi(\xiplus \exp(\theta_j))\\
  \ell \triangleq \sum_i \ln p(x_{ij} \mid \xiplus, \theta_j) &= \sum_i x_{ij} (\ln \xiplus + \theta_j) - \xiplus \exp(\theta_j) + \mathrm{const}\\
  \frac{\partial \ell}{\partial \theta_j} &= \sum_i x_{ij} - \xiplus \exp(\theta_j)\\
  \theta_j &= \ln\left(\frac{\sum_i x_{ij}}{\sum_i \xiplus}\right)\\
\end{align}

<p>
where \(\xiplus \triangleq \sum_j x_{ij}\) (Sarkar and Stephens 2020). This
approach is equivalent to constructing pseudobulk data \(y_{kj} \triangleq
  \sum_i x_{ij} z_{ik}\), where \(z_{ik}\) indicates whether cell \(i\) came
from donor \(k\), and using \(\ln(y_{kj} / y_{k+})\) as the estimated mean of
true log gene expression, where \(y_{k+} \triangleq \sum_j y_{kj}\). However,
the relationship between the voom-estimated variance and the true gene
expression variance is unclear because the variance used by voom is between
individuals, not within an individual (although there is
<a href="mpebpm.html#org677b3e2">some
evidence that the two are highly correlated</a>). Further, it is unlikely that
a point mass expression model will be supported by the data.
</p>

<p>
We previously developed a method to efficiently estimate more complex
expression models in large-scale scRNA-seq data sets (Sarkar et
al. 2019). Here, we use that method to investigate two new possibilities for
a precision weight derived from fitted expression models: (1) the inverse
squared standard error of a point mass model, or (2) the inverse variance of
the log true expression under a Gamma model. Specifically, we ask whether
these alterantive approaches improve the power or robustness of DE analysis
in scRNA-seq data.
</p>
</div>
</div>

<div id="outline-container-org3b4cae3" class="outline-2">
<h2 id="setup"><a id="org3b4cae3"></a>Setup</h2>
<div class="outline-text-2" id="text-setup">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> anndata
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> mpebpm
<span class="org-keyword">import</span> pandas <span class="org-keyword">as</span> pd
<span class="org-keyword">import</span> scanpy <span class="org-keyword">as</span> sc
<span class="org-keyword">import</span> rpy2.robjects.packages
<span class="org-keyword">import</span> rpy2.robjects.pandas2ri
<span class="org-keyword">import</span> scipy.special <span class="org-keyword">as</span> sp
<span class="org-keyword">import</span> scipy.sparse <span class="org-keyword">as</span> ss
<span class="org-keyword">import</span> scipy.stats <span class="org-keyword">as</span> st
<span class="org-keyword">import</span> sqlite3
<span class="org-keyword">import</span> scqtl
<span class="org-keyword">import</span> torch

<span class="org-variable-name">ashr</span> = rpy2.robjects.packages.importr(<span class="org-string">'ashr'</span>)
<span class="org-variable-name">limma</span> = rpy2.robjects.packages.importr(<span class="org-string">'limma'</span>)
rpy2.robjects.pandas2ri.activate()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%matplotlib inline
%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'retina'</span>])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'figure.facecolor'</span>] = <span class="org-string">'w'</span>
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'font.family'</span>] = <span class="org-string">'Nimbus Sans'</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org3e4ab9d" class="outline-2">
<h2 id="org3e4ab9d">Methods</h2>
<div class="outline-text-2" id="text-org3e4ab9d">
</div>
<div id="outline-container-org8a4c1a0" class="outline-3">
<h3 id="org8a4c1a0">Standard error of point mass expression model</h3>
<div class="outline-text-3" id="text-org8a4c1a0">
<p>
The standard error of \(\hat\theta_j\) is analytic
</p>

\begin{align}
  \frac{\partial^2 \ell}{\partial \theta_j^2} &= -\sum_i \xiplus \exp(\theta_j)\\
  \mathcal{I}(\mu_j) &= -\E\left[\frac{\partial^2 \ell}{\partial \mu_j^2}\right] = \sum_i \xiplus \exp(\theta_j)\\
  s_j^2 &= \frac{1}{\sum_i \xiplus \exp(\theta_j)},
\end{align}

<p>
where we have treated \(\xiplus\) as fixed. This treatment is justified by
the fact that the Poisson measurement model for each gene arises from a
Multinomial measurement model for all genes jointly, in which the total
number of molecules observed is fixed rather than a sum of random
variables. As an illustrative example, plot the bootstrap distribution of the
\(\hat\theta_j\) against a normal density with mean \(\theta_j\) and variance
\(s_j^2\) for a simple simulation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">rng</span> = np.random.default_rng(1)
<span class="org-variable-name">n_trials</span> = 1000
<span class="org-variable-name">n</span> = 100
<span class="org-variable-name">s</span> = 1e4
<span class="org-variable-name">theta</span> = -11
<span class="org-variable-name">thetahat</span> = []
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
  <span class="org-variable-name">x</span> = rng.poisson(s * np.exp(theta), size=n)
  thetahat.append(np.log(x.<span class="org-builtin">sum</span>()) - np.log(n) - np.log(s))
<span class="org-variable-name">thetahat</span> = np.array(thetahat)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.hist(thetahat, bins=16, density=<span class="org-constant">True</span>, color=<span class="org-string">'0.7'</span>)
<span class="org-variable-name">grid</span> = np.linspace(thetahat.<span class="org-builtin">min</span>(), thetahat.<span class="org-builtin">max</span>(), 1000)
plt.plot(grid, st.norm(loc=theta, scale=np.sqrt(1 / (np.exp(theta) * n * s))).pdf(grid), lw=1, c=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'Est ln mean gene expression'</span>)
plt.ylabel(<span class="org-string">'Density'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/analytic-se-log-link.png" alt="analytic-se-log-link.png">
</p>
</div>

<p>
After introducing multiplicative effects \(\vb_j\) for observed technical
covariates \(\vc_i\) into the measurement model
</p>

\begin{equation}
  x_{ij} \mid \xiplus, \vc_i, \vb_j, \theta_j \sim \Poi(\xiplus \exp(\vc_i' \vb_j + \theta_j)),
\end{equation}

<p>
the standard error of \(\hat\theta_j\) also depends on \(\vc_i'\vb_j\). In
contrast, if we assume the identity link
</p>

\begin{align}
  x_{ij} \mid \xiplus, \mu_j &\sim \Poi(\xiplus \mu_j)\\
  \ell \triangleq \sum_i \ln p(x_{ij} \mid \xiplus, \mu_j) &= \sum_i x_{ij} \ln(\xiplus \mu_j) - \xiplus \mu_j + \mathrm{const}\\
  \frac{\partial \ell}{\partial \mu_j} &= \sum_i \frac{x_{ij}}{\mu_j} - \xiplus\\
  \hat\mu_j &= \frac{\sum_i x_{ij}}{\sum_i \xiplus}\\
  \frac{\partial^2 \ell}{\partial \mu_j^2} &= -\sum_i \frac{x_{ij}}{\mu_j^2}\\
  \mathcal{I}(\mu_j) &= -\E\left[\frac{\partial^2 \ell}{\partial \mu_j^2}\right] = \frac{\E[\sum_i x_{ij}]}{\mu_j^2} = \frac{\sum_i \xiplus}{\mu_j}\\
  s_j^2 &= \frac{\mu_j}{\sum_i \xiplus},
\end{align}

<p>
where we have used the fact that \(\sum_i x_{ij} \sim \Poi(\mu_j \sum_i
   \xiplus)\). Surprisingly, \(\ln \hat\mu_j = \hat\theta_j\), the standard
error of \(\hat\mu_j\) increases as \(\mu_j\) increases, and the standard
error does not depend on technical covariates or their effects. As a sanity
check, plot the bootstrap distribution of \(\hat\mu_j\) against a normal
density with mean \(\theta_j\) and variance \(s_j^2\) for a simple
simulation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">rng</span> = np.random.default_rng(2)
<span class="org-variable-name">n_trials</span> = 1000
<span class="org-variable-name">n</span> = 100
<span class="org-variable-name">s</span> = 1e4
<span class="org-variable-name">log_mu</span> = -10
<span class="org-variable-name">muhat</span> = []
<span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
  <span class="org-variable-name">x</span> = rng.poisson(s * np.exp(log_mu), size=n)
  muhat.append(x.<span class="org-builtin">sum</span>() / (n * s))
<span class="org-variable-name">muhat</span> = np.array(muhat)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.hist(muhat, bins=14, density=<span class="org-constant">True</span>, color=<span class="org-string">'0.7'</span>)
<span class="org-variable-name">grid</span> = np.linspace(muhat.<span class="org-builtin">min</span>(), muhat.<span class="org-builtin">max</span>(), 1000)
plt.plot(grid, st.norm(loc=muhat.mean(), scale=np.sqrt(muhat[0] / (n * s))).pdf(grid), lw=1, c=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'Est mean gene expression'</span>)
plt.ylabel(<span class="org-string">'Density'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/analytic-se-identity-link.png" alt="analytic-se-identity-link.png">
</p>
</div>

<p>
With an analytic expression for \(s_j^2\), we can also derive a \(z\)-test
for DE, where
</p>

\begin{align}
  \frac{\hat\theta_{1j} - \hat\theta_{0j}}{\sqrt{s_{1j}^2 + s_{0j}^2}} \sim \N(0, 1)
\end{align}

<p>
under the null. However, one clear issue is that the estimator (8) is
biased, because
</p>

\begin{equation}
  \E[\ln \textstyle\sum_i x_{ij}] = \sum_{t=0}^{\infty} \ln(t) \Poi(t; \textstyle\sum_i \xiplus \exp(\theta_j)) = -\infty.
\end{equation}

<p>
This issue was previously noted (e.g., Lun 2018) via Taylor expansion
</p>

\begin{equation}
  \E[\ln x] \approx \ln \E[x] - \frac{\V[x]}{2 \E[x]^2},
\end{equation}

<p>
and demonstrates that the bias is worse for lower-expressed genes. To
illustrate the issue, plot the theoretical quantiles of the \(\N(\theta_j,
   s^2_j)\) distribution against the empirical quantiles of the (parametric,
oracle) bootstrap distribution of \(\hat\theta_j\).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">grid</span> = np.linspace(0, 1, thetahat.shape[0] + 1)[1:]
plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.xscale(<span class="org-string">'log'</span>)
plt.yscale(<span class="org-string">'log'</span>)
plt.plot(grid, st.norm(loc=theta, scale=np.sqrt(1 / (np.exp(theta) * n * s))).cdf(np.sort(thetahat)), lw=1, c=<span class="org-string">'k'</span>)
<span class="org-variable-name">lim</span> = [5e-7, 1]
plt.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
plt.xlim(lim)
plt.ylim(lim)
plt.xlabel(<span class="org-string">'Theoretical quantile'</span>)
plt.ylabel(<span class="org-string">'Empirical quantile'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/analytic-se-log-link-qq.png" alt="analytic-se-log-link-qq.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org618f456" class="outline-3">
<h3 id="org618f456">Variance of Gamma expression model</h3>
<div class="outline-text-3" id="text-org618f456">
<p>
Assuming a Gamma expression model
</p>

\begin{align}
  \lambda_{ij} &\sim \Gam(\phi_j^{-1}, \mu_j^{-1} \phi_j^{-1})\\
  \E[\ln \lambda_{ij}] &= \digamma(\phi_j^{-1}) + \ln(\mu_j \phi_j)\\
  \V[\ln \lambda_{ij}] &= \trigamma(\phi_j^{-1}),
\end{align}

<p>
where the Gamma distribution is parameterized by shape and rate,
\(\digamma(\cdot)\) denotes the digamma function, and \(\trigamma(\cdot)\)
denotes the trigamma function. We previously noted that robustly estimating
\(\phi_j\) is difficult, even from hundreds of cells per condition; despite
this difficulty, our method can still accurately estimate the variance of
true gene expression.
</p>
</div>
</div>

<div id="outline-container-orgdaf9c29" class="outline-3">
<h3 id="orgdaf9c29">Controlling FDR</h3>
<div class="outline-text-3" id="text-orgdaf9c29">
<p>
Given transformed data and standard errors, DE analysis is performed in two
steps:
</p>

<ol class="org-ol">
<li>Estimate the effect of the covariate of interest by GLS</li>
<li>Estimate moderated test statistics and \(p\)-values by EB treatment of
the standard errors from (1)</li>
<li>Control FDR by applying e.g., the BH procedure to the \(p\)-values from
(2)</li>
</ol>

<p>
<a href="https://arxiv.org/abs/1901.10679">Lu and Stephens 2019</a> describe a more
powerful approach to solve (3).
</p>
</div>
</div>

<div id="outline-container-orgc7d2b9a" class="outline-3">
<h3 id="orgc7d2b9a">Simulation</h3>
<div class="outline-text-3" id="text-orgc7d2b9a">
<p>
Implement a simplified
<a href="https://stephenslab.github.io/dsc-log-fold-change">DSC</a>.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org1888ed1"><span class="org-keyword">def</span> <span class="org-function-name">simulate_null</span>(dat, b=0, n_donors=1, n_cells=100, min_cells=1, seed=0):
  <span class="org-doc">"""Return AnnData object with simulated counts, and onehot matrix of labels</span>

<span class="org-doc">  Simulate data under the null by randomly assigning cells to donors. Simulate</span>
<span class="org-doc">  data with unequal sequencing depths (unequal total number of molecules</span>
<span class="org-doc">  observed) by subsequently applying binomial thinning (Gerard 2019) to *every*</span>
<span class="org-doc">  gene.</span>

<span class="org-doc">  dat - AnnData object</span>
<span class="org-doc">  b - log fold change in total number of molecules observed between groups</span>
<span class="org-doc">  n_donors - number of donors per group</span>
<span class="org-doc">  n_cells - number of cells per donor</span>
<span class="org-doc">  min_cells - minimum number of non-zero observations to retain genes</span>

<span class="org-doc">  """</span>
  <span class="org-keyword">assert</span> 2 * n_donors * n_cells &lt;= dat.shape[0]
  <span class="org-keyword">if</span> b &gt; 0:
    <span class="org-variable-name">b</span> = -b
  <span class="org-variable-name">query</span> = sc.pp.subsample(dat, n_obs=2 * n_donors * n_cells, random_state=seed, copy=<span class="org-constant">True</span>)
  sc.pp.filter_genes(query, min_cells=min_cells)
  <span class="org-variable-name">onehot</span> = ss.coo_matrix((np.ones(query.shape[0]), (np.arange(query.shape[0]), np.repeat(np.arange(2 * n_donors), n_cells)))).tocsr()
  <span class="org-keyword">if</span> np.isclose(b, 0):
    <span class="org-keyword">return</span> query, onehot
  <span class="org-keyword">else</span>:
    <span class="org-keyword">if</span> ss.isspmatrix(query.X):
      <span class="org-comment-delimiter"># </span><span class="org-comment">Important: keep this sparse to make downsampling non-zeros easier</span>
      <span class="org-variable-name">temp</span> = query.X[:n_donors * n_cells].astype(<span class="org-builtin">int</span>).tocsr()
      <span class="org-variable-name">y</span> = ss.csr_matrix((st.binom(n=temp.data, p=np.exp(b)).rvs().astype(<span class="org-builtin">float</span>), temp.indices, temp.indptr), shape=temp.shape)
      <span class="org-variable-name">x</span> = ss.vstack((y, query.X[n_donors * n_cells:]), <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
    <span class="org-keyword">else</span>:
      <span class="org-comment-delimiter"># </span><span class="org-comment">TODO: this breaks for n=0, but treating e.g. bulk RNA-seq counts as</span>
      <span class="org-comment-delimiter"># </span><span class="org-comment">sparse is *very* slow</span>
      <span class="org-variable-name">x</span> = st.binom(n=query.X.astype(<span class="org-builtin">int</span>), p=np.exp(b)).rvs().astype(<span class="org-builtin">float</span>)
    <span class="org-keyword">return</span> anndata.AnnData(x, obs=query.obs, var=query.var), onehot

<span class="org-keyword">def</span> <span class="org-function-name">simulate_effects_law_2014</span>(size, pi0=0.9):
  <span class="org-doc">"""Return effect sizes assumed by Law et al. 2014"""</span>
  <span class="org-variable-name">b</span> = np.zeros(size)
  <span class="org-variable-name">z</span> = np.random.uniform(size=size) &gt; pi0
  <span class="org-variable-name">s</span> = np.random.uniform(size=size) &gt; 0.5
  <span class="org-variable-name">b</span>[z &amp; s] = 2
  <span class="org-variable-name">b</span>[z &amp; ~s] = -2
  <span class="org-keyword">return</span> b

<span class="org-keyword">def</span> <span class="org-function-name">simulate_effects_pn</span>(size, pi0=0.9, scale=1):
  <span class="org-doc">"""Return effect sizes assuming a point-Normal distribution"""</span>
  <span class="org-variable-name">b</span> = np.zeros(size)
  <span class="org-variable-name">z</span> = np.random.uniform(size=size) &gt; pi0
  <span class="org-variable-name">b</span>[z] = st.norm(scale=scale).rvs(size=z.<span class="org-builtin">sum</span>())
  <span class="org-keyword">return</span> b

<span class="org-keyword">def</span> <span class="org-function-name">simulate_study</span>(dat, g, b=0, n_donors=1, n_cells=100, min_cells=10, seed=0):
  <span class="org-doc">"""Return AnnData object with simulated counts, onehot matrix, design matrix,</span>
<span class="org-doc">and true effect size vector</span>

<span class="org-doc">  Simulate non-null data assuming effect size distribution g by first</span>
<span class="org-doc">  simulating null data, then applying binomial thinning (Gerard 2019) to effect</span>
<span class="org-doc">  genes.</span>

<span class="org-doc">  dat - AnnData object</span>
<span class="org-doc">  g - function which returns array of effect sizes</span>
<span class="org-doc">  b - log fold change in total number of molecules observed between groups</span>
<span class="org-doc">  n_donors - number of donors per group</span>
<span class="org-doc">  n_cells - number of cells per donor</span>
<span class="org-doc">  min_cells - minimum number of non-zero observations to retain genes</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span> = simulate_null(dat, b=b, n_donors=n_donors, n_cells=n_cells, min_cells=min_cells, seed=seed)
  <span class="org-variable-name">lfc</span> = g(size=x.shape[1])
  <span class="org-keyword">if</span> ss.isspmatrix(x.X):
    <span class="org-comment-delimiter"># </span><span class="org-comment">Convert to CSC to deal with half the cells at a time</span>
    <span class="org-variable-name">y</span> = x.X.tocsc()
    <span class="org-variable-name">data</span> = y.data.copy()
    <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(y.shape[0]):
      <span class="org-keyword">if</span> lfc[i] &gt; 0:
        <span class="org-variable-name">idx</span> = y.indptr[i] + np.where(y.indices[y.indptr[i]:y.indptr[i+1]] &gt; n_donors * n_cells)[0]
        <span class="org-variable-name">data</span>[idx] = st.binom(n=y.data[idx].astype(<span class="org-builtin">int</span>), p=np.exp(-lfc[i])).rvs(size=<span class="org-builtin">len</span>(idx)).astype(<span class="org-builtin">float</span>)
      <span class="org-keyword">elif</span> lfc[i] &lt; 0:
        <span class="org-variable-name">idx</span> = y.indptr[i] + np.where(y.indices[y.indptr[i]:y.indptr[i+1]] &lt; n_donors * n_cells)[0]
        <span class="org-variable-name">data</span>[idx] = st.binom(n=y.data[idx].astype(<span class="org-builtin">int</span>), p=np.exp(lfc[i])).rvs(size=<span class="org-builtin">len</span>(idx)).astype(<span class="org-builtin">float</span>)
    <span class="org-variable-name">x</span> = anndata.AnnData(ss.csc_matrix((data, y.indices, y.indptr)), var=x.var, obs=x.obs)
  <span class="org-keyword">else</span>:
    <span class="org-variable-name">y</span> = x.X.copy()
    <span class="org-variable-name">query</span> = lfc &lt; 0
    <span class="org-variable-name">y</span>[n_donors * n_cells:,query] = st.binom(n=y[n_donors * n_cells,query].astype(<span class="org-builtin">int</span>), p=np.exp(lfc[query])).rvs()
    <span class="org-variable-name">y</span>[:n_donors * n_cells,~query] = st.binom(n=y[:n_donors * n_cells,~query].astype(<span class="org-builtin">int</span>), p=np.exp(lfc[~query])).rvs()
    <span class="org-variable-name">x</span> = annData.AnnData(y, var=x.var, obs=x.obs)
  <span class="org-keyword">if</span> n_donors &gt; 1:
    <span class="org-variable-name">design</span> = np.ones((2 * n_donors, 2))
    <span class="org-variable-name">design</span>[:n_donors,0] = 0
  <span class="org-keyword">else</span>:
    <span class="org-variable-name">design</span> = <span class="org-constant">None</span>
  <span class="org-keyword">return</span> x, onehot, design, lfc

<span class="org-keyword">def</span> <span class="org-function-name">estimate_limma_voom</span>(x, onehot, design=<span class="org-constant">None</span>, **kwargs):
  <span class="org-doc">"""Return MarrayLM object</span>

<span class="org-doc">  If design is None, assume rows of x are statistical units, and onehot[:,0]</span>
<span class="org-doc">  gives assignment of units to groups. Otherwise, assume onehot gives</span>
<span class="org-doc">  assignment of cells to donors, donors are statistical units, and design [:,0]</span>
<span class="org-doc">  gives the assignment of units to groups.</span>

<span class="org-doc">  x - count matrix (dense)</span>
<span class="org-doc">  onehot - mapping of cells to groups/donors (dense)</span>
<span class="org-doc">  design - design matrix for limma (dense)</span>

<span class="org-doc">  """</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: limma expects genes x samples</span>
  <span class="org-keyword">if</span> design <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">design</span> = np.vstack([onehot[:,0], np.ones(x.shape[0])]).T
    <span class="org-variable-name">y</span> = limma.voom(x.T, design)
  <span class="org-keyword">else</span>:
    <span class="org-variable-name">y</span> = limma.voom(x.T @ onehot, design)
  <span class="org-variable-name">fit</span> = limma.lmFit(y, design)
  <span class="org-keyword">return</span> fit

<span class="org-keyword">def</span> <span class="org-function-name">estimate_point</span>(x, onehot, **kwargs):
  <span class="org-doc">"""Return DataFrame of (bhat, se, p)</span>

<span class="org-doc">  Assume cells are units, and for each group estimate &#952;_j = log &#956;_j and its SE</span>
<span class="org-doc">  under a point mass expression model.</span>

<span class="org-doc">  x - count matrix (sparse)</span>
<span class="org-doc">  onehot - mapping of cells to groups (dense)</span>

<span class="org-doc">  """</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">Allow -inf</span>
  <span class="org-variable-name">theta</span> = np.log(onehot.T @ x) - np.log(onehot.T @ x.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>))
  <span class="org-keyword">if</span> ss.isspmatrix(theta):
    <span class="org-variable-name">theta</span> = theta.A
  <span class="org-variable-name">bhat</span> = theta[0] - theta[1]
  <span class="org-variable-name">V</span> = 1 / (onehot.T @ x)
  <span class="org-variable-name">se</span> = np.sqrt(V.<span class="org-builtin">sum</span>(axis=0))
  <span class="org-variable-name">z</span> = bhat / se
  <span class="org-variable-name">p</span> = st.norm().sf(<span class="org-builtin">abs</span>(z))
  <span class="org-keyword">return</span> pd.DataFrame({<span class="org-string">'bhat'</span>: bhat, <span class="org-string">'se'</span>: se, <span class="org-string">'p'</span>: p})

<span class="org-keyword">def</span> <span class="org-function-name">estimate_rqr</span>(x, onehot, **kwargs):
  <span class="org-doc">"""Return DataFrame of (bhat, se, p)</span>

<span class="org-doc">  Assume cells are units, estimate an expression model for each group, and then</span>
<span class="org-doc">  estimate randomized quantile residuals for each observation (Dunn and Smyth</span>
<span class="org-doc">  1996). Perform a z-test using the residuals as the data.</span>

<span class="org-doc">  This method is related to the sctransform method (Hafemeister and Satija</span>
<span class="org-doc">  2019), which uses Pearson residuals of a GLM. The advantage of using RQRs is</span>
<span class="org-doc">  that they can be computed for expression models which do not give rise to</span>
<span class="org-doc">  observation models which can be fit using GLMs (e.g., Gamma expression models</span>
<span class="org-doc">  with different variances per group).</span>

<span class="org-doc">  Dunn and Smyth, "Randomized Quantile Residuals". J Comput Graph Stat 1996.</span>
<span class="org-doc">  http://www.jstor.org/stable/1390802</span>

<span class="org-doc">  Hafemeister and Satija, "Normalization and variance stabilization of</span>
<span class="org-doc">  single-cell RNA-seq data using regularized negative binomial</span>
<span class="org-doc">  regression". Genome Biol 2020.</span>
<span class="org-doc">  https://genomebiology.biomedcentral.com/articles/10.1186/s13059-019-1874-1</span>

<span class="org-doc">  x - count matrix (dense)</span>
<span class="org-doc">  onehot - mapping of cells to groups (dense)</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = x.shape
  <span class="org-variable-name">_</span>, <span class="org-variable-name">m</span> = onehot.shape
  <span class="org-variable-name">s</span> = x.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
  <span class="org-comment-delimiter"># </span><span class="org-comment">TODO: don't fix expression model?</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">Heuristic: fix total number of updates</span>
  <span class="org-variable-name">num_epochs</span> = 6000 * 32 // x.shape[0]
  <span class="org-variable-name">log_mean</span>, <span class="org-variable-name">log_inv_disp</span>, <span class="org-variable-name">logodds</span> = mpebpm.ebpm_point_gamma(x, s, onehot=onehot, batch_size=32, num_epochs=num_epochs, shuffle=<span class="org-constant">True</span>)

  <span class="org-variable-name">n</span> = onehot @ np.exp(log_inv_disp)
  <span class="org-variable-name">p</span> = 1 / (1 + (s * (onehot @ np.exp(log_mean - log_inv_disp))))
  <span class="org-variable-name">pi0</span> = onehot @ sp.expit(logodds)
  <span class="org-variable-name">F</span> = st.nbinom(n, p).cdf(x - 1)
  <span class="org-variable-name">F</span> = np.where(x - 1 &gt;= 0, pi0 + (1 - pi0) * F, F)
  <span class="org-variable-name">f</span> = st.nbinom(n, p).pmf(x)
  <span class="org-variable-name">f</span> *= (1 - pi0)
  <span class="org-variable-name">f</span>[x == 0] += pi0[x == 0]
  <span class="org-variable-name">u</span> = np.random.uniform(size=F.shape)
  <span class="org-variable-name">rpp</span> = F + u * f
  <span class="org-variable-name">resid</span> = st.norm().ppf(rpp)

  <span class="org-variable-name">bhat</span> = np.diff((onehot.T @ resid) / (onehot.<span class="org-builtin">sum</span>(axis=0).reshape(-1, 1)), axis=0).ravel()
  <span class="org-variable-name">V</span> = 1 / (onehot.T @ x)
  <span class="org-variable-name">se</span> = np.sqrt(V.<span class="org-builtin">sum</span>(axis=0))
  <span class="org-variable-name">z</span> = bhat / se
  <span class="org-variable-name">p</span> = st.norm().sf(<span class="org-builtin">abs</span>(z))
  <span class="org-keyword">return</span> pd.DataFrame({<span class="org-string">'bhat'</span>: bhat, <span class="org-string">'se'</span>: se, <span class="org-string">'p'</span>: p})

<span class="org-keyword">def</span> <span class="org-function-name">estimate_wls_point</span>(x, onehot, design=<span class="org-constant">None</span>, **kwargs):
  <span class="org-doc">"""Return MarrayLM object</span>

<span class="org-doc">  Instead of voom, estimate &#952;_j = log &#956;_j under a point mass expression model</span>
<span class="org-doc">  and its sampling variance, and use those as input to WLS.</span>

<span class="org-doc">  If design is None, assume rows of x are statistical units, and onehot[:,0]</span>
<span class="org-doc">  gives assignment of units to groups. Otherwise, assume onehot gives</span>
<span class="org-doc">  assignment of cells to donors, donors are statistical units, and design [:,0]</span>
<span class="org-doc">  gives the assignment of units to groups.</span>

<span class="org-doc">  x - count matrix (dense)</span>
<span class="org-doc">  onehot - mapping of cells to groups/donors (dense)</span>
<span class="org-doc">  design - design matrix for limma (dense)</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">s</span> = x.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
  <span class="org-keyword">if</span> design <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">log_mean</span> = np.log(x + 1) - np.log(s)
    <span class="org-comment-delimiter"># </span><span class="org-comment">Important: this only reduces when there are no techncial covariates in</span>
    <span class="org-comment-delimiter"># </span><span class="org-comment">the measurement model</span>
    <span class="org-variable-name">w</span> = x
    <span class="org-variable-name">design</span> = np.vstack([onehot[:,0], np.ones(x.shape[0])]).T
  <span class="org-keyword">else</span>:
    <span class="org-variable-name">log_mean</span> = np.log(onehot.T @ x + 1) - np.log(onehot.T @ s)
    <span class="org-variable-name">w</span> = onehot.T @ x
  <span class="org-variable-name">fit</span> = limma.lm_series(log_mean.T, design=design, weights=w.T)
  <span class="org-keyword">return</span> fit

<span class="org-keyword">def</span> <span class="org-function-name">estimate_wls_gamma</span>(x, onehot, design, lr=1e-2, num_epochs=40, batch_size=64, shuffle=<span class="org-constant">True</span>, log_dir=<span class="org-constant">None</span>, **kwargs):
  <span class="org-doc">"""Return DataFrame of bhat, se</span>

<span class="org-doc">  Instead of voom, estimate E[log &#955;_{ij}] and V[log &#955;_{ij}] under a Gamma</span>
<span class="org-doc">  model, and use those as input to WLS.</span>

<span class="org-doc">  Assume donors are statistical units, onehot gives assignment of cells to</span>
<span class="org-doc">  donors, and design [:,0] gives the assignment of units to groups.</span>

<span class="org-doc">  """</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: this will be too slow on CPU</span>
  <span class="org-keyword">assert</span> torch.cuda.is_available()
  <span class="org-variable-name">s</span> = x.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
  <span class="org-variable-name">log_mean</span>, <span class="org-variable-name">log_inv_disp</span> = mpebpm.ebpm_gamma(
    x,
    s=s,
    onehot=onehot,
    lr=lr,
    num_epochs=num_epochs,
    batch_size=batch_size,
    shuffle=shuffle,
    log_dir=log_dir)
  <span class="org-comment-delimiter"># </span><span class="org-comment">[n_donors, n_genes]</span>
  <span class="org-variable-name">m</span> = sp.digamma(np.exp(log_inv_disp)) + log_mean - log_inv_disp
  <span class="org-variable-name">w</span> = 1 / sp.polygamma(1, np.exp(log_inv_disp))
  <span class="org-variable-name">fit</span> = limma.lm_series(m.T, design=design, weights=w.T)
  <span class="org-keyword">return</span> fit

<span class="org-keyword">def</span> <span class="org-function-name">estimate_moderated_t</span>(fit):
  <span class="org-variable-name">fit</span> = limma.eBayes(fit)
  <span class="org-keyword">return</span> fit.rx2(<span class="org-string">'p.value'</span>)[:,0]

<span class="org-keyword">def</span> <span class="org-function-name">estimate_z</span>(fit):
  <span class="org-variable-name">sf</span> = st.chi2(1).sf
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: this has estimates for the intercept also</span>
  <span class="org-variable-name">stat</span> = fit.rx2(<span class="org-string">'coefficients'</span>) / fit.rx2(<span class="org-string">'stdev.unscaled'</span>)
  <span class="org-variable-name">pval</span> = sf(np.square(stat))
  <span class="org-keyword">return</span> pval[:,0]

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_type1</span>(dat, b=0, alpha=0.01, n_cells=100, n_trials=1, min_cells=10):
  <span class="org-doc">"""Estimate Type 1 error to detect DE genes, treating cells as units.</span>

<span class="org-doc">  Use binomial thinning to simulate scenarios with unequal sequencing depth</span>
<span class="org-doc">  (total number of molecules observed).</span>

<span class="org-doc">  dat - AnnData object</span>
<span class="org-doc">  b - fold change in total observed molecules between groups</span>
<span class="org-doc">  alpha - significance level</span>
<span class="org-doc">  n_cells - number of cells per group</span>
<span class="org-doc">  n_trials - number of simulation trials</span>
<span class="org-doc">  min_cells - minimum number of non-zero observations to retain a gene</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
    <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span> = simulate_null(dat, b=b, n_donors=1, n_cells=n_cells, min_cells=min_cells, seed=i)
    <span class="org-keyword">if</span> ss.isspmatrix(x.X):
      <span class="org-variable-name">x</span> = x.X.A
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">x</span> = x.X
    <span class="org-variable-name">onehot</span> = onehot.A
    <span class="org-comment-delimiter"># </span><span class="org-comment">Heuristic: fix total number of updates</span>
    <span class="org-variable-name">num_epochs</span> = 6000 * 64 // x.shape[0]
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'limma_voom'</span>, <span class="org-string">'wls_point'</span>):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, batch_size=64, num_epochs=num_epochs)
      <span class="org-keyword">for</span> test <span class="org-keyword">in</span> (<span class="org-string">'moderated_t'</span>, <span class="org-string">'z'</span>):
        <span class="org-variable-name">pval</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{test}'</span>](fit)
        result.append((b, n_cells, method, test, i, (pval &lt; alpha).mean()))
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'point'</span>, <span class="org-string">'rqr'</span>):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, batch_size=64, num_epochs=num_epochs)
      result.append((b, n_cells, method, <span class="org-string">'z'</span>, i, (fit[<span class="org-string">'p'</span>] &lt; alpha).mean()))
  <span class="org-variable-name">result</span> = pd.DataFrame(result, columns=[<span class="org-string">'b'</span>, <span class="org-string">'n_cells'</span>, <span class="org-string">'method'</span>, <span class="org-string">'test'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'fdp'</span>])
  <span class="org-keyword">return</span> result

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_type1_by_donor</span>(dat, n_donors, b=0, alpha=0.01, n_cells=100, n_trials=1, min_cells=10):
  <span class="org-doc">"""Estimate Type 1 error to detect DE genes, treating donors as units.</span>

<span class="org-doc">  Use binomial thinning to simulate scenarios with unequal sequencing depth</span>
<span class="org-doc">  (total number of molecules observed).</span>

<span class="org-doc">  dat - AnnData object</span>
<span class="org-doc">  b - fold change in total observed molecules between groups</span>
<span class="org-doc">  n_donor - number of donors per group</span>
<span class="org-doc">  alpha - significance level</span>
<span class="org-doc">  n_cells - number of cells per group</span>
<span class="org-doc">  n_trials - number of simulation trials</span>
<span class="org-doc">  min_cells - minimum number of non-zero observations to retain a gene</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
    <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span> = simulate_null(dat, b=b, n_donors=n_donors, n_cells=n_cells, min_cells=min_cells, seed=i)
    <span class="org-keyword">if</span> ss.isspmatrix(x.X):
      <span class="org-variable-name">x</span> = x.X.A
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">x</span> = x.X
    <span class="org-variable-name">onehot</span> = onehot.A
    <span class="org-variable-name">design</span> = np.ones((2 * n_donors, 2))
    <span class="org-variable-name">design</span>[:n_donors,0] = 0
    <span class="org-comment-delimiter"># </span><span class="org-comment">Heuristic: fix total number of updates</span>
    <span class="org-variable-name">num_epochs</span> = 6000 * 64 // x.shape[0]
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'limma_voom'</span>, <span class="org-string">'wls_gamma'</span>, <span class="org-string">'wls_point'</span>):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, design=design, batch_size=64, num_epochs=num_epochs)
      <span class="org-keyword">for</span> test <span class="org-keyword">in</span> (<span class="org-string">'moderated_t'</span>, <span class="org-string">'z'</span>):
        <span class="org-variable-name">pval</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{test}'</span>](fit)
        result.append((b, n_cells, method, test, i, (pval &lt; alpha).mean()))
  <span class="org-variable-name">result</span> = pd.DataFrame(result, columns=[<span class="org-string">'b'</span>, <span class="org-string">'n_cells'</span>, <span class="org-string">'method'</span>, <span class="org-string">'test'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'fdp'</span>])
  <span class="org-keyword">return</span> result

<span class="org-keyword">def</span> <span class="org-function-name">estimate_fdr_bh</span>(fit):
  <span class="org-doc">"""Return vector of BH adjusted p-values"""</span>
  <span class="org-keyword">return</span> rpy2.robjects.r[<span class="org-string">'p.adjust'</span>](fit.rx2(<span class="org-string">'p.value'</span>)[:,0], method=<span class="org-string">'BH'</span>)

<span class="org-keyword">def</span> <span class="org-function-name">estimate_lfsr</span>(fit):
  <span class="org-doc">"""Return vector of lfsr</span>

<span class="org-doc">  Implement the pipeline of Liu and Stephens 2020</span>

<span class="org-doc">  https://arxiv.org/pdf/1901.10679</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">fit1</span> = ashr.ash(
    betahat=pd.Series(fit.rx2(<span class="org-string">'coefficients'</span>)[:,0]),
    sebetahat=pd.Series(np.sqrt(((fit.rx2(<span class="org-string">'df.total'</span>) - fit.rx2(<span class="org-string">'df.residual'</span>)) * fit.rx2(<span class="org-string">'s2.prior'</span>) + fit.rx2(<span class="org-string">'df.residual'</span>) * fit.rx2(<span class="org-string">'stdev.unscaled'</span>)[:,0]) / fit.rx2(<span class="org-string">'df.total'</span>))),
    df=fit.rx2(<span class="org-string">'df.total'</span>)[0],
    mixcompdist=<span class="org-string">'halfuniform'</span>)
  <span class="org-keyword">return</span> ashr.get_lfsr(fit1)

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_power</span>(dat, g, b=0, fdr=0.1, n_trials=1, n_cells=100, min_cells=10):
  <span class="org-doc">"""Evaluate power to detect DE genes, assuming effect size distribution g, at</span>
<span class="org-doc">specified FDR.</span>

<span class="org-doc">  dat - AnnData object</span>
<span class="org-doc">  g - function which returns array of effect sizes</span>
<span class="org-doc">  n_donors - number of donors per group</span>
<span class="org-doc">  b - log fold change in total number of molecules observed between groups</span>
<span class="org-doc">  fdr - False Discovery Rate</span>
<span class="org-doc">  n_trials - number of simulation trials</span>
<span class="org-doc">  n_cells - number of cells per donor</span>
<span class="org-doc">  min_cells - minimum number of non-zero observations to retain genes</span>

<span class="org-doc">  """</span>
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
    <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span>, <span class="org-variable-name">design</span>, <span class="org-variable-name">lfc</span> = simulate_study(dat, g, b=b, n_donors=1, n_cells=n_cells, min_cells=min_cells, seed=i)
    <span class="org-keyword">if</span> ss.isspmatrix(x.X):
      <span class="org-variable-name">x</span> = x.X.A
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">x</span> = x.X
    <span class="org-variable-name">onehot</span> = onehot.A
    <span class="org-comment-delimiter"># </span><span class="org-comment">Heuristic: fix total number of updates</span>
    <span class="org-variable-name">num_epochs</span> = 6000 * 64 // x.shape[0]
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'limma_voom'</span>, <span class="org-string">'wls_point'</span>):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, design=design, batch_size=64, num_epochs=num_epochs)
      <span class="org-comment-delimiter"># </span><span class="org-comment">Important: always use moderated t test</span>
      <span class="org-variable-name">fit</span> = limma.eBayes(fit)
      <span class="org-keyword">for</span> fdr_method <span class="org-keyword">in</span> (<span class="org-string">'fdr_bh'</span>, <span class="org-string">'lfsr'</span>):
        <span class="org-variable-name">score</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{fdr_method}'</span>](fit)
        <span class="org-variable-name">fdp</span> = ((score &lt; fdr) &amp; np.isclose(lfc, 0)).mean()
        <span class="org-variable-name">power</span> = (score[~np.isclose(lfc, 0)] &lt; fdr).mean()
        result.append((fdr, n_cells, method, fdr_method, i, fdp, power))
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'point'</span>, <span class="org-string">'rqr'</span>,):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, design=design, batch_size=64, num_epochs=num_epochs)
      <span class="org-variable-name">score</span> = rpy2.robjects.r[<span class="org-string">'p.adjust'</span>](fit[<span class="org-string">'p'</span>], method=<span class="org-string">'BH'</span>)
      <span class="org-variable-name">fdp</span> = ((score &lt; fdr) &amp; np.isclose(lfc, 0)).mean()
      <span class="org-variable-name">power</span> = (score[~np.isclose(lfc, 0)] &lt; fdr).mean()
      result.append((fdr, n_cells, method, <span class="org-string">'fdr_bh'</span>, i, fdp, power))
  <span class="org-variable-name">result</span> = pd.DataFrame(result, columns=[<span class="org-string">'fdr'</span>, <span class="org-string">'n_cells'</span>, <span class="org-string">'method'</span>, <span class="org-string">'fdr_method'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'fdp'</span>, <span class="org-string">'power'</span>])
  <span class="org-keyword">return</span> result

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_power_by_donor</span>(dat, g, n_donors, b=0, fdr=0.1, n_trials=1, n_cells=100, min_cells=10):
  <span class="org-doc">"""Evaluate power to detect DE genes, assuming effect size distribution g, at</span>
<span class="org-doc">specified FDR.</span>

<span class="org-doc">  dat - AnnData object</span>
<span class="org-doc">  g - function which returns array of effect sizes</span>
<span class="org-doc">  n_donors - number of donors per group</span>
<span class="org-doc">  b - log fold change in total number of molecules observed between groups</span>
<span class="org-doc">  fdr - False Discovery Rate</span>
<span class="org-doc">  n_trials - number of simulation trials</span>
<span class="org-doc">  n_cells - number of cells per donor</span>
<span class="org-doc">  min_cells - minimum number of non-zero observations to retain genes</span>

<span class="org-doc">  """</span>
  <span class="org-keyword">assert</span> n_donors &gt; 1
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
    <span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span>, <span class="org-variable-name">design</span>, <span class="org-variable-name">lfc</span> = simulate_study(dat, g, b=b, n_donors=n_donors, n_cells=n_cells, min_cells=min_cells, seed=i)
    <span class="org-keyword">if</span> ss.isspmatrix(x.X):
      <span class="org-variable-name">x</span> = x.X.A
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">x</span> = x.X
    <span class="org-variable-name">onehot</span> = onehot.A
    <span class="org-comment-delimiter"># </span><span class="org-comment">Heuristic: fix total number of updates</span>
    <span class="org-variable-name">num_epochs</span> = 6000 * 64 // x.shape[0]
    <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (<span class="org-string">'limma_voom'</span>, <span class="org-string">'wls_gamma'</span>, <span class="org-string">'wls_point'</span>):
      <span class="org-variable-name">fit</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{method}'</span>](x, onehot, design=design, batch_size=64, num_epochs=num_epochs)
      <span class="org-comment-delimiter"># </span><span class="org-comment">Important: always use moderated t test</span>
      <span class="org-variable-name">fit</span> = limma.eBayes(fit)
      <span class="org-keyword">for</span> fdr_method <span class="org-keyword">in</span> (<span class="org-string">'fdr_bh'</span>, <span class="org-string">'lfsr'</span>):
        <span class="org-variable-name">score</span> = <span class="org-builtin">globals</span>()[f<span class="org-string">'estimate_{fdr_method}'</span>](fit)
        <span class="org-variable-name">fdp</span> = ((score &lt; fdr) &amp; np.isclose(lfc, 0)).mean()
        <span class="org-variable-name">power</span> = (score[~np.isclose(lfc, 0)] &lt; fdr).mean()
        result.append((fdr, n_donors, n_cells, method, fdr_method, i, fdp, power))
  <span class="org-variable-name">result</span> = pd.DataFrame(result, columns=[<span class="org-string">'fdr'</span>, <span class="org-string">'n_donors'</span>, <span class="org-string">'n_cells'</span>, <span class="org-string">'method'</span>, <span class="org-string">'fdr_method'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'fdp'</span>, <span class="org-string">'power'</span>])
  <span class="org-keyword">return</span> result
</pre>
</div>

<p>
To generate null data, randomly sample cells from a homogeneous population,
and randomly assign labels. Use
<a href="https://support.10xgenomics.com/single-cell-gene-expression/datasets/3.0.0/pbmc_10k_v3">10X
v3 PBMC data</a>, which has more molecules observed per sample on average.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/modes/10k_pbmc_v3.h5ad'</span>)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org9652fb0" class="outline-2">
<h2 id="org9652fb0">Results</h2>
<div class="outline-text-2" id="text-org9652fb0">
</div>
<div id="outline-container-orga144bdf" class="outline-3">
<h3 id="orga144bdf">Accuracy of estimation</h3>
<div class="outline-text-3" id="text-orga144bdf">
<p>
We previously evaluated <code>mpebpm</code> <a href="mpebpm.html#accuracy">by simulating
from a point-Gamma expression model</a>. Now, simulate from a Gamma model, and
evaluate the accuracy of estimating \(\E[\ln\lambda_{ij}]\) and
\(\V[\ln\lambda_{ij}]\).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">evaluate</span>(num_samples, num_mols, num_trials=10, **kwargs):
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: generate all of the samples for each trial in one shot, and use</span>
  <span class="org-comment-delimiter"># </span><span class="org-comment">one-hot encoding to get separate estimates</span>
  <span class="org-variable-name">args</span> = [(num_samples * num_trials, num_mols, log_mu, log_phi, -1000, <span class="org-constant">None</span>, <span class="org-constant">None</span>, <span class="org-constant">None</span>)
          <span class="org-keyword">for</span> log_mu <span class="org-keyword">in</span> np.linspace(-12, -6, 7)
          <span class="org-keyword">for</span> log_phi <span class="org-keyword">in</span> np.linspace(-4, 0, 5)]
  <span class="org-variable-name">x</span> = np.concatenate([scqtl.simulation.simulate(*a)[0][:,:1] <span class="org-keyword">for</span> a <span class="org-keyword">in</span> args], axis=1)
  <span class="org-variable-name">x</span> = ss.csr_matrix(x)
  <span class="org-variable-name">s</span> = num_mols * np.ones((x.shape[0], 1))
  <span class="org-variable-name">onehot</span> = np.zeros((num_samples * num_trials, num_trials))
  onehot[np.arange(onehot.shape[0]), np.arange(onehot.shape[0]) // num_samples] = 1
  <span class="org-variable-name">onehot</span> = ss.csr_matrix(onehot)

  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: this is analytic</span>
  <span class="org-variable-name">theta</span> = mpebpm.sgd.ebpm_point(x.A, s=s, onehot=onehot.A)
  <span class="org-variable-name">log_mu</span>, <span class="org-variable-name">neg_log_phi</span> = mpebpm.sgd.ebpm_gamma(x, s=s, onehot=onehot, **kwargs)
  <span class="org-variable-name">result</span> = pd.DataFrame(
    [(a[0] // num_trials, <span class="org-builtin">int</span>(a[1]), <span class="org-builtin">int</span>(a[2]), <span class="org-builtin">int</span>(a[3]), <span class="org-builtin">int</span>(a[4]), a[-1], trial)
     <span class="org-keyword">for</span> a <span class="org-keyword">in</span> args
     <span class="org-keyword">for</span> trial <span class="org-keyword">in</span> <span class="org-builtin">range</span>(num_trials)],
    columns=[<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>, <span class="org-string">'log_mu'</span>, <span class="org-string">'log_phi'</span>, <span class="org-string">'logodds'</span>, <span class="org-string">'fold'</span>, <span class="org-string">'trial'</span>])
  <span class="org-variable-name">result</span>[<span class="org-string">'theta_hat'</span>] = theta.ravel(order=<span class="org-string">'F'</span>)
  <span class="org-variable-name">result</span>[<span class="org-string">'log_mu_hat'</span>] = log_mu.ravel(order=<span class="org-string">'F'</span>)
  <span class="org-variable-name">result</span>[<span class="org-string">'log_phi_hat'</span>] = -neg_log_phi.ravel(order=<span class="org-string">'F'</span>)
  <span class="org-comment-delimiter"># </span><span class="org-comment">Important: sign flipped in scqtl.simulation.simulate</span>
  <span class="org-variable-name">result</span>[<span class="org-string">'mean_log'</span>] = sp.digamma(np.exp(-query[<span class="org-string">'log_phi'</span>])) + query[<span class="org-string">'log_mu'</span>] + query[<span class="org-string">'log_phi'</span>]
  <span class="org-variable-name">result</span>[<span class="org-string">'var_log'</span>] = sp.polygamma(1, np.exp(-result[<span class="org-string">'log_phi'</span>]))
  <span class="org-variable-name">result</span>[<span class="org-string">'mean_log_hat'</span>] = sp.digamma(np.exp(-result[<span class="org-string">'log_phi_hat'</span>])) + result[<span class="org-string">'log_mu_hat'</span>] + result[<span class="org-string">'log_phi_hat'</span>]
  <span class="org-variable-name">result</span>[<span class="org-string">'var_log_hat'</span>] = sp.polygamma(1, np.exp(-result[<span class="org-string">'log_phi_hat'</span>]))
  <span class="org-keyword">return</span> result
</pre>
</div>

<p>
Run the simulation.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = [evaluate(num_samples=num_samples,
                   num_mols=num_mols,
                   batch_size=32,
                   num_epochs=num_epochs,
                   log_dir=f<span class="org-string">'runs/mpebpm/gamma-sim-{num_mols}-{num_samples}/'</span>)
          <span class="org-keyword">for</span> num_mols <span class="org-keyword">in</span> (10000, 100000)
          <span class="org-comment-delimiter"># </span><span class="org-comment">Important: for fixed batch size, having more samples means more</span>
          <span class="org-comment-delimiter"># </span><span class="org-comment">updates to each parameter per epoch</span>
          <span class="org-keyword">for</span> num_samples, num_epochs <span class="org-keyword">in</span> <span class="org-builtin">zip</span>((100, 1000), (400, 40))]
pd.concat(result).to_csv(<span class="org-string">'/scratch/midway2/aksarkar/ideas/mpebpm-gamma-sim.txt.gz'</span>, sep=<span class="org-string">'\t'</span>)
</pre>
</div>

<p>
Read the results.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = pd.read_csv(<span class="org-string">'/scratch/midway2/aksarkar/ideas/mpebpm-gamma-sim.txt.gz'</span>, sep=<span class="org-string">'\t'</span>, index_col=0)
</pre>
</div>

<p>
Compare the estimated \(\E[\ln\lambda_{ij}]\) to the ground truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4.5, 4.5)
<span class="org-variable-name">lim</span> = [-20, -5]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), result.groupby([<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>])):
  a.scatter(sp.digamma(np.exp(-g[<span class="org-string">'log_phi'</span>])) + g[<span class="org-string">'log_mu'</span>] + g[<span class="org-string">'log_phi'</span>],
            sp.digamma(np.exp(-g[<span class="org-string">'log_phi_hat'</span>])) + g[<span class="org-string">'log_mu_hat'</span>] + g[<span class="org-string">'log_phi_hat'</span>], s=1, c=<span class="org-string">'k'</span>, alpha=0.3)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(f<span class="org-string">'$n$={k[0]}, $s$={k[1]}'</span>)
  a.set_xlabel(<span class="org-string">'True $\mathrm{E}[\ln\ \lambda]$'</span>)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a[0].set_ylabel(<span class="org-string">'Estimated $\mathrm{E}[\ln\ \lambda]$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-mean-log.png" alt="sim-mean-log.png">
</p>
</div>

<p>
Estimate \(\E[\ln\lambda_{ij}]\) under a point mass expression model, and
compare to the ground truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4.5, 4.5)
<span class="org-variable-name">lim</span> = [-15, -5]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), result.groupby([<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>])):
  a.scatter(sp.digamma(np.exp(-g[<span class="org-string">'log_phi'</span>])) + g[<span class="org-string">'log_mu'</span>] + g[<span class="org-string">'log_phi'</span>], g[<span class="org-string">'theta_hat'</span>], s=1, c=<span class="org-string">'k'</span>, alpha=0.3)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(f<span class="org-string">'$n$={k[0]}, $s$={k[1]}'</span>)
  a.set_xlabel(<span class="org-string">'True $\mathrm{E}[\ln\ \lambda]$'</span>)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a[0].set_ylabel(<span class="org-string">'Estimated $\mathrm{E}[\ln\ \lambda]$'</span>)
fig.tight_layout()

</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-gam-vs-point.png" alt="sim-gam-vs-point.png">
</p>
</div>

<p>
Compare the estimated \(\V[\ln\lambda_{ij}]\) to the ground truth.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4.5, 4.5)
<span class="org-variable-name">lim</span> = [1e-4, 1e2]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), result.groupby([<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>])):
  <span class="org-variable-name">query</span> = g
  a.set_xscale(<span class="org-string">'log'</span>)
  a.set_yscale(<span class="org-string">'log'</span>)
  a.scatter(query[<span class="org-string">'var_log'</span>], query[<span class="org-string">'var_log_hat'</span>], s=1, c=<span class="org-string">'k'</span>, alpha=0.2)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(f<span class="org-string">'$n$={k[0]}, $s$={k[1]}'</span>)
  a.set_xlabel(<span class="org-string">'True $\mathrm{V}[\ln\ \lambda]$'</span>)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a[0].set_ylabel(<span class="org-string">'Estimated $\mathrm{V}[\ln\ \lambda]$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-var-log.png" alt="sim-var-log.png">
</p>
</div>

<p>
Compare the estimated \(\V[\ln\lambda_{ij}]\) to the ground truth,
restricting to genes with \(\ln\mu > -11\).
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 2, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4.5, 4.5)
<span class="org-variable-name">lim</span> = [1e-4, 1e2]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax.ravel(), result.groupby([<span class="org-string">'num_samples'</span>, <span class="org-string">'num_mols'</span>])):
  <span class="org-variable-name">query</span> = g[g[<span class="org-string">'log_mu'</span>] &gt; -10]
  a.set_xscale(<span class="org-string">'log'</span>)
  a.set_yscale(<span class="org-string">'log'</span>)
  a.scatter(query[<span class="org-string">'var_log'</span>], query[<span class="org-string">'var_log_hat'</span>], s=1, c=<span class="org-string">'k'</span>, alpha=0.2)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(f<span class="org-string">'$n$={k[0]}, $s$={k[1]}'</span>)
  a.set_xlabel(<span class="org-string">'True $\mathrm{V}[\ln\ \lambda]$'</span>)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a[0].set_ylabel(<span class="org-string">'Estimated $\mathrm{V}[\ln\ \lambda]$'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-var-log-mu-pass.png" alt="sim-var-log-mu-pass.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org1638472" class="outline-3">
<h3 id="org1638472">Estimation of true effect size distribution</h3>
<div class="outline-text-3" id="text-org1638472">
<p>
To estimate power controlling FDR, we need to make an assumption about the
true distribution of effect sizes. We will make a data-driven assumption by
estimating the true distribution of effect sizes, given observed effect
sizes and standard errors output by limma-voom on a constructed problem
using <code>ashr</code>.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way.h5ad'</span>)
</pre>
</div>

<p>
Construct a problem comparing B cells to cytotoxic T cells. Randomly assign
50 sorted cells to each of 128 donors within each cell type.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x1</span>, <span class="org-variable-name">onehot1</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=128, n_cells=50, min_counts=1, to_array=<span class="org-constant">False</span>)
<span class="org-variable-name">x2</span>, <span class="org-variable-name">onehot2</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'cytotoxic_t'</span>], n_donors=128, n_cells=50, min_counts=1, to_array=<span class="org-constant">False</span>)
<span class="org-variable-name">mix</span> = x1.concatenate(x2)
sc.pp.filter_genes(mix, min_counts=10)
<span class="org-variable-name">onehot</span> = ss.block_diag([onehot1, onehot2], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">design</span> = np.ones((256, 2))
<span class="org-variable-name">design</span>[:128,0] = 0
</pre>
</div>

<p>
Fit <code>limma-voom</code>, followed by EB shrinkage of standard errors.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit0</span> = limma.eBayes(estimate_limma_voom(mix.X.A, onehot, design))
</pre>
</div>

<p>
Fit <code>ashr</code>, using the moderated standard errors and degrees of freedom.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">ashr</span> = rpy2.robjects.packages.importr(<span class="org-string">'ashr'</span>)
<span class="org-variable-name">fit1</span> = ashr.ash(
  betahat=pd.Series(fit0.rx2(<span class="org-string">'coefficients'</span>)[:,0]),
  sebetahat=pd.Series(np.sqrt((fit0.rx2(<span class="org-string">"df.prior"</span>) * fit0.rx2(<span class="org-string">"s2.prior"</span>) + fit0.rx2(<span class="org-string">"df.residual"</span>) * fit0.rx2(<span class="org-string">"stdev.unscaled"</span>)[:,0]) / fit0.rx2(<span class="org-string">"df.total"</span>))),
  df=fit0.rx2(<span class="org-string">'df.total'</span>)[0],
  mixcompdist=<span class="org-string">'halfuniform'</span>)
</pre>
</div>

<p>
Look at the fitted prior distribution of true effects. Find an analytic
distribution whose tail behavior is close enough.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Paired'</span>)
<span class="org-variable-name">grid</span> = np.linspace(-3, 3, 1000)
<span class="org-variable-name">F</span> = ashr.cdf_ash(fit1, grid).rx2(<span class="org-string">'y'</span>).ravel()
<span class="org-variable-name">F2</span> = st.t(scale=0.1, df=1).cdf(grid)
plt.clf()
plt.gcf().set_size_inches(4.5, 2.5)
plt.plot(grid, F, lw=1, c=cm(0), label=<span class="org-string">'ashr'</span>)
plt.plot(grid, F2, lw=1, c=cm(1), label=f<span class="org-string">'$t_1(0, 0.1^2)$'</span>)
plt.axvline(x=0, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'0.5'</span>)
plt.legend(frameon=<span class="org-constant">False</span>)
plt.xlabel(<span class="org-string">'Prior effect size'</span>)
plt.ylabel(<span class="org-string">'CDF'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/b_cells-cytotoxic_t-fitted_g.png" alt="b_cells-cytotoxic_t-fitted_g.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org403ef73" class="outline-3">
<h3 id="org403ef73">Simulation sanity check</h3>
<div class="outline-text-3" id="text-org403ef73">
<p>
As a sanity check, use bulk RNA-seq data from GTEx v6 lung.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.AnnData(rpy2.robjects.r[<span class="org-string">'readRDS'</span>](<span class="org-string">'/project2/gilad/joycehsiao/dsc-log-fold-change/dsc/data/gtex_lung.rds'</span>).T)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">n_donors</span> = 4
<span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span> = simulate_null(dat, n_donors=2 * n_donors, n_cells=1, to_dense=<span class="org-constant">True</span>, min_counts=2000, seed=1)
<span class="org-variable-name">design</span> = np.ones((2 * n_donors, 2))
<span class="org-variable-name">design</span>[:n_donors,0] = 0
(estimate_moderated_t(estimate_limma_voom(x, onehot, design)) &lt; 0.01).mean()
</pre>
</div>

<pre class="example">
0.005917682388270624

</pre>

<div class="org-src-container">
<pre class="src src-ipython">np.random.seed(3)
<span class="org-variable-name">pi0</span> = 0.9
<span class="org-variable-name">z</span> = np.random.uniform(size=x.shape[1]) &gt; pi0
<span class="org-variable-name">s</span> = np.random.uniform(size=x.shape[1]) &gt; 0.5
<span class="org-variable-name">x1</span> = x[:n_donors].copy()
<span class="org-variable-name">x1</span>[:,z &amp; s] = st.binom(n=x1[:,z &amp; s].astype(<span class="org-builtin">int</span>), p=0.5).rvs()
<span class="org-variable-name">x2</span> = x[n_donors:].copy()
<span class="org-variable-name">x2</span>[:,z &amp; ~s] = st.binom(n=x2[:,z &amp; ~s].astype(<span class="org-builtin">int</span>), p=0.5).rvs()
<span class="org-variable-name">y</span> = np.vstack([x1, x2])
<span class="org-variable-name">fit</span> = estimate_limma_voom(y, onehot, design)
<span class="org-variable-name">fit</span> = limma.eBayes(fit)
<span class="org-variable-name">score</span> = estimate_fdr_bh(fit)
(score[z] &lt; 0.1).mean(), (score[~z] &lt; 0.1).mean()
</pre>
</div>

<pre class="example">
(0.33662477558348297, 0.0025470219435736676)

</pre>
</div>
</div>

<div id="outline-container-org05839be" class="outline-3">
<h3 id="org05839be">Type 1 error rate (single cells as units)</h3>
<div class="outline-text-3" id="text-org05839be">
<p>
Simulate null data, varying the number of cells per group.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = pd.concat(
  evaluate_type1(dat, n_cells=n_cells, min_cells=n_cells, n_trials=50)
  <span class="org-keyword">for</span> n_cells <span class="org-keyword">in</span> (10, 100, 1000))
</pre>
</div>

<p>
Plot the distribution of Type 1 errors in each trial.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 3)
fig.set_size_inches(5.5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'PM-Z'</span>, <span class="org-string">'SE-EB'</span>, <span class="org-string">'SE-Z'</span>]
<span class="org-keyword">for</span> a, (t, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax, result.groupby(<span class="org-string">'n_cells'</span>)):
  a.boxplot(g.pivot_table(columns=<span class="org-string">'trial'</span>, index=[<span class="org-string">'method'</span>, <span class="org-string">'test'</span>], values=<span class="org-string">'fdp'</span>), widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
  a.axhline(y=0.01, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
  a.set_xticklabels(labels, rotation=90)
  a.set_xlabel(<span class="org-string">'Method'</span>)
  a.set_title(f<span class="org-string">'$n$={t}'</span>)
ax[0].set_ylabel(<span class="org-string">'Type 1 error rate'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/fpr.png" alt="fpr.png">
</p>
</div>

<p>
To generate null data with systematic differences in sequencing depth,
follow the scheme above, then apply binomial thinning with \(p = 0.5\) to
every gene.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = <span class="org-builtin">dict</span>()
<span class="org-keyword">for</span> n_cells <span class="org-keyword">in</span> (25, 50, 100):
  <span class="org-variable-name">result</span>[n_cells] = evaluate_type1(dat, b=np.log(2), n_cells=n_cells, min_cells=n_cells, n_trials=50)
<span class="org-variable-name">result</span> = pd.concat(result).reset_index(drop=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 3)
fig.set_size_inches(5.5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'PM-Z'</span>, <span class="org-string">'SE-EB'</span>, <span class="org-string">'SE-Z'</span>]
<span class="org-keyword">for</span> a, (t, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax, result.groupby(<span class="org-string">'n_cells'</span>)):
  a.boxplot(g.pivot_table(columns=<span class="org-string">'trial'</span>, index=[<span class="org-string">'method'</span>, <span class="org-string">'test'</span>], values=<span class="org-string">'fdp'</span>), widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
  a.axhline(y=0.01, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
  a.set_xticklabels(labels, rotation=90)
  a.set_xlabel(<span class="org-string">'Method'</span>)
  a.set_title(f<span class="org-string">'$n$={t}'</span>)
ax[0].set_ylabel(<span class="org-string">'Type 1 error rate'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/fpr-unequal-s.png" alt="fpr-unequal-s.png">
</p>
</div>

<p>
As an alternative view, fix the number of cells \(n=100\) and vary the
difference in sequencing depth.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = pd.concat(
  evaluate_type1(dat, b=b, n_cells=100, min_cells=100, n_trials=50)
  <span class="org-keyword">for</span> b <span class="org-keyword">in</span> np.log(np.linspace(1, 2, 4))
)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 4)
fig.set_size_inches(6.5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'PM-Z'</span>, <span class="org-string">'SE-EB'</span>, <span class="org-string">'SE-Z'</span>]
<span class="org-keyword">for</span> a, (b, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax, result.groupby(<span class="org-string">'b'</span>)):
  a.boxplot(g.pivot_table(columns=<span class="org-string">'trial'</span>, index=[<span class="org-string">'method'</span>, <span class="org-string">'test'</span>], values=<span class="org-string">'fdp'</span>), widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
  a.axhline(y=0.01, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
  a.set_xticklabels(labels, rotation=90)
  a.set_xlabel(<span class="org-string">'Method'</span>)
  a.set_title(f<span class="org-string">'$b$={np.exp(b):.2g}'</span>)
ax[0].set_ylabel(<span class="org-string">'Type 1 error rate'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/fpr-vs-b.png" alt="fpr-vs-b.png">
</p>
</div>
</div>

<div id="outline-container-org6116287" class="outline-4">
<h4 id="org6116287">Unequal size factors</h4>
<div class="outline-text-4" id="text-org6116287">
<p>
To generate single cells with unequal size factors, combine simulated
doublets from sorted cells in one group.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">dat</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way.h5ad'</span>)
<span class="org-variable-name">n_cells</span> = 100
<span class="org-variable-name">x1</span>, <span class="org-variable-name">onehot1</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=1, n_cells=n_cells, min_counts=0, to_dense=<span class="org-constant">False</span>)
<span class="org-variable-name">x2</span>, <span class="org-variable-name">onehot2</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=n_cells, n_cells=2, min_counts=0, to_dense=<span class="org-constant">False</span>)
<span class="org-variable-name">mix</span> = ss.vstack([x1, onehot2.T @ x2], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">mix</span> = anndata.AnnData(mix)
<span class="org-comment-delimiter"># </span><span class="org-comment">Estimate the global mean for filtering genes</span>
<span class="org-variable-name">thetahat</span> = np.log(mix.X.A.<span class="org-builtin">sum</span>(axis=0) + 1) - np.log(mix.X.<span class="org-builtin">sum</span>())
<span class="org-variable-name">onehot</span> = ss.block_diag([onehot1, np.ones((100, 1))], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
</pre>
</div>

<p>
0 - 06711880-dce2-448e-9b52-b1b94f6d7c9e
</p>

<p>
Fit <code>limma-voom</code>, followed by EB shrinkage of standard errors. Report the
number of false positives (\(\alpha < 0.01\)), and the number of genes
tested.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">query</span> = thetahat &gt; -11
(estimate_moderated_t(estimate_limma_voom(mix[:,query].X.A, onehot.A)) &lt; 0.01).mean(), query.<span class="org-builtin">sum</span>()
</pre>
</div>

<pre class="example">
(0.9590070598952403, 4391)

</pre>

<p>
Repeat the analysis for a larger number of cells.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">n_cells</span> = 1000
<span class="org-variable-name">x1</span>, <span class="org-variable-name">onehot1</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=1, n_cells=n_cells, min_counts=0, to_dense=<span class="org-constant">False</span>, seed=1)
<span class="org-variable-name">x2</span>, <span class="org-variable-name">onehot2</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=n_cells, n_cells=2, min_counts=0, to_dense=<span class="org-constant">False</span>, seed=2)
<span class="org-variable-name">mix</span> = ss.vstack([x1, onehot2.T @ x2], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">mix</span> = anndata.AnnData(mix)
<span class="org-comment-delimiter"># </span><span class="org-comment">Estimate the global mean for filtering genes</span>
<span class="org-variable-name">thetahat</span> = np.log(mix.X.A.<span class="org-builtin">sum</span>(axis=0) + 1) - np.log(mix.X.<span class="org-builtin">sum</span>())
<span class="org-variable-name">onehot</span> = ss.block_diag([onehot1, np.ones((n_cells, 1))], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">query</span> = thetahat &gt; -11
(estimate_moderated_t(estimate_limma_voom(mix[:,query].X.A, onehot.A)) &lt; 0.01).mean(), query.<span class="org-builtin">sum</span>()
</pre>
</div>

<pre class="example">
(0.9706529713866471, 4089)

</pre>

<p>
Fit a point mass expression model to each group.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">theta</span> = np.log(onehot.T @ mix.X[:,query].A + 1) - np.log(onehot.T @ mix.X.<span class="org-builtin">sum</span>(axis=1)).A
</pre>
</div>

<p>
Fit a Gamma expression model to each group.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">log_mu</span>, <span class="org-variable-name">neg_log_phi</span> = mpebpm.sgd.ebpm_gamma(
  mix.X[:,query].A,
  s=mix.X.<span class="org-builtin">sum</span>(axis=1).A,
  onehot=onehot.A,
  batch_size=32,
  num_epochs=1000,
  log_dir=<span class="org-string">'runs/mpebpm/b_cells-sim-unequal-s'</span>)
</pre>
</div>

<p>
Compare the estimated mean log expression for each gene under the Gamma
model to the estimate under the point mass model.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 2, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(4, 2.5)
<span class="org-variable-name">lim</span> = [-12, -2]
<span class="org-keyword">for</span> a, y, t <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax, [theta.A, log_mu], [<span class="org-string">'Point mass'</span>, <span class="org-string">'Gamma'</span>]):
  a.scatter(y[0], y[1], c=<span class="org-string">'k'</span>, s=1, alpha=0.1)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
  a.set_title(t)
  a.set_xlabel(<span class="org-string">'$\mathrm{E}[\ln\ \lambda]$ (size $s$)'</span>)
ax[0].set_ylabel(<span class="org-string">'$\mathrm{E}[\ln\ \lambda]$ (size $2s$)'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/b_cells-sim-unequal-s.png" alt="b_cells-sim-unequal-s.png">
</p>
</div>

<p>
The problem seems to be that in <code>limma</code>, observed \(x_{ij} = 0\) are
treated as having \(\ln\lambda_{ij} = -\ln\xiplus\). This treatment makes
sense, because observing a zero is strong information that true gene
expression is not bigger than \(1 / \xiplus\); however, it is clear that
with double \(\xiplus\), observing a zero further bounds true gene
expression. Therefore, <code>limma</code> is expected to identify all genes as
&ldquo;differentially expressed&rdquo; in this scenario. This problem cannot be solved
by using the posterior mean of gene expression under e.g., Gamma models for
each group instead, because the posterior mean is
</p>

\begin{equation}
  \E[\ln\lambda_{ij} \mid x_{ij}, \xiplus, g_{jk}] = \psi(x_{ij} + \phi_{jk}^{-1}) + \ln(\xiplus + \mu_{jk}^{-1}\phi_{jk}^{-1}),
\end{equation}

<p>
and we have shown empirically that the prior means are equal. Therefore, it
will still be the case that the posterior means for observed zeros will be
systematically different between two groups with systematically different
size factors. Suppose instead we use the estimate \(\hat\theta_{jk}\) under
a point mass model and its estimated standard error to compute a
\(z\)-score.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-comment-delimiter"># </span><span class="org-comment">Important: this only reduces when there is no design matrix</span>
<span class="org-variable-name">s2</span> = 1 / (onehot.T @ mix.X[:,query].A)
<span class="org-variable-name">z</span> = (theta[0].ravel() - theta[1].ravel()) / np.sqrt(s2.<span class="org-builtin">sum</span>(axis=0))
(st.norm().sf(<span class="org-builtin">abs</span>(z)) &lt; 0.01).mean()
</pre>
</div>

<pre class="example">
0.016385424309122036

</pre>

<p>
Plot the distribution of \(z\)-scores in this simulation against a standard
normal density (to make sure we don&rsquo;t need to use a \(t\) distribution
instead).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">grid</span> = np.linspace(-4, 4, 1000)
plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.hist(z, bins=11, color=<span class="org-string">'0.7'</span>, density=<span class="org-constant">True</span>)
plt.plot(grid, st.norm().pdf(grid), lw=1, c=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'$z$-score'</span>)
plt.ylabel(<span class="org-string">'Density'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/b_cells-sim-unequal-s-dist.png" alt="b_cells-sim-unequal-s-dist.png">
</p>
</div>
</div>
</div>

<div id="outline-container-orgd9329ed" class="outline-4">
<h4 id="orgd9329ed">Anti-conservative \(z\)-test</h4>
<div class="outline-text-4" id="text-orgd9329ed">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span>, <span class="org-variable-name">onehot</span> = simulate_null(dat, n_donors=1, n_cells=100, min_cells=100, seed=3)
<span class="org-variable-name">y</span> = x.X.A.copy()
<span class="org-comment-delimiter"># </span><span class="org-comment">for j in range(y.shape[1]):</span>
<span class="org-comment-delimiter">#   </span><span class="org-comment">temp = y[:,j].copy()</span>
<span class="org-comment-delimiter">#   </span><span class="org-comment">np.random.shuffle(temp)</span>
<span class="org-comment-delimiter">#   </span><span class="org-comment">y[:,j] = temp</span>
<span class="org-variable-name">theta</span> = np.log(onehot.T @ y) - np.log(onehot.T @ y.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>))
<span class="org-variable-name">bhat</span> = theta[0] - theta[1]
<span class="org-variable-name">V</span> = 1 / (onehot.T @ y)
<span class="org-variable-name">se</span> = np.sqrt(V.<span class="org-builtin">sum</span>(axis=0))
<span class="org-variable-name">z</span> = bhat / se
<span class="org-variable-name">p</span> = st.norm().sf(<span class="org-builtin">abs</span>(z))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">grid</span> = np.linspace(-5, 5, 1000)
plt.clf()
plt.gcf().set_size_inches(3, 3)
plt.hist(bhat / se, bins=21, density=<span class="org-constant">True</span>, color=<span class="org-string">'0.7'</span>)
plt.plot(grid, st.norm().pdf(grid), lw=1, c=<span class="org-string">'k'</span>)
plt.xlabel(<span class="org-string">'$z$-score'</span>)
plt.ylabel(<span class="org-string">'Density'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/point-example-hist.png" alt="point-example-hist.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">lim</span> = [1e-4, 1]
<span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
plt.clf()
plt.gcf().set_size_inches(3, 3)
plt.xscale(<span class="org-string">'log'</span>)
plt.yscale(<span class="org-string">'log'</span>)
<span class="org-keyword">for</span> i, (F, label) <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(<span class="org-builtin">zip</span>([st.norm()], [<span class="org-string">'N(0, 1)'</span>])):
  plt.plot(np.linspace(0, 1, fit.shape[0] + 1)[1:], np.sort(F.cdf(fit[<span class="org-string">'bhat'</span>] / fit[<span class="org-string">'se'</span>])), lw=1, c=cm(i), label=label)
plt.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'k'</span>)
plt.xlim(lim)
plt.ylim(lim)
plt.legend(frameon=<span class="org-constant">False</span>)
plt.xlabel(<span class="org-string">'Theoretical quantile'</span>)
plt.ylabel(<span class="org-string">'Observed quantile'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/point-example.png" alt="point-example.png">
</p>
</div>

<p>
Check whether the SE is calibrated.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">n_trials</span> = 50
<span class="org-variable-name">n_bootstraps</span> = 400
<span class="org-variable-name">n_cells</span> = 100
<span class="org-variable-name">s</span> = 1e4
<span class="org-variable-name">result</span> = []
<span class="org-keyword">for</span> trial <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_trials):
  <span class="org-keyword">for</span> theta <span class="org-keyword">in</span> np.arange(-12, -2, 1):
    <span class="org-variable-name">x</span> = st.poisson(s * np.exp(theta)).rvs(size=n_cells)
    <span class="org-variable-name">thetahat</span> = np.log(x.<span class="org-builtin">sum</span>()) - np.log(n_cells * s)
    <span class="org-variable-name">se</span> = np.sqrt(1 / x.<span class="org-builtin">sum</span>())
    <span class="org-variable-name">bootstraps</span> = []
    <span class="org-keyword">for</span> b <span class="org-keyword">in</span> <span class="org-builtin">range</span>(n_bootstraps):
      <span class="org-variable-name">x</span> = st.poisson(s * np.exp(theta)).rvs(size=n_cells)
      bootstraps.append(np.log(x.<span class="org-builtin">sum</span>()) - np.log(n_cells * s))
    <span class="org-variable-name">se_b</span> = np.array(bootstraps).std()
    result.append([theta, trial, thetahat, se, se_b])
<span class="org-variable-name">result</span> = pd.DataFrame(result, columns=[<span class="org-string">'theta'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'thetahat'</span>, <span class="org-string">'se'</span>, <span class="org-string">'se_b'</span>])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.xscale(<span class="org-string">'log'</span>)
plt.yscale(<span class="org-string">'log'</span>)
plt.scatter(result[<span class="org-string">'se'</span>], result[<span class="org-string">'se_b'</span>], s=1, c=<span class="org-string">'k'</span>)
<span class="org-variable-name">lim</span> = [1e-3, 1.5]
plt.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
plt.xlim(lim)
plt.ylim(lim)
plt.xlabel(<span class="org-string">'Analytic SE'</span>)
plt.ylabel(<span class="org-string">'Bootstrap SE'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/se.png" alt="se.png">
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org6fff017" class="outline-3">
<h3 id="org6fff017">Power (single cells as units)</h3>
<div class="outline-text-3" id="text-org6fff017">
<p>
To generate true positives treating cells as units, generate null data as
above, and then use binomial thinning (Gerard 2019) to introduce effects of
a given magnitude at effect genes. Assume effects are drawn from a scaled
\(t\) distribution \(g = 0.1 t_1\).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = <span class="org-builtin">dict</span>()
<span class="org-keyword">for</span> n_cells <span class="org-keyword">in</span> (25, 50, 100):
  <span class="org-variable-name">result</span>[n_cells] = evaluate_power(dat, g=st.t(scale=0.1, df=1).rvs, n_cells=n_cells, min_cells=n_cells, n_trials=1)
<span class="org-variable-name">result</span> = pd.concat(result).reset_index(drop=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Paired'</span>)
plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 3, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'PM-EB'</span>, <span class="org-string">'PM-Z'</span>]
<span class="org-keyword">for</span> a, (t, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax, result[result[<span class="org-string">'fdr_method'</span>] == <span class="org-string">'fdr_bh'</span>].groupby(<span class="org-string">'n_cells'</span>)):
  a.boxplot(g.pivot_table(columns=<span class="org-string">'trial'</span>, index=[<span class="org-string">'method'</span>, <span class="org-string">'test'</span>], values=<span class="org-string">'power'</span>), widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
  a.set_xticklabels(labels, rotation=90)
  a.set_xlabel(<span class="org-string">'Method'</span>)
  a.set_title(f<span class="org-string">'$n$={t}'</span>)
ax[0].set_ylabel(r<span class="org-string">'Power (FDR 10%)'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/power-2-0.01.png" alt="power-2-0.01.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org3aa1007" class="outline-3">
<h3 id="org3aa1007">Type 1 error rate (donors as units)</h3>
<div class="outline-text-3" id="text-org3aa1007">
<p>
To generate null data, first randomly assign cells from a homogeneous sample
to donors, then randomly assign donors to groups.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = pd.concat(
  evaluate_type1_by_donor(dat, b=b, n_donors=4, n_cells=100, min_cells=100, n_trials=10)
  <span class="org-keyword">for</span> b <span class="org-keyword">in</span> np.log(np.linspace(1, 2, 4)))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 4, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(5.5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'GAM-EB'</span>, <span class="org-string">'GAM-Z'</span>, <span class="org-string">'PM-EB'</span>, <span class="org-string">'PM-Z'</span>]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax, result.groupby(<span class="org-string">'b'</span>)):
  a.boxplot(g.pivot_table(index=[<span class="org-string">'method'</span>, <span class="org-string">'test'</span>], columns=<span class="org-string">'trial'</span>, values=<span class="org-string">'fdp'</span>), widths=0.35, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
  a.axhline(y=0.01, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
  a.set_xticklabels(labels, rotation=90)
  a.set_title(f<span class="org-string">'$b$={np.exp(k):.3g}'</span>)
  a.set_xlabel(<span class="org-string">'Method'</span>)
ax[0].set_ylabel(<span class="org-string">'Type 1 error rate'</span>)
ax[0].set_ylim(0, 0.1)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/fpr-by-donor.png" alt="fpr-by-donor.png">
</p>
</div>
</div>

<div id="outline-container-org4d5f185" class="outline-4">
<h4 id="org4d5f185">Unequal size factors</h4>
<div class="outline-text-4" id="text-org4d5f185">
<p>
Generate null data with different size factors by assigning different
numbers of cells to different donors.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x1</span>, <span class="org-variable-name">onehot1</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=4, n_cells=50, min_counts=1, to_array=<span class="org-constant">False</span>)
<span class="org-variable-name">x2</span>, <span class="org-variable-name">onehot2</span> = simulate_null(dat[dat.obs[<span class="org-string">'cell_type'</span>] == <span class="org-string">'b_cells'</span>], n_donors=4, n_cells=100, min_counts=1, to_array=<span class="org-constant">False</span>)
<span class="org-variable-name">mix</span> = x1.concatenate(x2)
sc.pp.filter_genes(mix, min_counts=10)
<span class="org-variable-name">onehot</span> = ss.block_diag([onehot1, onehot2], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">design</span> = np.ones((8, 2))
<span class="org-variable-name">design</span>[:4,0] = 0
</pre>
</div>

<p>
Look at the distribution of size factors.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.boxplot((onehot.T @ mix.X.<span class="org-builtin">sum</span>(axis=1)).A.reshape(2, -1).T, widths=0.5, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>})
plt.xlabel(<span class="org-string">'Group'</span>)
plt.ylabel(<span class="org-string">'Size factor'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-ex-unequal-s-hist.png" alt="sim-ex-unequal-s-hist.png">
</p>
</div>

<p>
Fit <code>limma-voom</code>, followed by EB shrinkage of standard errors.
</p>

<div class="org-src-container">
<pre class="src src-ipython">(estimate_moderated_t(estimate_limma_voom(mix.X.A, onehot, design)) &lt; 0.01).mean()
</pre>
</div>

<pre class="example">
0.0

</pre>

<p>
Look at the point mass estimates.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">thetahat</span> = np.log((onehot.T @ mix.X).A + 1) - np.log(onehot.T @ mix.X.<span class="org-builtin">sum</span>(axis=1).A)
plt.clf()
plt.gcf().set_size_inches(2.5, 2.5)
plt.scatter(thetahat[:4].ravel(), thetahat[4:].ravel(), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
<span class="org-variable-name">lim</span> = [-15, 3]
plt.plot(lim, lim, c=<span class="org-string">'r'</span>, lw=1, ls=<span class="org-string">':'</span>)
plt.xlim(lim)
plt.ylim(lim)
plt.xlabel(<span class="org-string">'Est mean (50 cells)'</span>)
plt.ylabel(<span class="org-string">'Est mean (100 cells)'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/sim-ex-unequal-s-point-mass.png" alt="sim-ex-unequal-s-point-mass.png">
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org9c356fb" class="outline-3">
<h3 id="org9c356fb">Power (donors as units)</h3>
<div class="outline-text-3" id="text-org9c356fb">
<p>
To generate true positives treating donors as units, randomly sample cells
from a homogeneous population, randomly assign cells to donors, randomly
assign donors to groups, and then thin effect genes.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = pd.concat(
  evaluate_power_by_donor(dat, g=st.t(scale=0.1, df=1).rvs, n_donors=n_donors, n_cells=50, n_trials=10)
  <span class="org-keyword">for</span> n_donors <span class="org-keyword">in</span> (4, 16, 64))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Paired'</span>)
plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 3, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(5, 2.5)
<span class="org-variable-name">labels</span> = [<span class="org-string">'LV-EB'</span>, <span class="org-string">'LV-Z'</span>, <span class="org-string">'GAM-EB'</span>, <span class="org-string">'GAM-Z'</span>, <span class="org-string">'PM-EB'</span>, <span class="org-string">'PM-Z'</span>]
<span class="org-keyword">for</span> a, (k, g) <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(ax, result[result[<span class="org-string">'fdr_method'</span>] == <span class="org-string">'fdr_bh'</span>].groupby(<span class="org-string">'n_donors'</span>)):
  a.boxplot(g.pivot_table(columns=<span class="org-string">'trial'</span>, index=[<span class="org-string">'method'</span>, <span class="org-string">'test'</span>], values=<span class="org-string">'power'</span>), widths=0.4, medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>}, flierprops={<span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markersize'</span>: 2})
  a.set_xticklabels(labels, rotation=90)
  a.set_xlabel(<span class="org-string">'Method'</span>)
  a.set_title(f<span class="org-string">'$n$={k}'</span>)
ax[0].set_ylabel(r<span class="org-string">'Power (FDR 10%)'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/voom.org/power-by-donor.png" alt="power-by-donor.png">
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2020-07-09 Thu 23:44</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
