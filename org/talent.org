#+TITLE: The role of randomness in success
#+SETUPFILE: setup.org

* Introduction

  [[https://arxiv.org/abs/1802.07068][Pluchino et al. 2018]] investigate the
  disconnect between an assumed Gaussian distribution of ability, and the
  observed Pareto distribution of wealth. Specifically, they ask what sort of
  mechanism could cause an input distribution with a characteristic scale to
  lead to an output distribution which is scale-invariant. To analyze, they
  suggest a simple model over \(n\) agents and \(m\) life events:

  - Each agent \(i = 1, \ldots, n\) has latent talent \(t_i\)
  - Each agent has capital \(c_i(t)\), and all agents begin with equal
    \(c_i(0)\)
  - Each event \(j = 1, \ldots, m\) is either lucky or unlucky, with \(\pi\)
    fraction of events being lucky
  - Agents and events are spatially distributed on a 2d (toroidal) grid,
    leading to agent-specific distributions of lucky events over time
    (equivalently, \(\pi_i\) fractions of events are lucky for individual
    \(i\))
  - If agent \(i\) and event \(j\) meet at time \(t\), and if \(j\) is lucky,
    then with probability \(t_i\), the agent's capital \(c_i(t) = 2 c_i(t -
    1)\) (otherwise it is unchanged). If \(j\) is unlucky, then \(c_i(t) =
    c_i(t - 1) / 2\)

  Here, we play with a simplification of this model.

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="singlecell",partition="mstephens") :exports none :dir /scratch/midway2/aksarkar/modes

  #+RESULTS:
  : Submitted batch job 66312200

  #+BEGIN_SRC ipython
    import numpy as np
    import scipy.stats as st
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:
  
* Results
** Simplified model

   Assume that latent talent follows a standard normal distribution, and assume
   that agent-specific luck (proportion of lucky events) follows a Beta
   distribution with mean 0.5.

   #+BEGIN_SRC ipython
     np.random.seed(0)
     N = 1000
     capital = np.ones(N)
     Ft = st.norm()
     Fl = st.beta(a=20, b=20)
     talent = Ft.rvs(size=N)
     luck = Fl.rvs(size=N)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[18]:
   :END:

   Draw an example set of agents.

   #+BEGIN_SRC ipython :ipyfile figure/talent.org/ex1.png
     plt.clf()
     fig, ax = plt.subplots(1, 2)
     fig.set_size_inches(5, 2.5)

     grid = np.linspace(-4, 4, 1000)
     ax[0].hist(talent, bins=20, density=True, color='0.7')
     ax[0].plot(grid, Ft.pdf(grid), lw=1, c='k')
     ax[0].set_xlabel('Latent talent')
     ax[0].set_ylabel('Density')

     grid = np.linspace(0, 1, 1000)
     ax[1].hist(luck, bins=20, density=True, color='0.7')
     ax[1].plot(grid, Fl.pdf(grid), lw=1, c='k')
     ax[1].set_xlabel('Latent luck')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[92]:
   [[file:figure/talent.org/ex1.png]]
   :END:

   Suppose we measure time in years, and consider a lifetime, say
   \(t=80\). Assume an exponential waiting time between events; then, the
   number of events in a lifetime is Poisson distributed.

   #+BEGIN_SRC ipython
     def simulate(N=1000, a=20, b=20, wait_time=0.05, t_max=80, seed=0):
       np.random.seed(seed)
       capital = np.ones(N)
       talent = st.norm().rvs(size=N)
       Fl = st.beta(a=20, b=20)
       luck = Fl.rvs(size=N)
       Fw = st.expon(scale=1 / wait_time)
       trace = []
       t = 0
       while t < t_max:
         wait = 1 / Fw.rvs(size=N)
         t += np.min(wait)
         target = np.argmin(wait)
         lucky = np.random.uniform() < luck[target]
         success = np.random.uniform() < Ft.cdf(talent[target])
         if lucky and success:
           capital[target] *= 2
         elif not lucky:
           capital[target] /= 2
         trace.append((t, capital))
       return talent, luck, capital
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[77]:
   :END:

   Draw from the simulation.

   #+BEGIN_SRC ipython :async t
     talent, luck, capital = simulate(N=1000, wait_time=0.1)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[72]:
   :END:

   Look at the final distribution of capital.

   #+BEGIN_SRC ipython :ipyfile figure/talent.org/ex2.png
     plt.clf()
     fig, ax = plt.subplots(1, 4)
     fig.set_size_inches(8, 2)

     ax[0].hist(capital, bins=20, color='0.7')
     ax[0].set_xlabel('Capital')
     ax[0].set_ylabel('Number of individuals')

     ax[1].set_yscale('log')
     ax[1].scatter(talent, capital, s=4, c='k', alpha=0.2)
     ax[1].set_xlabel('Latent talent')
     ax[1].set_ylabel('Capital')

     ax[2].set_yscale('log')
     ax[2].scatter(luck, capital, s=4, c='k', alpha=0.2)
     ax[2].set_xlabel('Latent luck')
     ax[2].set_ylabel('Capital')

     ax[3].scatter(luck, talent, s=4, c='k', alpha=0.2)
     ax[3].set_xlabel('Latent luck')
     ax[3].set_ylabel('Latent talent')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[76]:
   [[file:figure/talent.org/ex2.png]]
   :END:

   Now, take 100 draws from the simulation.

   #+BEGIN_SRC ipython :async t
     n_trials = 100
     talents = []
     lucks = []
     capitals = []
     for t in range(n_trials):
       t, l, c = simulate(N=1000, wait_time=0.1, seed=t)
       talents.append(t)
       lucks.append(l)
       capitals.append(c)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[84]:
   :END:

   Look at the distributions of luck and talent of the wealthiest individual,
   compared to the population distributions.

   #+BEGIN_SRC ipython
     talent_max = np.array([t[np.argmax(c)] for t, c in zip(talents, capitals)])
     luck_max = np.array([l[np.argmax(c)] for l, c in zip(lucks, capitals)])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[93]:
   :END:

   #+BEGIN_SRC ipython
     import scipy.optimize as so
     def beta_nll(theta, x):
       return -st.beta(a=np.exp(theta[0]), b=np.exp(theta[1])).logpdf(x).sum()

     opt = so.minimize(beta_nll, x0=np.zeros(2), args=(luck_max,), method='L-BFGS-B')
     opt
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[95]:
   #+BEGIN_EXAMPLE
     fun: -127.9427851349254
     hess_inv: <2x2 LbfgsInvHessProduct with dtype=float64>
     jac: array([4.54747351e-05, 7.53175300e-05])
     message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'
     nfev: 51
     nit: 10
     status: 0
     success: True
     x: array([3.42174158, 3.0879293 ])
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/talent.org/ex3.png
     plt.clf()
     fig, ax = plt.subplots(1, 2)
     fig.set_size_inches(5, 2.5)
     grid = np.linspace(-3, 3, 1000)
     ax[0].hist(talent_max, bins=10, density=True, color='0.7')
     ax[0].plot(grid, st.norm().pdf(grid), color='k', lw=1, ls=':')
     ax[0].plot(grid, st.norm(loc=talent_max.mean(), scale=talent_max.std()).pdf(grid), color='k', lw=1)
     ax[0].set_xlabel('Latent talent')
     ax[0].set_ylabel('Density')

     grid = np.linspace(0, 1, 1000)
     ax[1].hist(luck_max, bins=10, density=True, color='0.7')
     ax[1].plot(grid, st.beta(a=20, b=20).pdf(grid), color='k', lw=1, ls=':')
     ax[1].plot(grid, st.beta(*np.exp(opt.x)).pdf(grid), color='k', lw=1)
     ax[1].set_xlabel('Latent luck')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[100]:
   [[file:figure/talent.org/ex3.png]]
   :END:

   Estimate the average quantile of talent for the most successful
   individual.

   #+BEGIN_SRC ipython
     st.norm.cdf(talent_max.mean())
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[101]:
   : 0.8774647656061401
   :END:

   Estimate the average quantile of luck for the most successful individual.

   #+BEGIN_SRC ipython
     F_lm = st.beta(*np.exp(opt.x))
     st.beta(a=20, b=20).cdf(F_lm.mean())
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[102]:
   : 0.8523639432276193
   :END:
