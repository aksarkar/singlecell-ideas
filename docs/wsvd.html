<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2018-08-03 Fri 18:10 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Factor analysis for single cell data</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<style type="text/css">body {width: 60em; margin:auto} pre.src {overflow:auto}</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Factor analysis for single cell data</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org792a4de">Introduction</a></li>
<li><a href="#org3e1b3c4">Implementation</a>
<ul>
<li><a href="#org9050847">Iterative reweighted factor analysis</a></li>
<li><a href="#org420c835">First order optimization</a></li>
<li><a href="#org44d3211">Naive factor analysis</a></li>
</ul>
</li>
<li><a href="#org17b1019">Simulation</a></li>
<li><a href="#orgc11fabd">Application to single cell data</a></li>
</ul>
</div>
</div>

<div id="outline-container-org792a4de" class="outline-2">
<h2 id="org792a4de">Introduction</h2>
<div class="outline-text-2" id="text-org792a4de">
<p>
Suppose we want to fit a linear model with heteroscedastic errors:
</p>

<p>
\[ y \sim N(X \beta, \Sigma) \]
</p>

<p>
where \(y\) is \(n \times 1\), \(X\) is \(n \times p\), and \(\Sigma =
  \mathrm{diag}(\sigma^2_1, \ldots, \sigma^2_n)\).
</p>

<p>
We can estimate \(\beta\) via weighted least squares:
</p>

<p>
\[ \hat\beta = (X' W X)^{-1} X' W y \]
</p>

<p>
where \(W = \Sigma^{-1}\).
</p>

<p>
Now suppose \(y\) is not Gaussian, but we assume a generalized linear model:
</p>

<p>
\[ \eta = X \beta \]
</p>

<p>
\[ E[y \mid x] = \mu = g^{-1}(\eta) \]
</p>

<p>
In this case, we can estimate \(\beta\) via iterative reweighted least
squares (Nelder and Wedderbun 1972).
</p>

<p>
The key idea is to perform approximate Newton-Raphson updates (by
approximating the Hessian). Introduce an auxiliary response:
</p>

<p>
\[ z = \eta + (y - \mu) \left(\frac{\partial \mu}{\partial \eta}\right) \]
</p>

<p>
and associated weight:
</p>

<p>
\[ w = \frac{1}{V[y]} \left(\frac{\partial \mu}{\partial \eta}\right)^2 \]
</p>

<p>
IRLS consists of repeatedly applying the updates:
</p>

<ol class="org-ol">
<li>Given \(z, w\), update \(\beta \leftarrow (X' W X)^{-1} X' W z\)</li>
<li>Given \(\beta\), update \(z, w\)</li>
</ol>

<p>
Can we generalize these ideas to perform PCA/factor analysis (Tipping 1999)?
Suppose:
</p>

<p>
\[ x_i = W z_i + \mu_i + \epsilon_i \]
</p>

<p>
where \(x_i\) is an observed \(p\)-vector, \(z_i\) is a latent \(q\)-vector,
and \(q \ll p\).
</p>

<p>
If we assume \(i = 1, \ldots, n, z_i \sim N(0, 1), \epsilon_i \sim N(0,
  \sigma^2)\) then the MAP estimates are:
</p>

<p>
\[ \hat{\mu}_i = \frac{1}{n} \sum_j x_{ij} \]
</p>

<p>
\[ \hat{\sigma^2} = \frac{1}{p - q} \sum_{j = q + 1}^{p} \lambda_j \]
</p>

<p>
\[ \hat{W} = U (\Lambda - \sigma^2 I)^{1/2} \]
</p>

<p>
where \(U, \Lambda\) are the top \(q\) eigenvectors (eigenvalues) of \(X' X\)
</p>

<p>
If the errors are heteroscedastic, can we generalize the weighted least
squares idea to a weighted SVD? Suppose:
</p>

<p>
\[ X = U D V' + Z + E \]
</p>

<p>
\[ z_{ij} \sim N(0, s_{ij}^2) \]
</p>

<p>
\[ e_{ij} \sim N(0, \tau^{-1}) \]
</p>

<p>
Given \(Z\), the problem becomes PCA of \((X - Z)\) with homoscedastic
errors.
</p>

<p>
Let \(R = X - UDV'\). Then, given \(U, D, V, S, \tau\):
</p>

<p>
\[ r_{ij} \mid z_{ij} \sim N(r_{ij}, \tau^{-1}) \]
</p>

<p>
\[ z_{ij} \mid \cdot \sim N(\mu_1, \tau_1^{-1}) \]
</p>

<p>
\[ \mu_1 = r_{ij} \tau / \tau_1 \]
</p>

<p>
\[ \tau_1 = \tau + 1 / s_{ij}^2 \]
</p>

<p>
This idea generalizes the basic iteration in the Soft-Impute algorithm for
matrix completion (Mazumder 2010), by representing missing entries as
\(s_{ij} = \infty\).
</p>

<p>
Now suppose the data \(X\) is not Gaussian. Can we generalize IRLS to an
iterative reweighted factor analysis, using our weighted SVD? Suppose \(Y\)
is the auxiliary response:
</p>

<ol class="org-ol">
<li>Given \(Y, W\), update \(U, D, V\)</li>
<li>Given \(U, D, V\), update \(Y, W\)</li>
</ol>
</div>
</div>

<div id="outline-container-org3e1b3c4" class="outline-2">
<h2 id="org3e1b3c4">Implementation</h2>
<div class="outline-text-2" id="text-org3e1b3c4">
</div>
<div id="outline-container-org9050847" class="outline-3">
<h3 id="org9050847">Iterative reweighted factor analysis</h3>
<div class="outline-text-3" id="text-org9050847">
<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">def</span> <span class="org-function-name">wsvd</span>(x, s, n_components, prior_prec=1, max_iters=10, verbose=<span class="org-constant">False</span>):
  <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = x.shape
  <span class="org-variable-name">z</span> = np.zeros((n, p))
  <span class="org-variable-name">pca</span> = skd.PCA(n_components=n_components)
  <span class="org-variable-name">obj</span> = <span class="org-builtin">float</span>(<span class="org-string">'-inf'</span>)
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(max_iters):
    <span class="org-variable-name">u</span>, <span class="org-variable-name">d</span>, <span class="org-variable-name">vt</span> = pca._fit(x - z)
    <span class="org-variable-name">r</span> = x - np.einsum(<span class="org-string">'ij,j,jk-&gt;ik'</span>, u, d, vt)
    <span class="org-variable-name">posterior_prec</span> = prior_prec + 1 / s ** 2
    <span class="org-variable-name">z</span> = r * prior_prec / posterior_prec
    <span class="org-variable-name">update</span> = st.norm(scale=np.sqrt(s ** 2 + 1 / prior_prec)).logpdf(r).mean()
    <span class="org-keyword">if</span> verbose:
      <span class="org-keyword">print</span>(f<span class="org-string">'wsvd [{i}] = {update}'</span>)
    <span class="org-keyword">if</span> update &lt; obj <span class="org-keyword">or</span> np.isclose(update, obj):
      <span class="org-keyword">return</span> u, d, vt
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">obj</span> = update
  <span class="org-keyword">raise</span> <span class="org-type">RuntimeError</span>(<span class="org-string">'failed to converge'</span>)

<span class="org-keyword">def</span> <span class="org-function-name">pois_llik</span>(y, lam):
  <span class="org-keyword">return</span> y * np.log(lam) - lam - sp.gammaln(y + 1)

<span class="org-keyword">def</span> <span class="org-function-name">exp</span>(x):
  <span class="org-doc">"""Numerically safe exp"""</span>
  <span class="org-keyword">return</span> np.exp(np.clip(x, 0, 700))

<span class="org-keyword">def</span> <span class="org-function-name">pois_svd</span>(x, max_outer_iters=10, verbose=<span class="org-constant">False</span>, **kwargs):
  <span class="org-variable-name">mu</span> = x.mean(axis=0, keepdims=<span class="org-constant">True</span>) * np.ones(x.shape)
  <span class="org-variable-name">eta</span> = np.log(mu)
  <span class="org-variable-name">obj</span> = <span class="org-builtin">float</span>(<span class="org-string">'-inf'</span>)
  <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(max_outer_iters):
    <span class="org-variable-name">y</span> = eta + (x - mu) / mu
    <span class="org-variable-name">w</span> = 1 / mu
    <span class="org-variable-name">u</span>, <span class="org-variable-name">d</span>, <span class="org-variable-name">vt</span> = wsvd(y, w, verbose=verbose, **kwargs)
    <span class="org-variable-name">eta</span> = np.einsum(<span class="org-string">'ij,j,jk-&gt;ik'</span>, u, d, vt)
    <span class="org-variable-name">mu</span> = exp(eta)
    <span class="org-variable-name">update</span> = pois_llik(x, mu).mean()
    <span class="org-keyword">if</span> verbose:
      <span class="org-keyword">print</span>(f<span class="org-string">'pois_svd [{i}] = {update}'</span>)
    <span class="org-keyword">if</span> update &lt; obj <span class="org-keyword">or</span> np.isclose(update, obj):
      <span class="org-keyword">return</span> u, d, vt
    <span class="org-keyword">else</span>:
      <span class="org-variable-name">obj</span> = update
  <span class="org-keyword">raise</span> <span class="org-type">RuntimeError</span>(<span class="org-string">'failed to converge'</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-org420c835" class="outline-3">
<h3 id="org420c835">First order optimization</h3>
<div class="outline-text-3" id="text-org420c835">
<p>
Directly optimize the log likelihood via gradient descent:
</p>

<p>
\[ x_{ij} \sim Poisson(\lambda_{ij}) \]
</p>

<p>
\[ \lambda_{ij} = \sum_k L_{ik} F_{kj} \]
</p>

<p>
For simplicity, don't put any constraints on \(L, F\).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> torch

<span class="org-keyword">class</span> <span class="org-type">PoissonFA</span>(torch.nn.Module):
  <span class="org-keyword">def</span> <span class="org-function-name">__init__</span>(<span class="org-keyword">self</span>, n_samples, n_features, n_components):
    <span class="org-builtin">super</span>().__init__()
    <span class="org-keyword">self</span>.l = torch.randn([n_samples, n_components], requires_grad=<span class="org-constant">True</span>)
    <span class="org-keyword">self</span>.f = torch.randn([n_components, n_features], requires_grad=<span class="org-constant">True</span>)

  <span class="org-keyword">def</span> <span class="org-function-name">forward</span>(<span class="org-keyword">self</span>, x):
    <span class="org-variable-name">log_lam</span> = torch.matmul(<span class="org-keyword">self</span>.l, <span class="org-keyword">self</span>.f)
    <span class="org-keyword">return</span> -torch.mean(x * log_lam - torch.exp(log_lam) + sp.gammaln(x + 1))

  <span class="org-keyword">def</span> <span class="org-function-name">fit</span>(<span class="org-keyword">self</span>, x, max_epochs=1000, verbose=<span class="org-constant">False</span>, **kwargs):
    <span class="org-variable-name">x</span> = torch.tensor(x, dtype=torch.<span class="org-builtin">float</span>)
    <span class="org-variable-name">opt</span> = torch.optim.Adam([<span class="org-keyword">self</span>.l, <span class="org-keyword">self</span>.f], **kwargs)
    <span class="org-keyword">for</span> i <span class="org-keyword">in</span> <span class="org-builtin">range</span>(max_epochs):
      opt.zero_grad()
      <span class="org-variable-name">loss</span> = <span class="org-keyword">self</span>.forward(x)
      <span class="org-keyword">if</span> verbose <span class="org-keyword">and</span> <span class="org-keyword">not</span> i % 100:
        <span class="org-keyword">print</span>(f<span class="org-string">'Epoch {i} = {loss}'</span>)
      loss.backward()
      opt.step()
    <span class="org-keyword">return</span> <span class="org-keyword">self</span>

<span class="org-keyword">def</span> <span class="org-function-name">pois_fa</span>(x, n_components, **kwargs):
  <span class="org-variable-name">n</span>, <span class="org-variable-name">p</span> = x.shape
  <span class="org-variable-name">res</span> = PoissonFA(n, p, n_components).fit(x, max_epochs=2000, lr=5e-2)
  <span class="org-keyword">return</span> res.l.detach().numpy(), np.ones(n_components), res.f.detach().numpy()
</pre>
</div>
</div>
</div>

<div id="outline-container-org44d3211" class="outline-3">
<h3 id="org44d3211">Naive factor analysis</h3>
<div class="outline-text-3" id="text-org44d3211">
<p>
The naive approach would be to compute the Poisson MLE \(\hat\lambda_{ij}\)
once and then factorize the resulting matrix. But without further
assumptions, the MLE is \(\hat\lambda_{ij} = x_{ij}\)
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org97eb20d"><span class="org-keyword">def</span> <span class="org-function-name">naive_pois_svd</span>(x, n_components, **kwargs):
  <span class="org-keyword">return</span> skd.PCA(n_components=n_components)._fit(x)
</pre>
</div>
</div>
</div>
</div>


<div id="outline-container-org17b1019" class="outline-2">
<h2 id="org17b1019">Simulation</h2>
<div class="outline-text-2" id="text-org17b1019">
<p>
Generate a Poisson data matrix assuming the rate matrix is low rank. Evaluate
the quality of the fit using RRMSE.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orgcde48b8"><span class="org-keyword">def</span> <span class="org-function-name">simulate</span>(num_samples, num_features, rank, seed=<span class="org-constant">None</span>):
  <span class="org-keyword">if</span> seed <span class="org-keyword">is</span> <span class="org-constant">None</span>:
    <span class="org-variable-name">seed</span> = 0
  np.random.seed(seed)
  <span class="org-variable-name">l</span> = np.random.normal(scale=0.7, size=(num_samples, rank))
  <span class="org-variable-name">f</span> = np.random.normal(scale=0.7, size=(rank, num_features))
  <span class="org-variable-name">lf</span> = l.dot(f)
  <span class="org-variable-name">e</span> = np.random.normal(scale=lf.std(), size=(num_samples, num_features))
  <span class="org-variable-name">x</span> = np.random.poisson(lam=np.exp(lf + e))
  <span class="org-keyword">return</span> x, lf

<span class="org-keyword">def</span> <span class="org-function-name">reconstruct</span>(res):
  <span class="org-keyword">return</span> np.einsum(<span class="org-string">'ij,j,jk-&gt;ik'</span>, *res)

<span class="org-keyword">def</span> <span class="org-function-name">rrmse</span>(pred, true):
  <span class="org-keyword">return</span> np.sqrt(np.linalg.norm(pred - true) / np.linalg.norm(true))
</pre>
</div>

<p>
Test the simulation framework.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span>, <span class="org-variable-name">lf</span> = simulate(num_samples=100, num_features=1000, rank=1, seed=0)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">res</span> = pois_svd(x, n_components=1)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">rrmse(reconstruct(res), lf)
</pre>
</div>

<pre class="example">
0.7758305792529097

</pre>

<p>
Compute the naive estimate.
</p>

<div class="org-src-container">
<pre class="src src-ipython">rrmse(reconstruct(naive_pois_svd(x, 1)), lf)
</pre>
</div>

<pre class="example">
1.1425364246860807

</pre>

<p>
Evaluate the methods systematically.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="orgd87ff5d"><span class="org-keyword">def</span> <span class="org-function-name">evaluate</span>(num_trials=10):
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> rank <span class="org-keyword">in</span> <span class="org-builtin">range</span>(1, 4):
    <span class="org-keyword">for</span> n_components <span class="org-keyword">in</span> <span class="org-builtin">range</span>(1, 4):
      <span class="org-keyword">for</span> method <span class="org-keyword">in</span> (pois_svd, pois_fa, naive_pois_svd):
        <span class="org-keyword">for</span> trial <span class="org-keyword">in</span> <span class="org-builtin">range</span>(num_trials):
          <span class="org-keyword">try</span>:
            <span class="org-variable-name">x</span>, <span class="org-variable-name">lam</span> = simulate(num_samples=100, num_features=1000, rank=rank, seed=trial)
            <span class="org-variable-name">res</span> = method(x, n_components=n_components, max_outer_iters=1000, max_iters=1000)
            <span class="org-variable-name">rrmse_</span> = rrmse(reconstruct(res), lam)
            <span class="org-variable-name">llik</span> = pois_llik(x, np.exp(reconstruct(res))).mean()
          <span class="org-keyword">except</span>:
            <span class="org-variable-name">rrmse_</span> = <span class="org-constant">None</span>
            <span class="org-variable-name">llik</span> = <span class="org-constant">None</span>
          result.append((rank, trial, method.<span class="org-builtin">__name__</span>, n_components, rrmse_, llik))
  <span class="org-variable-name">result</span> = pd.DataFrame(result)
  <span class="org-variable-name">result.columns</span> = [<span class="org-string">'rank'</span>, <span class="org-string">'trial'</span>, <span class="org-string">'method'</span>, <span class="org-string">'n_components'</span>, <span class="org-string">'rrmse'</span>, <span class="org-string">'llik'</span>]
  <span class="org-keyword">return</span> result
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = evaluate(num_trials=5)
</pre>
</div>

<p>
Serialize the results.
</p>

<div class="org-src-container">
<pre class="src src-ipython">result.to_csv(<span class="org-string">'pois-svd-simulation.txt.gz'</span>, sep=<span class="org-string">'\t'</span>, compression=<span class="org-string">'gzip'</span>)
</pre>
</div>

<p>
Read the results.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">result</span> = pd.read_table(<span class="org-string">'pois-svd-simulation.txt.gz'</span>, index_col=0)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
result[result[<span class="org-string">'rank'</span>] == result[<span class="org-string">'n_components'</span>]].boxplot(column=<span class="org-string">'rrmse'</span>, by=[<span class="org-string">'rank'</span>, <span class="org-string">'method'</span>], figsize=(3, 3), grid=<span class="org-constant">False</span>, rot=90)
plt.ylabel(<span class="org-string">'Relative RMSE'</span>)
plt.title(<span class="org-string">''</span>)
plt.suptitle(<span class="org-string">''</span>)
</pre>
</div>

<pre class="example">
Text(0.5,0.98,'')

</pre>

<div class="figure">
<p><img src="figure/wsvd.org/rrmse.png" alt="rrmse.png">
</p>
</div>

<p>
Does the WSVD reveal the underlying rank?
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
result[result[<span class="org-string">'method'</span>] == <span class="org-string">'pois_svd'</span>].dropna().boxplot(column=<span class="org-string">'llik'</span>, by=[<span class="org-string">'rank'</span>, <span class="org-string">'n_components'</span>], figsize=(3, 5), grid=<span class="org-constant">False</span>, rot=90)
plt.ylabel(<span class="org-string">'Per sample log likelihood'</span>)
plt.yscale(<span class="org-string">'symlog'</span>, linthreshy=1e-14)
plt.title(<span class="org-string">''</span>)
plt.suptitle(<span class="org-string">''</span>)
</pre>
</div>

<pre class="example">
Text(0.5,0.98,'')

</pre>

<div class="figure">
<p><img src="figure/wsvd.org/llik.png" alt="llik.png">
</p>
</div>

<p>
For each data set, how often does the model with number of components equal
to the ground truth have the highest likelihood?
</p>

<div class="org-src-container">
<pre class="src src-ipython">(result[result[<span class="org-string">'method'</span>] == <span class="org-string">'pois_svd'</span>]
 .groupby([<span class="org-string">'rank'</span>, <span class="org-string">'trial'</span>])
 .<span class="org-builtin">apply</span>(<span class="org-keyword">lambda</span> x: x.loc[x[<span class="org-string">'llik'</span>].idxmax, <span class="org-string">'n_components'</span>])
 .reset_index())
</pre>
</div>

<pre class="example">
rank  trial  0
0      1      0  1
1      1      1  1
2      1      2  1
3      1      3  1
4      1      4  1
5      2      0  2
6      2      1  2
7      2      2  3
8      2      3  2
9      2      4  2
10     3      0  3
11     3      1  3
12     3      2  3
13     3      3  3
14     3      4  3
</pre>
</div>
</div>

<div id="outline-container-orgc11fabd" class="outline-2">
<h2 id="orgc11fabd">Application to single cell data</h2>
<div class="outline-text-2" id="text-orgc11fabd">
<p>
What are the latent factors we expect to find in single cell data?
</p>

<ol class="org-ol">
<li>Unwanted variation</li>
<li>Cell types/subpopulations</li>
</ol>

<p>
Of these, cell types are of the most interest, because we can then read off
the relevant genes from the factors.
</p>

<p>
To test whether the method recovers cell type, we use known mixtures of
sorted PBMCs from 10X Genomics.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">b_cells</span> = si.mmread(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cd19+_b_cells/filtered_matrices_mex/hg19/matrix.mtx'</span>)
<span class="org-variable-name">t_cells</span> = si.mmread(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cd8+_cytotoxic_t_cells/filtered_matrices_mex/hg19/matrix.mtx'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">genes</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/cd19+_b_cells/filtered_matrices_mex/hg19/genes.tsv'</span>, header=<span class="org-constant">None</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">b_cell_subset</span> = b_cells.tocsc()[:,:500]
<span class="org-variable-name">t_cell_subset</span> = t_cells.tocsc()[:,:500]
<span class="org-variable-name">mix</span> = ss.hstack([b_cell_subset, t_cell_subset], <span class="org-builtin">format</span>=<span class="org-string">'csr'</span>)
<span class="org-variable-name">keep</span> = (mix.<span class="org-builtin">sum</span>(axis=1) &gt; 0).A.ravel()
<span class="org-variable-name">genes</span> = genes.loc[keep]
<span class="org-variable-name">mix</span> = mix[keep].A.T
<span class="org-variable-name">mix</span> /= mix.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">res</span> = pois_svd(mix, n_components=10, verbose=<span class="org-constant">True</span>)
</pre>
</div>

<p>
2 - 8b2e7d2c-614d-46bb-aaff-4a9a5a4420d0
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">res0</span> = skd.PCA(n_components=10).fit(mix)  
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">Y</span> = np.zeros(mix.shape[0])
Y[:mix.shape[0] // 2] = 1
<span class="org-variable-name">m0</span> = sklm.LogisticRegressionCV(fit_intercept=<span class="org-constant">True</span>).fit(res0.transform(mix), Y)
m0.coef_
</pre>
</div>

<pre class="example">
array([[ 5.53867438e-04, -1.16538042e-04,  1.97613135e-05,
-7.26492033e-06, -8.97671870e-06,  6.80991734e-06,
-3.30404299e-06,  1.02224040e-05, -2.31100318e-06,
7.68760237e-07]])
</pre>

<div class="org-src-container">
<pre class="src src-ipython">m0.score(res0.transform(mix), Y)
</pre>
</div>

<pre class="example">
1.0

</pre>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">scaler</span> = skp.StandardScaler()
<span class="org-variable-name">m1</span> = sklm.LogisticRegressionCV(fit_intercept=<span class="org-constant">True</span>).fit(scaler.fit_transform(mix), Y)
m1.score(scaler.transform(mix), Y)
</pre>
</div>

<pre class="example">
1.0

</pre>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2018-08-03 Fri 18:10</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
