<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2018-09-25 Tue 14:22 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Weighted low rank approximation</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="https://maxcdn.bootstrapcdn.com/bootswatch/3.3.7/cosmo/bootstrap.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="https://www.pirilampo.org/styles/readtheorg/css/htmlize.css"/>
<style type="text/css">body {width: 60em; margin:auto} pre.src {overflow:auto}</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Weighted low rank approximation</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgb49048c">Introduction</a></li>
<li><a href="#org3822917">Methods</a>
<ul>
<li><a href="#org19362fe">EM algorithm</a></li>
<li><a href="#org7074885">Bernoulli low rank approximation</a></li>
<li><a href="#org90ac4e1">Poisson low rank approximation</a></li>
<li><a href="#orgafb113e">Imputing missing values</a></li>
</ul>
</li>
<li><a href="#org23e1a28">Results</a>
<ul>
<li><a href="#org56d579d">Recovering planted low rank structure</a></li>
<li><a href="#org8f29519">Imputing missing values</a></li>
<li><a href="#orgd780580">Explaining held out data</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgb49048c" class="outline-2">
<h2 id="orgb49048c">Introduction</h2>
<div class="outline-text-2" id="text-orgb49048c">
<p>
We are interested in solving the <i>weighted low-rank approximation problem</i>:
</p>

<p>
\[ \min_{\mathbf{Z}} \sum_{i,j} w_{ij} \left(x_{ij} - z_{ij} \right)^2 \]
</p>

<p>
where \(n \times p\) target matrix \(\mathbf{X}\) and \(n \times p\) weight
matrix \(\mathbf{W}\) are given, and \(\mathbf{Z}\) is constrained to some
rank.
</p>

<p>
Solving WLRA allows us to solve two main problems:
</p>

<ol class="org-ol">
<li><b>Learn low rank structure in non-Gaussian data.</b> Using Taylor expansion of
non-Gaussian likelihoods, we can rewrite the MLE of factor models as the
solution to WLRA. The key idea is that the Taylor expansion is performed
around a different value for each observation, naturally leading to an
iterative approach.</li>

<li><b>Handle truly missing data.</b> By setting weights to zero, we can code
missing data. This approach works even in settings where observations can
also take the value zero, such as single cell RNA sequencing data.</li>
</ol>
</div>
</div>

<div id="outline-container-org3822917" class="outline-2">
<h2 id="org3822917">Methods</h2>
<div class="outline-text-2" id="text-org3822917">
</div>
<div id="outline-container-org19362fe" class="outline-3">
<h3 id="org19362fe">EM algorithm</h3>
<div class="outline-text-3" id="text-org19362fe">
<p>
<a href="https://www.aaai.org/Papers/ICML/2003/ICML03-094.pdf">Srebro and Jaakkola 2003</a> propose an EM algorithm to solve WLRA. The algorithm
is EM in the following sense: suppose the weights \(w_{ij} \in \{0, 1\}\),
corresponding to presence/absence, and suppose \(\mathbf{X} = \mathbf{Z} +
   \mathbf{E}\), where \(\mathbf{Z}\) is low-rank and elements of \(\mathbf{E}\)
are Gaussian.
</p>

<p>
Then, \(E[x_{ij} \mid w_{ij} = 0] = z_{ij}\), naturally giving an EM
algorithm. The E-step fills in \(x_{ij}\) with \(z_{ij}\), and the M-step
estimates \(\mathbf{Z}\) from the filled in \(\mathbf{X}\). The solution to
the M-step is given by the optimal unweighted rank \(k\) approximation,
i.e. truncated SVD, because all the non-zero weights are equal to 1.
</p>

<p>
Conceptually, the method for arbitrary weights is to suppose instead that we
have rational \(w_{ij} \in \{0, 1/N, \ldots, 1\}\). 
</p>

<p>
Then, we can reduce this problem to a problem in 0/1 weights by supposing we
have \(X^{(k)} = Z + E^{(k)}\), \(k \in 1, \ldots, N\), and each entry is
observed in only \(N w_{ij}\) of the \(X^{(k)}\).
</p>

<p>
Then, the M-step becomes:
</p>

<p>
\[ \mathbf{Z}^{(t + 1)} = \mathrm{LRA}_k(\mathbf{W} \circ \mathbf{X} +
   (\mathbf{1} - \mathbf{W}) \circ \mathbf{Z}^{(t)}) \]
</p>

<p>
where \(\mathrm{LRA}_k\) is the unweighted rank \(k\) approximation and
\(\circ\) denotes Hadamard product.
</p>

<p>
Intuitively, the implied E-step corresponds to taking the expectation of
\(z_{ij}^{(k)}\) over the targets \(k\). Clearly, the algorithm generalizes
to any weight matrix where \(0 \leq w_{ij} \leq 1\) are stored in finite
precision.
</p>
</div>
</div>

<div id="outline-container-org7074885" class="outline-3">
<h3 id="org7074885">Bernoulli low rank approximation</h3>
<div class="outline-text-3" id="text-org7074885">
<p>
Srebro and Jaakkola apply the EM approach to solve low rank approximation
for binary data, where the assumed low rank structure is on the probability
a user will prefer an item.
</p>

<p>
They seek to minimize the loss function \(l(\eta) = \log\mathrm{sigmoid}(x
   \eta)\). They take a variational lower bound to the log sigmoid function
(Jaakkola and Jordan 2000), then perform second-order Taylor expansion about
\(\eta_0\), yielding the objective function:
</p>

<p>
\[ l(\eta) \geq -\frac{1}{4} \frac{\tanh(\eta_0 / 2)}{\eta_0} \left(\eta -
   \frac{y\,\eta_0}{\tanh(\eta_0 / 2)}\right) + \mathrm{const} \]
</p>

<p>
where the constant does not depend on \(\eta\). Now, the objective function
has the form of WLRA. This result suggests an iterative algorithm, where we
take successive Taylor approximations about different parameter estimates
for each entry.
</p>
</div>
</div>

<div id="outline-container-org90ac4e1" class="outline-3">
<h3 id="org90ac4e1">Poisson low rank approximation</h3>
<div class="outline-text-3" id="text-org90ac4e1">
<p>
We extend this approach to maximize the Poisson log-likelihood. Dropping
indexes, we assume for each entry:
</p>

<p>
\[ \ln p(x \mid \eta) = l(\eta) = x \eta - \exp(\eta) +
   \ln\Gamma(x + 1) \]
</p>

<p>
Taking a second-order Taylor expansion about \(\eta_0\):
</p>

<p>
\[ l(\eta) \approx \tilde{l}(\eta) = (\eta - \eta_0) [x - \exp(\eta_0)] +
   \frac{(\eta - \eta_0)^2}{2}[-\exp(\eta_0)] + \mathrm{const}\]
</p>

<p>
where the constant does not depend on \(\eta\).
</p>

<p>
\[ \tilde{l}(\eta) = -\frac{\exp(\eta_0)}{2} \left[\eta - \left(1 +
   \eta_0 - \frac{x}{\exp(\eta_0)}\right)\right]^2 + \mathrm{const}\]
</p>

<p>
The weights must be constrained to be between zero and one in the EM
algorithm, so we scale them by the maximum weight in each outer
iteration. Our method is implemented in the Python package <i>wlra</i>.
</p>
</div>
</div>

<div id="outline-container-orgafb113e" class="outline-3">
<h3 id="orgafb113e">Imputing missing values</h3>
<div class="outline-text-3" id="text-orgafb113e">
<p>
To support missing values, we need to introduce external weights
\(\tilde{w}_{ij} \in \{0, 1\}\) to denote presence/absence. We can do this
by incorporating the weights \(\tilde{\mathbf{W}} \circ \mathbf{W}\) in each
outer iteration.
</p>
</div>
</div>
</div>

<div id="outline-container-org23e1a28" class="outline-2">
<h2 id="org23e1a28">Results</h2>
<div class="outline-text-2" id="text-org23e1a28">
</div>
<div id="outline-container-org56d579d" class="outline-3">
<h3 id="org56d579d">Recovering planted low rank structure</h3>
<div class="outline-text-3" id="text-org56d579d">
</div>
<div id="outline-container-org89d37d1" class="outline-4">
<h4 id="org89d37d1">Gaussian noise</h4>
<div class="outline-text-4" id="text-org89d37d1">
<p>
We first consider the problem of recovering a planted low rank matrix after
convolving with Gaussian noise, assuming we know the rank.
</p>

<p>
\[ l_{ik} \sim \mathcal{N}(0, 1) \]
\[ f_{kj} \sim \mathcal{N}(0, 1) \]
\[ \mu_{ij} = (\mathbf{l}\mathbf{f})_{ij} \]
\[ \sigma^2_{ij} \sim \mathrm{Uniform}(1, \sigma^2_0) \]
\[ x_{ij} \sim \mathcal{N}(\mu_{ij}, \sigma^2_{ij}) \]
</p>

<p>
We assume the noise variances for each observation are known, and use the
inverse variances as the weights.
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org57c9be9"><span class="org-keyword">def</span> <span class="org-function-name">wnorm</span>(x, w):
  <span class="org-keyword">return</span> (w * np.square(x)).<span class="org-builtin">sum</span>()

<span class="org-keyword">def</span> <span class="org-function-name">simulate_gaussian</span>(n, p, rank, s0=10, seed=0):
  np.random.seed(seed)
  <span class="org-variable-name">l</span> = np.random.normal(size=(n, rank))
  <span class="org-variable-name">f</span> = np.random.normal(size=(rank, p))
  <span class="org-variable-name">eta</span> = l.dot(f)
  <span class="org-variable-name">noise</span> = np.random.uniform(1, s0, size=eta.shape)
  <span class="org-variable-name">w</span> = 1 / noise
  <span class="org-variable-name">x</span> = np.random.normal(loc=eta, scale=noise)
  <span class="org-variable-name">snr</span> = wnorm(eta, w) / wnorm(noise, w)
  <span class="org-keyword">return</span> x, w, eta, snr

<span class="org-keyword">def</span> <span class="org-function-name">rrmse</span>(pred, true):
  <span class="org-keyword">return</span> np.sqrt(np.linalg.norm(pred - true) / np.linalg.norm(true))

<span class="org-keyword">def</span> <span class="org-function-name">score_wlra</span>(x, w, eta, rank):
  <span class="org-variable-name">res</span> = wlra.wlra(x, w, rank=rank, max_iters=1000)
  <span class="org-keyword">return</span> rrmse(res, eta)

<span class="org-keyword">def</span> <span class="org-function-name">score_lra</span>(x, eta, rank):
  <span class="org-variable-name">u</span>, <span class="org-variable-name">d</span>, <span class="org-variable-name">vt</span> = skd.PCA(n_components=rank)._fit(x)
  <span class="org-variable-name">res</span> = np.einsum(<span class="org-string">'ij,j,jk-&gt;ik'</span>, u, d, vt)
  <span class="org-keyword">return</span> rrmse(res, eta)

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_gaussian_known_rank</span>(rank, num_trials=10):
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> trial <span class="org-keyword">in</span> <span class="org-builtin">range</span>(num_trials):
    <span class="org-variable-name">x</span>, <span class="org-variable-name">w</span>, <span class="org-variable-name">eta</span>, <span class="org-variable-name">snr</span> = simulate_gaussian(n=200, p=300, rank=rank, s0=10, seed=trial)
    result.append([trial,
                   snr,
                   score_lra(x, eta, rank=rank),
                   score_wlra(x, w, eta, rank=rank)])
  <span class="org-variable-name">result</span> = pd.DataFrame(result)
  <span class="org-variable-name">result.columns</span> = [<span class="org-string">'trial'</span>, <span class="org-string">'snr'</span>, <span class="org-string">'LRA'</span>, <span class="org-string">'WLRA'</span>]
  <span class="org-keyword">return</span> result
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">&lt;&lt;imports&gt;&gt;
&lt;&lt;gaussian-reconstruction&gt;&gt;
<span class="org-variable-name">results_gaussian_known_rank</span> = evaluate_gaussian_known_rank(rank=3, num_trials=100)
results_gaussian_known_rank.to_csv(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/wlra/gaussian-known-rank.txt.gz'</span>, compression=<span class="org-string">'gzip'</span>, sep=<span class="org-string">'\t'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=broadwl --job-name=gaussian-wlra
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate singlecell
python /project2/mstephens/aksarkar/projects/singlecell-ideas/code/gaussian-known-rank.py
</pre>
</div>

<pre class="example">
Submitted batch job 50097466

</pre>

<p>
Read the results.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">results_gaussian_known_rank</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/wlra/gaussian-known-rank.txt.gz'</span>, index_col=0)
</pre>
</div>

<p>
Plot the performance.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(3, 3)
plt.boxplot(x=results_gaussian_known_rank[[<span class="org-string">'LRA'</span>, <span class="org-string">'WLRA'</span>]].T, positions=<span class="org-builtin">range</span>(2), medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>})
plt.xticks(<span class="org-builtin">range</span>(2), [<span class="org-string">'LRA'</span>, <span class="org-string">'WLRA'</span>])
plt.xlabel(<span class="org-string">'Method'</span>)
<span class="org-variable-name">_</span> = plt.ylabel(<span class="org-string">'RRMSE'</span>)
</pre>
</div>


<div class="figure">
<p><img src="figure/wlra.org/gaussian-known-rank.png" alt="gaussian-known-rank.png">
</p>
</div>
</div>
</div>

<div id="outline-container-orge8a41c6" class="outline-4">
<h4 id="orge8a41c6">Poisson noise</h4>
<div class="outline-text-4" id="text-orge8a41c6">
<p>
We then consider the problem of recovering a planted low rank matrix, after
convolving with Poisson noise, assuming we know the rank.
</p>

<p>
\[ \eta_{ij} = (\mathbf{l f})_{ij} \]
\[ x_{ij} \sim \mathrm{Poisson}(\exp(\eta_{ij})) \]
</p>

<div class="org-src-container">
<pre class="src src-ipython" id="org95581f0"><span class="org-keyword">def</span> <span class="org-function-name">simulate_pois</span>(n, p, rank, seed=0):
  np.random.seed(seed)
  <span class="org-variable-name">l</span> = np.random.normal(size=(n, rank))
  <span class="org-variable-name">f</span> = np.random.normal(size=(rank, p))
  <span class="org-variable-name">eta</span> = l.dot(f)
  <span class="org-variable-name">x</span> = np.random.poisson(lam=np.exp(eta))
  <span class="org-keyword">return</span> x, eta

<span class="org-keyword">def</span> <span class="org-function-name">score_pois_lra</span>(x, eta, rank):
  <span class="org-variable-name">res</span> = wlra.pois_lra(x, rank=1)
  <span class="org-keyword">return</span> rrmse(res, eta)

<span class="org-keyword">def</span> <span class="org-function-name">evaluate_pois_known_rank</span>(rank, num_trials=10):
  <span class="org-variable-name">result</span> = []
  <span class="org-keyword">for</span> trial <span class="org-keyword">in</span> <span class="org-builtin">range</span>(num_trials):
    <span class="org-variable-name">x</span>, <span class="org-variable-name">eta</span> = simulate_pois(n=200, p=300, rank=1, seed=trial)
    result.append([trial,
                   score_lra(x, eta, rank=1),
                   score_pois_lra(x, eta, rank=1)])
  <span class="org-variable-name">result</span> = pd.DataFrame(result)
  <span class="org-variable-name">result.columns</span> = [<span class="org-string">'trial'</span>, <span class="org-string">'LRA'</span>, <span class="org-string">'Poisson LRA'</span>]
  <span class="org-keyword">return</span> result
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">&lt;&lt;imports&gt;&gt;
&lt;&lt;gaussian-reconstruction&gt;&gt;
&lt;&lt;poisson-reconstruction&gt;&gt;
<span class="org-variable-name">results_pois_known_rank</span> = evaluate_pois_known_rank(rank=1, num_trials=100)
results_pois_known_rank.to_csv(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/wlra/pois-known-rank.txt.gz'</span>, compression=<span class="org-string">'gzip'</span>, sep=<span class="org-string">'\t'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=broadwl --job-name=pois-lra
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">source</span> activate singlecell
python /project2/mstephens/aksarkar/projects/singlecell-ideas/code/pois-known-rank.py
</pre>
</div>

<pre class="example">
Submitted batch job 50100695

</pre>

<p>
Read the results.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">results_pois_known_rank</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/wlra/pois-known-rank.txt.gz'</span>, index_col=0)
</pre>
</div>

<p>
Plot the performance.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(3, 3)
plt.semilogy()
plt.boxplot(x=results_pois_known_rank[[<span class="org-string">'LRA'</span>, <span class="org-string">'Poisson LRA'</span>]].T,
            positions=<span class="org-builtin">range</span>(2),
            flierprops={<span class="org-string">'markersize'</span>: 4, <span class="org-string">'marker'</span>: <span class="org-string">'.'</span>, <span class="org-string">'markerfacecolor'</span>: <span class="org-string">'k'</span>},
            medianprops={<span class="org-string">'color'</span>: <span class="org-string">'k'</span>})
plt.xticks(<span class="org-builtin">range</span>(2), [<span class="org-string">'LRA'</span>, <span class="org-string">'Poisson LRA'</span>])
plt.xlabel(<span class="org-string">'Method'</span>)
<span class="org-variable-name">_</span> = plt.ylabel(<span class="org-string">'RRMSE'</span>)
</pre>
</div>


<div class="figure">
<p><img src="figure/wlra.org/pois-known-rank.png" alt="pois-known-rank.png">
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org8f29519" class="outline-3">
<h3 id="org8f29519">Imputing missing values</h3>
</div>

<div id="outline-container-orgd780580" class="outline-3">
<h3 id="orgd780580">Explaining held out data</h3>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2018-09-25 Tue 14:22</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
