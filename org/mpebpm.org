#+TITLE: Massively Parallel Empirical Bayes Poisson Means
#+SETUPFILE: setup.org

* Introduction
  :PROPERTIES:
  :CUSTOM_ID: introduction
  :END:

  The /Empirical Bayes Poisson Means/ (EBPM) problem is \( 
  \DeclareMathOperator\Gam{Gamma}
  \DeclareMathOperator\Poi{Poisson}
  \DeclareMathOperator\argmin{arg min}
  \newcommand\mf{\mathbf{F}} 
  \newcommand\ml{\mathbf{L}}
  \newcommand\mx{\mathbf{X}}
  \newcommand\vl{\mathbf{l}}
  \newcommand\vx{\mathbf{x}}
  \)

  \begin{align*}
    x_i \mid s_i, \lambda_i &\sim \Poi(s_i \lambda_i)\\
    \lambda_i &\sim g(\cdot) \in \mathcal{G},
  \end{align*}

  where the (primary) inference goal is to estimate \(g\) by maximizing the
  likelihood. In our prior work
  ([[https://dx.doi.org/10.1371/journal.pgen.1008045][Sarkar et al. 2019]]), we
  used this approach to estimate the mean and variance of gene expression from
  scRNA-seq data collected on a homogeneous sample of cells from each of a
  number of donor individuals, where we assumed \(\mathcal{G}\) was the family
  of point-Gamma distributions. This procedure removes the effect of variation
  introduced by the measurement process, leaving the variation in true gene
  expression levels which are of interest
  ([[http://dx.doi.org/10.1101/2020.04.07.030007][Sarkar and Stephens
  2020]]). In total, we solved 537,678 EBPM problems in parallel by formulating
  them as a single factor model

  \begin{align*}
    x_{ij} \mid x_{i+}, \lambda_{ij} &\sim \Poi(x_{i+} \lambda_{ij})\\
    \lambda_{ij} \mid \mu_{ij}, \phi_{ij}, \pi_{ij} &\sim \pi_{ij} \delta_0(\cdot) + (1 - \pi_{ij}) \Gam(\phi_{ij}^{-1}, \mu_{ij}^{-1} \phi_{ij}^{-1})\\
    \ln \mu_{ij} &= (\ml \mf_\mu')_{ij}\\
    \ln \phi_{ij} &= (\ml \mf_\phi')_{ij}\\
    \operatorname{logit} \pi_{ij} &= (\ml \mf_\pi')_{ij},
  \end{align*}

  where 

  - \(x_{ij}\) is the number of molecules of gene \(j = 1, \ldots, p\) observed
    in cell \(i = 1, \ldots, n\)
  - \(x_{i+} \triangleq \sum_j x_{ij}\) is the total number of molecules
    observed in sample \(i\)
  - cells are taken from \(m\) donor individuals, \(\ml\) is \(n \times m\),
    and each \(\mf_{(\cdot)}\) is \(p \times m\)
  - assignments of cells to donors (loadings) \(l_{ik} \in \{0, 1\}, k = 1,
    \ldots, m\) are known and fixed.

  We previously implemented maximum likelihood inference of this model via
  batch gradient descent in the Python package
  [[https://www.github.com/aksarkar/scqtl.git][scqtl]]. We have now developed a
  new Python package [[https://www.github.com/aksarkar/mpebpm.git][mpebpm]],
  which scales to much larger data sets. The key improvements are optimization
  using minibatch gradient descent and support for sparse matrices. Here, we
  evaluate the method on simulations and large biological data sets.

* Setup
  :PROPERTIES:
  :CUSTOM_ID: setup
  :END:

  #+BEGIN_SRC emacs-lisp :exports none
    (add-to-list 'python-shell-completion-native-disabled-interpreters "jupyter")
    (org-babel-lob-ingest "/home/aksarkar/.emacs.d/org-templates/library.org")
  #+END_SRC

  #+RESULTS:
  : 1

  #+CALL: ipython3(venv="singlecell",partition="gpu2",opts="--gres=gpu:1",memory="32G") :exports none :dir /scratch/midway2/aksarkar/singlecell/

  #+RESULTS:
  : Submitted batch job 1211797

  #+CALL: ipython3(venv="singlecell",partition="mstephens",memory="16G") :exports none :dir /scratch/midway2/aksarkar/singlecell/

  #+RESULTS:
  : Submitted batch job 1162416

  #+BEGIN_SRC ipython
    import anndata
    import loompy
    import mpebpm
    import numpy as np
    import os
    import pandas as pd
    import scipy.sparse as ss
    import scipy.special as sp
    import scipy.stats as st
    import scmodes
    import scqtl
    import time
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[1]:
  :END:

  #+BEGIN_SRC ipython
    %matplotlib inline
    %config InlineBackend.figure_formats = set(['retina'])
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[2]:
  :END:

  #+BEGIN_SRC ipython
    import matplotlib.pyplot as plt
    plt.rcParams['figure.facecolor'] = 'w'
    plt.rcParams['font.family'] = 'Nimbus Sans'
  #+END_SRC

  #+RESULTS:
  :RESULTS:
  # Out[3]:
  :END:

  #+BEGIN_SRC sh :results none :session tensorboard :dir /scratch/midway2/aksarkar/singlecell/
    srun --pty --partition=mstephens bash
    source activate singlecell
    tensorboard --host=$(hostname -i) --logdir=runs &
  #+END_SRC

* Results
  :PROPERTIES:
  :CUSTOM_ID: results
  :END:
** Accuracy of parameter estimation
   :PROPERTIES:
   :CUSTOM_ID: accuracy
   :END:

   We previously evaluated ~scqtl~
   [[https://jdblischak.github.io/singlecell-qtl/zinb.html#orgca44e7f][by
   simulating data from the model]].

   #+BEGIN_SRC ipython
     def evaluate(num_samples, num_mols, num_trials=10, **kwargs):
       # Important: generate all of the samples for each trial in one shot, and use
       # one-hot encoding to get separate estimates
       args = [(num_samples * num_trials, num_mols, log_mu, log_phi, logodds, None, None, None)
               for log_mu in np.linspace(-12, -6, 7)
               for log_phi in np.linspace(-4, 0, 5)
               for logodds in np.linspace(-3, 3, 7)]
       x = np.concatenate([scqtl.simulation.simulate(*a)[0][:,:1] for a in args], axis=1)
       x = ss.csr_matrix(x)
       s = num_mols * np.ones((x.shape[0], 1))
       onehot = np.zeros((num_samples * num_trials, num_trials))
       onehot[np.arange(onehot.shape[0]), np.arange(onehot.shape[0]) // num_samples] = 1
       onehot = ss.csr_matrix(onehot)

       log_mu, neg_log_phi, logodds, _ = mpebpm.ebpm_point_gamma(x, s=s, onehot=onehot, **kwargs)
       result = pd.DataFrame(
         [(a[0] // num_trials, int(a[1]), int(a[2]), int(a[3]), int(a[4]), a[-1], trial)
          for a in args
          for trial in range(num_trials)],
         columns=['num_samples', 'num_mols', 'log_mu', 'log_phi', 'logodds', 'fold', 'trial'])
       result['mean'] = np.exp(result['log_mu'])
       result['var'] = (1 - sp.expit(result['logodds'])) * np.exp(2 * result['log_mu'] + result['log_phi']) + sp.expit(-result['logodds']) * (1 - sp.expit(result['logodds'])) * np.exp(2 * result['log_mu'])

       result['log_mu_hat'] = log_mu.ravel(order='F')
       result['log_phi_hat'] = -neg_log_phi.ravel(order='F')
       result['logodds_hat'] = logodds.ravel(order='F')
       result['mean_hat'] = np.exp(result['log_mu_hat'])
       result['var_hat'] = (1 - sp.expit(result['logodds_hat'])) * np.exp(2 * result['log_mu_hat'] + result['log_phi_hat']) + sp.expit(-result['logodds_hat']) * (1 - sp.expit(result['logodds_hat'])) * np.exp(2 * result['log_mu_hat'])

       diagnostic = []
       for i in range(x.shape[1]):
         for j in range(onehot.shape[1]):
           idx = onehot.A[:,j].astype(bool)
           diagnostic.append(scqtl.diagnostic.diagnostic_test(
             x.A[idx,i].reshape(-1, 1),
             log_mu[j,i],
             -neg_log_phi[j,i],
             -logodds[j,i],
             num_mols,
             np.ones((num_samples, 1))))
       diagnostic = np.array(diagnostic)
       result['ks_d'] = diagnostic[:,0]
       result['ks_p'] = diagnostic[:,1]
       return result
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[53]:
   :END:

   Run the simulation.

   #+BEGIN_SRC ipython :async t
     result = evaluate(num_samples=100, num_mols=int(1e5), batch_size=32, max_epochs=200, verbose=True)
     result.to_csv('/scratch/midway2/aksarkar/ideas/mpebpm-sim.txt.gz', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[94]:
   :END:

   Read the results.

   #+BEGIN_SRC ipython
     result = pd.read_csv('/scratch/midway2/aksarkar/ideas/mpebpm-sim.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[7]:
   :END:

   Plot the estimated values against the ground truth values.

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/sim-params.png
     mu_pass = result['log_mu'] > -10
     pi_pass = result['logodds'] < 0

     plt.clf()
     fig, ax = plt.subplots(2, 3)
     fig.set_size_inches(8, 5)

     subset = result.loc[pi_pass]
     ax[0, 0].scatter(subset['log_mu'], subset['log_mu_hat'], s=2, c='k')
     ax[0, 0].set_xlim(-14, -5)
     ax[0, 0].set_ylim(ax[0, 0].get_xlim())
     ax[0, 0].plot(ax[0, 0].get_xlim(), ax[0, 0].get_xlim(), c='r', ls=':', lw=1)
     ax[0, 0].set_xlabel('True $\ln(\mu)$')
     ax[0, 0].set_ylabel('Estimated $\ln(\mu)$')

     ax[1, 0].set_xscale('log')
     ax[1, 0].set_yscale('log')
     ax[1, 0].scatter(subset['mean'], subset['mean_hat'], s=2, c='k')
     ax[1, 0].set_xlim(1e-6, 1e-2)
     ax[1, 0].set_ylim(ax[1, 0].get_xlim())
     ax[1, 0].plot(ax[1, 0].get_xlim(), ax[1, 0].get_xlim(), c='r', ls=':', lw=1)
     ax[1, 0].set_xlabel('True latent mean')
     ax[1, 0].set_ylabel('Estimated latent mean')

     subset = result.loc[np.logical_and.reduce(np.vstack([mu_pass, pi_pass]))]
     ax[0, 1].scatter(subset['log_phi'], subset['log_phi_hat'], s=2, c='k')
     ax[0, 1].set_xlim(-5, 2)
     ax[0, 1].set_ylim(ax[0, 1].get_xlim())
     ax[0, 1].plot(ax[0, 1].get_xlim(), ax[0, 1].get_xlim(), c='r', ls=':', lw=1)
     ax[0, 1].set_xlabel('True $\ln(\phi)$')
     ax[0, 1].set_ylabel('Estimated $\ln(\phi)$')

     ax[1, 1].set_xscale('log')
     ax[1, 1].set_yscale('log')
     ax[1, 1].scatter(subset['var'], subset['var_hat'], s=2, c='k')
     ax[1, 1].set_xlim(1e-9, 5e-5)
     ax[1, 1].set_ylim(ax[1, 1].get_xlim())
     ax[1, 1].plot(ax[1, 1].get_xlim(), ax[1, 1].get_xlim(), c='r', ls=':', lw=1)
     ax[1, 1].set_xlabel('True latent variance')
     ax[1, 1].set_ylabel('Estimated latent variance')

     subset = result.loc[pi_pass]
     ax[0, 2].scatter(subset['logodds'], subset['logodds_hat'], s=2, c='k')
     ax[0, 2].plot(ax[0, 2].get_xlim(), ax[0, 2].get_xlim(), c='r', ls=':', lw=1)
     ax[0, 2].set_xlabel('True $\mathrm{logit}(\pi)$')
     ax[0, 2].set_ylabel('Estimated $\mathrm{logit}(\pi)$')

     ax[1, 2].set_axis_off()
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[95]:
   [[file:figure/mpebpm.org/sim-params.png]]
   :END:

** Goodness of fit
   :PROPERTIES:
   :CUSTOM_ID: gof
   :END:

   We previously developed a test for goodness of fit, based on the fact that
   if \(x_{ij} \sim F_{ij}\), then \(F_{ij}(x_{ij}) \sim
   \operatorname{Uniform}(0, 1)\). We applied this test to the distributions
   estimated from the simulated data sets. Plot the histogram of
   goodness-of-fit \(p\)-values.

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/mpebpm-sim-gof.png
     plt.clf()
     plt.gcf().set_size_inches(2, 2)
     plt.hist(result['ks_p'], bins=np.linspace(0, 1, 11), density=True, color='0.7')
     plt.axhline(y=1, lw=1, ls=':', c='k')
     plt.xlim(0, 1)
     plt.xlabel('$p$-value')
     plt.ylabel('Density')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[96]:
   [[file:figure/mpebpm.org/mpebpm-sim-gof.png]]
   :END:

   Report the number (proportion) of simulation trials where the observed data
   significantly depart from the estimated distribution (\(p < 0.05\) after
   Bonferroni correction).

   #+BEGIN_SRC ipython
     sig = result.loc[result['ks_p'] < 0.05 / result.shape[0]]
     sig.shape[0], sig.shape[0] / result.shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[97]:
   : (0, 0.0)
   :END:

** Application to iPSCs
   :PROPERTIES:
   :CUSTOM_ID: ipsc
   :END:

   We previously generated scRNA-seq of 5,597 cells from 54 donors
   ([[https://dx.doi.org/10.1371/journal.pgen.1008045][Sarkar et
   al. 2019]]). Read the data, and remove the donor with evidence of
   contamination.

   #+BEGIN_SRC ipython
     x = anndata.read_h5ad('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/ipsc/ipsc.h5ad')
     x = x[x.obs.chip_id != 'NA18498']
     x.X
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[4]:
   #+BEGIN_EXAMPLE
     <5578x9957 sparse matrix of type '<class 'numpy.float32'>'
     with 39529537 stored elements in Compressed Sparse Row format>
   #+END_EXAMPLE
   :END:

   Prepare the data.

   #+BEGIN_SRC ipython
     # Important: the dense data will fit on the GPU
     y = x.X.A
     s = x.obs['mol_hs'].values.reshape(-1, 1)
     # Important: constructing this as a dense matrix will blow up memory for larger
     # data sets
     onehot = ss.coo_matrix((np.ones(x.shape[0]), (np.arange(x.shape[0]), pd.Categorical(x.obs['chip_id']).codes))).tocsr()
     # Important: center the matrix of dummy variables (batch), because there is no
     # baseline
     design = ss.coo_matrix(pd.get_dummies(x.obs['experiment'])).astype(float).A
     design -= design.mean(axis=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[323]:
   :END:

   Fit ~mpebpm~.

   #+BEGIN_SRC ipython :async t
     trial = 5
     num_epochs = 40
     batch_size = 64
     lr = 1e-2
     res1 = mpebpm.sgd.ebpm_gamma(
       y,
       s=s,
       onehot=onehot,
       batch_size=batch_size,
       shuffle=True,
       lr=lr,
       num_epochs=num_epochs,
       log_dir=f'runs/mpebpm/ipsc{trial}/init/')
     log_mu, neg_log_phi, logodds = mpebpm.sgd.ebpm_point_gamma(
       y,
       s=s,
       onehot=onehot,
       init=res1,
       batch_size=batch_size,
       shuffle=True,
       lr=lr,
       num_epochs=num_epochs,
       log_dir=f'runs/mpebpm/ipsc{trial}/fit/')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[342]:
   :END:

   Estimate log likelihood for each observation under Gamma and point-Gamma
   expression models.

   #+BEGIN_SRC ipython :async t
     mean = s.ravel() * onehot @ np.exp(res1[0])
     inv_disp = onehot @ np.exp(res1[1])
     nb_llik = (y * np.log(mean / inv_disp)
                - y * np.log(1 + mean / inv_disp)
                - inv_disp * np.log(1 + mean / inv_disp)
                + sp.gammaln(y + inv_disp)
                - sp.gammaln(inv_disp)
                - sp.gammaln(y + 1))

     mean = s.ravel() * onehot @ np.exp(log_mu)
     inv_disp = onehot @ np.exp(neg_log_phi)
     temp = (y * np.log(mean / inv_disp)
                - y * np.log(1 + mean / inv_disp)
                - inv_disp * np.log(1 + mean / inv_disp)
                + sp.gammaln(y + inv_disp)
                - sp.gammaln(inv_disp)
                - sp.gammaln(y + 1))
     case_zero = -np.log1p(np.exp(onehot @ -logodds)) + np.log1p(np.exp(temp - (onehot @ logodds)))
     case_non_zero = -np.log1p(np.exp(onehot @ logodds)) + temp
     zinb_llik = np.where(y < 1, case_zero, case_non_zero)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[343]:
   :END:

   Take the best model for each donor/gene combination, then evaluate the full
   data log likelihood.

   #+BEGIN_SRC ipython
     L = np.tensordot(onehot.T.A, np.stack([nb_llik, zinb_llik], axis=-1), 1)
     L.max(axis=-1).sum() / np.prod(y.shape)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[344]:
   : -51.14861191512254
   :END:

   Evaluate the proportion of times each model was the best fit for donor/gene
   combinations.

   #+BEGIN_SRC ipython
     pd.Series({k: v for k, v in zip(
       ['gamma', 'point_gamma'],
       np.histogram(L.argmax(axis=-1), bins=np.arange(3))[0])}) / np.prod(L.shape[:2])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[345]:
   #+BEGIN_EXAMPLE
     gamma          0.311343
     point_gamma    0.688657
     dtype: float64
   #+END_EXAMPLE
   :END:

   Test each individual-gene combination for goodness-of-fit to the
   ~mpebpm~-estimated distribution.

   #+BEGIN_SRC ipython :async t
     result = dict()
     for j in range(x.shape[1]):
       for k, donor in enumerate(pd.Categorical(x.obs['chip_id']).categories):
         idx = onehot[:,k].A.ravel().astype(bool)
         size = s[idx].ravel()
         if L[k,j,0] > L[k,j,1]:
           d, p = scmodes.benchmark.gof._gof(
             y[idx,j],
             cdf=scmodes.benchmark.gof._zig_cdf,
             pmf=scmodes.benchmark.gof._zig_pmf,
             size=size,
             log_mu=res1[0][k,j],
             log_phi=-res1[1][k,j])
         else:
           d, p = scmodes.benchmark.gof._gof(
             y[idx,j],
             cdf=scmodes.benchmark.gof._zig_cdf,
             pmf=scmodes.benchmark.gof._zig_pmf,
             size=size,
             log_mu=log_mu[k,j],
             log_phi=-neg_log_phi[k,j],
             logodds=logodds[k,j])
         result[(donor, x.var.iloc[j].name)] = pd.Series({'stat': d, 'p': p})
     result = pd.DataFrame.from_dict(result, orient='index')
     result.index.names = ['donor', 'gene']
     result = result.reset_index()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[346]:
   :END:

   Write out the GOF tests.

   #+BEGIN_SRC ipython
     result.to_csv('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-gof.txt.gz', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[337]:
   :END:

   Plot the histogram of GOF \(p\)-values.

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/mpebpm-ipsc-gof.png
     plt.clf()
     plt.gcf().set_size_inches(2, 2)
     plt.hist(result['p'], bins=np.linspace(0, 1, 11), color='0.7', density=True)
     plt.axhline(y=1, lw=1, ls=':', c='k')
     plt.xlim(0, 1)
     plt.xlabel('$p$-value')
     plt.ylabel('Density')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[347]:
   [[file:figure/mpebpm.org/mpebpm-ipsc-gof.png]]
   :END:

   Report how many individual-gene combinations (proportion) depart
   significantly from the estimated distribution.

   #+BEGIN_SRC ipython
     sig = result.loc[result['p'] < 0.05 / result.shape[0]]
     sig.shape[0], sig.shape[0] / result.shape[0]
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[348]:
   : (65, 0.000123171145359006)
   :END:

   Look at one of the examples where the data depart from the estimated
   distribution.

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/mpebpm-ipsc-ex.png
     plt.clf()
     fig, ax = plt.subplots(2, 1)
     fig.set_size_inches(6, 4)
     query = x[x.obs['chip_id'] == sig.iloc[0]['donor'], x.var.index == sig.iloc[0]['gene']].X.A.ravel()
     ax[0].hist(query, bins=np.arange(query.max() + 1), color='k')
     ax[0].set_xlabel('Number of molecules')
     ax[0].set_ylabel('Number of cells')
     ax[0].set_title(x.var.loc[sig.iloc[0]['gene'], 'name'])

     grid = np.linspace(0, 1e-3, 1000)
     j = list(x.var.index).index(sig.iloc[0]['gene'])
     k = list(pd.Categorical(x.obs['chip_id']).categories).index(sig.iloc[0]['donor'])
     ax[1].plot(grid, st.gamma(a=np.exp(neg_log_phi[k,j]), scale=np.exp(log_mu[k,j] - neg_log_phi[k,j])).cdf(grid), c='k', lw=1)
     ax[1].set_xlabel('Latent gene expression')
     ax[1].set_ylabel('CDF')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[349]:
   [[file:figure/mpebpm.org/mpebpm-ipsc-ex.png]]
   :END:

   Report all genes at which the data depart from the estimated distribution
   for at least one individual.

   #+BEGIN_SRC ipython
     x.var.merge(sig, left_index=True, right_on='gene', how='inner')['name'].unique()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[350]:
   #+BEGIN_EXAMPLE
     array(['NUP98', 'B4GALT5', 'ANXA5', 'RHOG', 'MT-CO2', 'MT-CYB', 'MT-ND2',
     'MT-ND4', 'MT-ATP6', 'MT-CO3', 'MT-ND4L'], dtype=object)
   #+END_EXAMPLE
   :END:

** Confounder correction in iPSC data
   :PROPERTIES:
   :CUSTOM_ID: confounders
   :END:

   Repeat the analysis, including C1 chip as a covariate. Report the wall clock
   time for the analysis, in minutes.

   #+BEGIN_SRC ipython :async t
     start = time.time()
     log_mu1, neg_log_phi1, logodds1, bhat1 = mpebpm.sgd.ebpm_point_gamma(
       y,
       s=s,
       onehot=onehot,
       design=design,
       batch_size=64,
       lr=1e-2,
       max_epochs=100,
       verbose=True)
     elapsed = time.time() - start
     np.save('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-design-log-mu', log_mu)
     np.save('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-design-neg-log-phi', neg_log_phi)
     np.save('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-design-logodds', logodds)
     np.save('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-design-bhat', bhat)
     elapsed / 60
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[34]:
   : 3.198907784620921
   :END:

   Read the ~mpebpm~ and ~scqtl~ estimates.

   #+BEGIN_SRC ipython
     log_mu1 = np.load('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-design-log-mu.npy')
     neg_log_phi1 = np.load('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-design-neg-log-phi.npy')
     logodds1 = np.load('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-design-logodds.npy')
     bhat1 = np.load('/scratch/midway2/aksarkar/ideas/mpebpm-ipsc-design-bhat.npy')

     log_mu2 = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-mu.txt.gz', index_col=0, sep=' ')
     log_phi2 = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-log-phi.txt.gz', index_col=0, sep=' ')
     logodds2 = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/zi2-logodds.txt.gz', index_col=0, sep=' ')
     bhat2 = pd.read_table('/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design1/beta.txt.gz', index_col=0, sep=' ')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   :END:

   Compute the full data log likelihood at the ~mpebpm~ solution.

   #+BEGIN_SRC ipython :async t
     mean = s.ravel() * onehot @ np.exp(log_mu1) * np.exp(design @ bhat1)
     inv_disp = onehot @ np.exp(neg_log_phi1)
     nb_llik = (y * np.log(mean / inv_disp)
                - y * np.log(1 + mean / inv_disp)
                - inv_disp * np.log(1 + mean / inv_disp)
                # Important: these terms are why we use inverse dispersion
                + sp.gammaln(y + inv_disp)
                - sp.gammaln(inv_disp)
                - sp.gammaln(y + 1))
     case_zero = -np.log1p(np.exp(onehot @ -logodds1)) + np.log1p(np.exp(nb_llik - (onehot @ logodds1)))
     case_non_zero = -np.log1p(np.exp(onehot @ logodds1)) + nb_llik
     np.where(y < 1, case_zero, case_non_zero).mean()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[96]:
   : -222.59761148808386
   :END:

   Compute the full data log likelihood at the ~scqtl~ solution.

   #+BEGIN_SRC ipython :async t
     mean = s.ravel() * onehot @ np.exp(log_mu2.values.T) * np.exp(design @ bhat2.values.T)
     inv_disp = onehot @ np.exp(-log_phi2.values.T)
     nb_llik = (y * np.log(mean / inv_disp)
                - y * np.log(1 + mean / inv_disp)
                - inv_disp * np.log(1 + mean / inv_disp)
                # Important: these terms are why we use inverse dispersion
                + sp.gammaln(y + inv_disp)
                - sp.gammaln(inv_disp)
                - sp.gammaln(y + 1))
     case_zero = -np.log1p(np.exp(onehot @ -logodds2.values.T)) + np.log1p(np.exp(nb_llik - (onehot @ logodds2.values.T)))
     case_non_zero = -np.log1p(np.exp(onehot @ logodds2.values.T)) + nb_llik
     np.where(y < 1, case_zero, case_non_zero).mean()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[114]:
   : -349.2031033227098
   :END:

   Compare the ~mpebpm~ estimates with and without correcting for batch.

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/mpebpm-ipsc-design.png
     plt.clf()
     fig, ax = plt.subplots(1, 3)
     fig.set_size_inches(7, 2.5)

     ax[0].scatter(log_mu.ravel(), log_mu1.ravel(), s=1, c='k', alpha=0.1)
     ax[0].set_xlim(ax[0].get_ylim())
     ax[0].plot(ax[0].get_xlim(), ax[0].get_ylim(), lw=1, ls=':', c='r')
     ax[0].set_xlabel('Est $\log(\mu)$')
     ax[0].set_ylabel('Corrected est $\log(\mu)$')

     ax[1].scatter(-neg_log_phi.ravel(), -neg_log_phi1.ravel(), s=1, c='k', alpha=0.1)
     ax[1].set_xlim(ax[1].get_ylim())
     ax[1].plot(ax[1].get_xlim(), ax[1].get_ylim(), lw=1, ls=':', c='r')
     ax[1].set_xlabel('Est $\log(\phi)$')
     ax[1].set_ylabel('Corrected est $\log(\phi)$')

     ax[2].scatter(logodds.ravel(), logodds1.ravel(), s=1, c='k', alpha=0.1)
     ax[2].set_xlim(ax[2].get_ylim())
     ax[2].plot(ax[2].get_xlim(), ax[2].get_ylim(), lw=1, ls=':', c='r')
     ax[2].set_xlabel('Est $\mathrm{logit}(\pi)$')
     ax[2].set_ylabel('Corrected est $\mathrm{logit}(\pi)$')

     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[37]:
   [[file:figure/mpebpm.org/mpebpm-ipsc-design.png]]
   :END:

   Compare the ~mpebpm~ estimate against the ~scqtl~ estimate (with confounder
   correction).

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/scqtl-mpebpm-design.png
     plt.clf()
     fig, ax = plt.subplots(2, 2)
     fig.set_size_inches(5, 5)

     ax[0,0].scatter(log_mu2.values.ravel(order='F'), log_mu1.ravel(), s=1, c='k', alpha=0.1)
     ax[0,0].set_xlim(ax[0,0].get_ylim())
     ax[0,0].plot(ax[0,0].get_xlim(), ax[0,0].get_ylim(), lw=1, ls=':', c='r')
     ax[0,0].set_xlabel('scqtl $\log(\mu)$')
     ax[0,0].set_ylabel('mpebpm est $\log(\mu)$')

     ax[0,1].scatter(log_phi2.values.ravel(order='F'), -neg_log_phi1.ravel(), s=1, c='k', alpha=0.1)
     ax[0,1].set_xlim(ax[0,1].get_ylim())
     ax[0,1].plot(ax[0,1].get_xlim(), ax[0,1].get_ylim(), lw=1, ls=':', c='r')
     ax[0,1].set_xlabel('scqtl est $\log(\phi)$')
     ax[0,1].set_ylabel('mpebpm est $\log(\phi)$')

     ax[1,0].scatter(logodds2.values.ravel(order='F'), logodds1.ravel(), s=1, c='k', alpha=0.1)
     ax[1,0].set_xlim(ax[1,0].get_ylim())
     ax[1,0].plot(ax[1,0].get_xlim(), ax[1,0].get_ylim(), lw=1, ls=':', c='r')
     ax[1,0].set_xlabel('scqtl est $\mathrm{logit}(\pi)$')
     ax[1,0].set_ylabel('mpebpm est $\mathrm{logit}(\pi)$')

     ax[1,1].scatter(bhat2.values.ravel(order='F'), bhat1.ravel(), s=1, c='k', alpha=0.1)
     ax[1,1].set_xlim(ax[1,1].get_ylim())
     ax[1,1].plot(ax[1,1].get_xlim(), ax[1,1].get_ylim(), lw=1, ls=':', c='r')
     ax[1,1].set_xlabel(r'scqtl est $\beta$')
     ax[1,1].set_ylabel(r'mpebpm est $\beta$')

     for a in ax.ravel():
       a.set_aspect('equal')
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[112]:
   [[file:figure/mpebpm.org/scqtl-mpebpm-design.png]]
   :END:

   Compare the ~mpebpm~ estimated mean latent gene expression against the
   ~scqtl~ estimate.

   #+BEGIN_SRC ipython
     mean1 = -np.log1p(np.exp(logodds1)) + log_mu1
     mean2 = -np.log1p(np.exp(logodds2)) + log_mu2
   #+END_SRC

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/mpebpm-scqtl-ipsc-latent-mean.png
     plt.clf()
     plt.gcf().set_size_inches(2.5, 2.5)
     plt.scatter(mean1.ravel(), mean2.values.ravel(order='F'), c='k', s=1, alpha=0.1)
     plt.xlim(plt.ylim())
     plt.plot(plt.xlim(), plt.ylim(), lw=1, ls=':', c='r')
     plt.xlabel('mpebpm log latent mean')
     plt.ylabel('scqtl log latent mean')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[10]:
   [[file:figure/mpebpm.org/mpebpm-scqtl-ipsc-latent-mean.png]]
   :END:

** Comparison to previous approach

   For comparison, this analysis previously required 395 minutes using
   ~scqtl~. Read the previously estimated parameters, and estimate the full
   data log likelihood.

   #+BEGIN_SRC ipython
     log_mu0 = pd.read_table("/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design0/zi2-log-mu.txt.gz", index_col=0, sep=' ')
     log_phi0 = pd.read_table("/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design0/zi2-log-phi.txt.gz", index_col=0, sep=' ')
     logodds0 = pd.read_table("/project2/mstephens/aksarkar/projects/singlecell-qtl/data/density-estimation/design0/zi2-logodds.txt.gz", index_col=0, sep=' ')
     del log_mu0['NA18498']
     del log_phi0['NA18498']
     del logodds0['NA18498']
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[113]:
   :END:

   #+BEGIN_SRC ipython :async t
     mean0 = s.ravel() * onehot @ np.exp(log_mu0.values.T)
     inv_disp0 = onehot @ np.exp(-log_phi0.values.T)
     nb_llik = (y * np.log(mean0 / inv_disp0)
                - y * np.log(1 + mean0 / inv_disp0)
                - inv_disp0 * np.log(1 + mean0 / inv_disp0)
                + sp.gammaln(y + inv_disp0)
                - sp.gammaln(inv_disp0)
                - sp.gammaln(y + 1))
     case_zero = -np.log1p(np.exp(onehot @ -logodds0.values.T)) + np.log1p(np.exp(nb_llik - (onehot @ logodds0.values.T)))
     case_non_zero = -np.log1p(np.exp(onehot @ logodds0.values.T)) + nb_llik
     np.where(y < 1, case_zero, case_non_zero).mean()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[92]:
   : -244.56285324910596
   :END:

** Application to Census of Immune Cells
   :PROPERTIES:
   :CUSTOM_ID: immune-census
   :END:

   The
   [[https://data.humancellatlas.org/explore/projects/cc95ff89-2e68-4a08-a234-480eca21ce79][Census
   of Immune Cells]] is part of the Human Cell Atlas. Currently, it comprises
   scRNA-seq data of 593,844 cells from 16 donors. The cells vary in donor sex,
   donor ancestry, tissue of origin, as well as (latent) cell
   types/subtypes/states within each donor.

   #+BEGIN_SRC ipython :results output html verbatim
     with loompy.connect('/project2/mstephens/aksarkar/projects/singlecell-ideas/data/human-cell-atlas/immune-cell-census.loom') as con:
       metadata = pd.DataFrame(np.hstack([
         con.ca['derived_organ_parts_label', 'donor_organism.human_specific.ethnicity.ontology_label'],
         con.ca['donor_organism.provenance.document_id', 'donor_organism.sex']]))
       print(metadata.groupby([0,3,1,2]).agg(len).to_frame().to_html(classes='table'))
   #+END_SRC

   #+RESULTS:
   #+BEGIN_EXPORT html
   <table border="1" class="dataframe table">
     <thead>
       <tr style="text-align: right;">
         <th></th>
         <th></th>
         <th></th>
         <th></th>
         <th>0</th>
       </tr>
       <tr>
         <th>0</th>
         <th>3</th>
         <th>1</th>
         <th>2</th>
         <th></th>
       </tr>
     </thead>
     <tbody>
       <tr>
         <th rowspan="8" valign="top">bone marrow</th>
         <th rowspan="4" valign="top">female</th>
         <th rowspan="4" valign="top">European</th>
         <th>085e737d-adb5-4597-bd54-5ebeda170038</th>
         <td>49716</td>
       </tr>
       <tr>
         <th>af7fe7a6-7d7e-4cdf-9799-909680fa9a3f</th>
         <td>44584</td>
       </tr>
       <tr>
         <th>cf514c66-88b2-45e4-a397-7fb362ae9950</th>
         <td>48630</td>
       </tr>
       <tr>
         <th>fb30bb83-0278-4117-bd42-e2e8dddfedfe</th>
         <td>49839</td>
       </tr>
       <tr>
         <th rowspan="4" valign="top">male</th>
         <th rowspan="2" valign="top">African American</th>
         <th>d23515a7-e182-4bc6-89e2-b1635885c0ec</th>
         <td>51239</td>
       </tr>
       <tr>
         <th>eb8fb36b-6e02-41c4-8760-3eabbde6bacb</th>
         <td>51024</td>
       </tr>
       <tr>
         <th rowspan="2" valign="top">European</th>
         <th>0a6c46dd-0905-4581-95eb-d89eef8a7213</th>
         <td>47167</td>
       </tr>
       <tr>
         <th>9aaf8a07-924f-456c-86dc-82f5da718246</th>
         <td>48784</td>
       </tr>
       <tr>
         <th rowspan="8" valign="top">umbilical cord blood</th>
         <th rowspan="3" valign="top">female</th>
         <th>Asian</th>
         <th>e4b5115d-3a0d-4c50-aba4-04b5f76810da</th>
         <td>57893</td>
       </tr>
       <tr>
         <th rowspan="2" valign="top">European</th>
         <th>4a404c91-0dbf-4246-bc23-d13aff961ba7</th>
         <td>45078</td>
       </tr>
       <tr>
         <th>509c507c-4759-452f-994e-d134d90329fd</th>
         <td>39584</td>
       </tr>
       <tr>
         <th rowspan="5" valign="top">male</th>
         <th>African American</th>
         <th>0b91cb1f-e2a8-413a-836c-1d38e7af3f2d</th>
         <td>54544</td>
       </tr>
       <tr>
         <th rowspan="2" valign="top">European</th>
         <th>53af872d-b838-44d6-ae1b-25b56405483c</th>
         <td>62609</td>
       </tr>
       <tr>
         <th>6072d1f5-aa0c-4ab1-a8a6-a00ab479a1ba</th>
         <td>52142</td>
       </tr>
       <tr>
         <th rowspan="2" valign="top">nan</th>
         <th>31f89559-2682-4bbc-84c6-826dfe4a4e39</th>
         <td>29455</td>
       </tr>
       <tr>
         <th>4e98f612-15ec-44ab-b5f9-39787f92b01a</th>
         <td>50571</td>
       </tr>
     </tbody>
   </table>
   #+END_EXPORT

   To demonstrate the scalability of ~mpebpm~, fit a point-Gamma distribution
   to each gene in each donor, resulting in 254,432 EBPM problems. We
   [[https://aksarkar.github.io/singlecell-modes/immune-census.html#orgc2a066a][previously
   pre-processed the data]] to ~npz~ format, which is much faster to read than
   ~h5ad~ or ~loom~.

   #+BEGIN_SRC ipython :async t
     y_csr = ss.load_npz('/scratch/midway2/aksarkar/modes/immune-cell-census.npz')
     genes = pd.read_csv('/scratch/midway2/aksarkar/modes/immune-cell-census-genes.txt.gz', sep='\t', index_col=0)
     donor = pd.read_csv('/scratch/midway2/aksarkar/modes/immune-cell-census-samples.txt.gz', sep='\t', index_col=0)['0']
     onehot = ss.csr_matrix(pd.get_dummies(donor).values)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[5]:
   :END:

   Remove genes which only have zero observations in some donor.

   #+BEGIN_SRC ipython :async t
     # Important: CSC needed to subset on columns (genes)
     y_csc = y_csr.tocsc()
     keep = (((y_csc.T @ onehot) > 0).sum(axis=1) == onehot.shape[1]).A.ravel()
     genes = genes.loc[keep]
     y_csc = y_csc[:,keep]
     y_csr = y_csc.tocsr()
     s = y_csr.sum(axis=1).A.ravel()
     y_csr
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[6]:
   #+BEGIN_EXAMPLE
     <593844x15902 sparse matrix of type '<class 'numpy.int32'>'
     with 550918891 stored elements in Compressed Sparse Row format>
   #+END_EXAMPLE
   :END:

   Fit ~mpebpm~ (6 minutes/epoch).

   #+BEGIN_SRC ipython :async t
     # This converges quickly
     init = mpebpm.sgd.ebpm_gamma(
       y_csr, onehot=onehot, batch_size=128, lr=1e-2,
       max_epochs=1, shuffle=True)
     logdir = 'runs/mpebpm6'
     os.mkdir(logdir)
     log_mu, neg_log_phi, logodds = mpebpm.sgd.ebpm_point_gamma(
       y_csr, onehot=onehot, init=init, batch_size=128, lr=1e-2,
       max_epochs=5, shuffle=True, logdir=logdir)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[39]:
   :END:

   #+BEGIN_SRC ipython
     pd.DataFrame(log_mu, index=donor.unique(), columns=genes['featurekey']).to_csv('/scratch/midway2/aksarkar/ideas/mpebpm-immune-census-log-mu.txt.gz', sep='\t')
     pd.DataFrame(neg_log_phi, index=donor.unique(), columns=genes['featurekey']).to_csv('/scratch/midway2/aksarkar/ideas/mpebpm-immune-census-neg-log-phi.txt.gz', sep='\t')
     pd.DataFrame(logodds, index=donor.unique(), columns=genes['featurekey']).to_csv('/scratch/midway2/aksarkar/ideas/mpebpm-immune-census-logodds.txt.gz', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[40]:
   :END:

   Read the estimated parameters.

   #+BEGIN_SRC ipython
     log_mu = pd.read_csv('/scratch/midway2/aksarkar/ideas/mpebpm-immune-census-log-mu.txt.gz', sep='\t', index_col=0)
     neg_log_phi = pd.read_csv('/scratch/midway2/aksarkar/ideas/mpebpm-immune-census-neg-log-phi.txt.gz', sep='\t', index_col=0)
     logodds = pd.read_csv('/scratch/midway2/aksarkar/ideas/mpebpm-immune-census-logodds.txt.gz', sep='\t', index_col=0)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[41]:
   :END:

   Test each donor-gene combination for goodness-of-fit to the
   ~mpebpm~-estimated distribution.

   #+BEGIN_SRC ipython :async t
     result = dict()
     for j in range(y_csr.shape[1]):
       query = y_csc[:,j].tocsr()
       for k, name in enumerate(donor.unique()):
         # Important: scqtl.diagnostic blows up memory for some reason
         idx = onehot[:,k].tocsc().indices
         d, p = scmodes.benchmark.gof._gof(
            query[idx].A.ravel(),
            cdf=scmodes.benchmark.gof._zig_cdf,
            pmf=scmodes.benchmark.gof._zig_pmf,
            size=s[idx],
            log_mu=log_mu.iloc[k,j],
            log_phi=-neg_log_phi.iloc[k,j],
            logodds=logodds.iloc[k,j])
         result[(name, genes.iloc[j]['Gene'])] = pd.Series({'stat': d, 'p': p})
     result = pd.DataFrame.from_dict(result, orient='index')
     result.index.names = ['donor', 'gene']
     result = result.reset_index()
     result.to_csv('/scratch/midway2/aksarkar/ideas/mpebpm-immune-census-gof.txt.gz', sep='\t')
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[16]:
   :END:

   Plot the histogram of GOF \(p\)-values.

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/mpebpm-immune-census-gof.png
     plt.clf()
     plt.gcf().set_size_inches(2, 2)
     plt.hist(result['p'], bins=np.linspace(0, 1, 11), color='0.7', density=True)
     plt.axhline(y=1, lw=1, ls=':', c='k')
     plt.xlabel('$p$-value')
     plt.ylabel('Density')
     plt.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[17]:
   [[file:figure/mpebpm.org/mpebpm-immune-census-gof.png]]
   :END:

   Look at an example.

   #+BEGIN_SRC ipython
     j = 1
     k = 0
     query = y_csc[:,k].tocsr()
     idx = onehot[:,j].tocsc().indices
     x = query[idx].A.ravel()
   #+END_SRC

   #+BEGIN_SRC ipython :async t
     scmodes.benchmark.gof._gof(
       x, 
       cdf=scmodes.benchmark.gof._zig_cdf,
       pmf=scmodes.benchmark.gof._zig_pmf,
       size=s[idx],
       log_mu=init[0][k,j],
       log_phi=-init[1][k,j],)
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[44]:
   : KstestResult(statistic=0.14346460385738558, pvalue=0.0)
   :END:


   #+BEGIN_SRC ipython :async t
     scmodes.benchmark.gof._gof(
       x, 
       cdf=scmodes.benchmark.gof._zig_cdf,
       pmf=scmodes.benchmark.gof._zig_pmf,
       size=s[idx],
       log_mu=log_mu.iloc[k,j],
       log_phi=-neg_log_phi.iloc[k,j],
       logodds=logodds.iloc[k,j])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[42]:
   : KstestResult(statistic=0.13278115317033756, pvalue=0.0)
   :END:

   #+BEGIN_SRC ipython :async t
     res1 = scmodes.ebpm.ebpm_point_gamma(x, s[idx].ravel())
     scmodes.benchmark.gof._gof(
       x, 
       cdf=scmodes.benchmark.gof._zig_cdf,
       pmf=scmodes.benchmark.gof._zig_pmf,
       size=s[idx],
       log_mu=res1[0],
       log_phi=-res1[1],
       logodds=res1[2])
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[9]:
   : KstestResult(statistic=0.006399062002559908, pvalue=0.1017356159621166)
   :END:

   Compare the negative log likelihood for this gene in this individual.

   #+BEGIN_SRC ipython
     pd.Series({'scmodes': scmodes.ebpm.wrappers._zinb_obj(res1[:-1], x, s[idx]),
                'mpebpm': scmodes.ebpm.wrappers._zinb_obj([log_mu.iloc[k,j], neg_log_phi.iloc[k,j], logodds.iloc[k,j]], x, s[idx])})
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[45]:
   #+BEGIN_EXAMPLE
     scmodes     858.372281
     mpebpm     7139.640261
     dtype: float64
   #+END_EXAMPLE
   :END:

   #+BEGIN_SRC ipython :ipyfile figure/mpebpm.org/ic-dpm1.png
     cm = plt.get_cmap('Paired')
     plt.clf()
     fig, ax = plt.subplots(2, 1)
     fig.set_size_inches(5, 3.5)

     grid = np.arange(x.max() + 2)
     ax[0].hist(x, bins=grid, color='k')
     ax[0].set_xticks(grid)
     ax[0].set_xlabel('Number of molecules')
     ax[0].set_ylabel('Number of cells')
     ax[0].set_title(genes.iloc[1]['Gene'])

     grid = np.linspace(0, 1e-5, 1000)
     pi0 = sp.expit(logodds.iloc[k,j])
     F = pi0 + (1 - pi0) * st.gamma(a=np.exp(-neg_log_phi.iloc[k,j]), scale=np.exp(log_mu.iloc[k,j] - neg_log_phi.iloc[k,j])).cdf(grid)
     ax[1].plot(grid, F, c=cm(0), lw=1, label='mpebpm')

     pi0 = sp.expit(res1[2])
     F = pi0 + (1 - pi0) * st.gamma(a=np.exp(-res1[1]), scale=np.exp(res1[0] - res1[1])).cdf(grid)
     ax[1].plot(grid, F, c=cm(1), lw=1, label='scmodes')
     ax[1].set_xlabel('Latent gene expression')
     ax[1].set_ylabel('CDF')
     ax[1].legend(frameon=False)
     fig.tight_layout()
   #+END_SRC

   #+RESULTS:
   :RESULTS:
   # Out[46]:
   [[file:figure/mpebpm.org/ic-dpm1.png]]
   :END:
