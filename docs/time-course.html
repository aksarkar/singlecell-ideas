<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2020-05-14 Thu 23:52 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Fully unsupervised topic models of scRNA-seq time course data</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Abhishek Sarkar">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<link href="bootstrap.min.css" rel="stylesheet" />
<link rel="stylesheet" type="text/css" href="htmlize.css"/>
<link rel="stylesheet" type="text/css" href="main.css"/>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Fully unsupervised topic models of scRNA-seq time course data</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#org65b71e4">Introduction</a></li>
<li><a href="#setup">Setup</a></li>
<li><a href="#org9e18411">Methods</a>
<ul>
<li><a href="#org82c213b">Amortized NMF</a></li>
<li><a href="#org59bb306">Amortized LDA</a></li>
<li><a href="#orgb998252">iPSC data</a></li>
<li><a href="#orgf25e3a5">iPSC CM data</a></li>
<li><a href="#org2019ba5">10-way mixture</a></li>
<li><a href="#org6f10d4c">Census of Immune Cells</a></li>
<li><a href="#orga01414f">Mouse Organogenesis Cell Atlas</a></li>
</ul>
</li>
<li><a href="#org1f866f5">Results</a>
<ul>
<li><a href="#org0f4b4a8">Simulation</a></li>
<li><a href="#org016b06e">ANMF on iPSC data</a></li>
<li><a href="#org5a20b29">NMF on iPSC-CM data</a></li>
<li><a href="#orgca6e596">ANMF on 68K PBMCs</a></li>
<li><a href="#org8fe675b">ANMF on 10-way mixture</a></li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-org65b71e4" class="outline-2">
<h2 id="org65b71e4">Introduction</h2>
<div class="outline-text-2" id="text-org65b71e4">
<p>
In our prior work (<a href="https://dx.doi.org/10.1371/journal.pgen.1008045">Sarkar
et al. 2019</a>), we introduced a factor model to capture between donor
individual variation in the mean and variance of gene expression in a single
cell type \( 
  \DeclareMathOperator\Gam{Gamma}
  \DeclareMathOperator\Poi{Poisson}
  \DeclareMathOperator\argmin{arg min}
  \newcommand\mf{\mathbf{F}} 
  \newcommand\ml{\mathbf{L}}
  \newcommand\mx{\mathbf{X}}
  \newcommand\vl{\mathbf{l}}
  \newcommand\vx{\mathbf{x}}
  \)
</p>

\begin{align*}
  x_{ij} &\sim \Poi(x_i^+ \lambda_{ij})\\
  \lambda_{ij} &\sim \pi_{ij} \delta_0(\cdot) + (1 - \pi_{ij}) \Gam(\phi_{ij}^{-1}, \mu_{ij}^{-1} \phi_{ij}^{-1})\\
  \ln \mu_{ij} &= (\ml \mf_\mu')_{ij}\\
  \ln \phi_{ij} &= (\ml \mf_\phi')_{ij}\\
  \operatorname{logit} \pi_{ij} &= (\ml \mf_\pi')_{ij}\\
\end{align*}

<p>
where 
</p>

<ul class="org-ul">
<li>\(x_{ij}\) is the number of molecules of gene \(j = 1, \ldots, p\) observed
in cell \(i = 1, \ldots, n\)</li>
<li>cells are taken from \(m\) donor individuals, \(\ml\) is \(n \times m\),
each \(\mf_{\cdot}\) is \(p \times m\)</li>
<li>assignments of cells to donors (loadings) \(l_{ik} \in \{0, 1\}\) are
known and fixed.</li>
</ul>

<p>
We are now interested in several lines of questions:
</p>

<ol class="org-ol">
<li>If we analyze this kind of data in a fully unsupervised manner, can we
recover the assignments of cells to donors? This approach has been
previously proposed in our specific factor model
(<a href="10.1038/s41467-017-02554-5">Risso et al. 2018</a>). If not, what do
we recover?</li>
<li>Can we generalize this analysis approach to data which additionally has
multiple cell types, and then multiple time points?</li>
<li>Can we implement this approach without forming entire products
\(\ml\mf'\)? Can we implement each update without looking at the entire
data \(\mx\)? How much faster can we get than existing methods? Can we
analyze datasets which are currently impossible to analyze (due to size),
e.g. Human Cell Atlas? As references, compare against
<a href="10.1038/s41592-018-0229-2">scVI</a>,
<a href="https://rawcdn.githack.com/aertslab/cisTopic/8d15fa2813312aa0b20c1042604079558829e947/vignettes/10X_workflow.html#building_the_models">cisTopic</a>,
<a href="https://github.com/stephenslab/fastTopics">fastTopics</a></li>
</ol>
</div>
</div>

<div id="outline-container-org2008151" class="outline-2">
<h2 id="setup"><a id="org2008151"></a>Setup</h2>
<div class="outline-text-2" id="text-setup">
<pre class="example">
Submitted batch job 83345

</pre>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> anmf
<span class="org-keyword">import</span> anndata
<span class="org-keyword">import</span> dca.api
<span class="org-keyword">import</span> numpy <span class="org-keyword">as</span> np
<span class="org-keyword">import</span> pandas <span class="org-keyword">as</span> pd
<span class="org-keyword">import</span> pickle
<span class="org-keyword">import</span> rpy2.robjects.packages
<span class="org-keyword">import</span> rpy2.robjects.pandas2ri
<span class="org-keyword">import</span> scanpy <span class="org-keyword">as</span> sc
<span class="org-keyword">import</span> scipy.io <span class="org-keyword">as</span> si
<span class="org-keyword">import</span> scipy.sparse <span class="org-keyword">as</span> ss
<span class="org-keyword">import</span> scipy.stats <span class="org-keyword">as</span> st
<span class="org-keyword">import</span> scmodes
<span class="org-keyword">import</span> sklearn.decomposition <span class="org-keyword">as</span> skd
<span class="org-keyword">import</span> time
<span class="org-keyword">import</span> time
<span class="org-keyword">import</span> torch
<span class="org-keyword">import</span> torch.utils.data <span class="org-keyword">as</span> td

<span class="org-variable-name">matrix</span> = rpy2.robjects.packages.importr(<span class="org-string">'Matrix'</span>)
<span class="org-variable-name">ft</span> = rpy2.robjects.packages.importr(<span class="org-string">'fastTopics'</span>)

rpy2.robjects.pandas2ri.activate()
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">%matplotlib inline
%config <span class="org-variable-name">InlineBackend.figure_formats</span> = <span class="org-builtin">set</span>([<span class="org-string">'retina'</span>])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">import</span> colorcet
<span class="org-keyword">import</span> matplotlib
<span class="org-keyword">import</span> matplotlib.pyplot <span class="org-keyword">as</span> plt
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'figure.facecolor'</span>] = <span class="org-string">'w'</span>
<span class="org-variable-name">plt.rcParams</span>[<span class="org-string">'font.family'</span>] = <span class="org-string">'Nimbus Sans'</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-org9e18411" class="outline-2">
<h2 id="org9e18411">Methods</h2>
<div class="outline-text-2" id="text-org9e18411">
</div>
<div id="outline-container-org82c213b" class="outline-3">
<h3 id="org82c213b">Amortized NMF</h3>
<div class="outline-text-3" id="text-org82c213b">
<p>
Amortized inference
(<a href="http://ruishu.io/2017/11/07/amortized-optimization/">Shu 2017</a>,
<a href="https://papers.nips.cc/paper/7692-amortized-inference-regularization.pdf">Shu
et al. 2018</a>) refers to a strategy to efficiently solve a large (possibly
infinite) collection of optimization problems:
</p>

<p>
\[ \theta^* = \argmin_{\theta} f(\theta, \phi), \]
</p>

<p>
where \(\phi \in \Phi\) is some context variable. Rather than solving one
problem for each \(\phi \in \Phi\), we learn a function \(h_\alpha\)
parameterized by \(\alpha\) which predicts \(\theta^*\) from \(\phi\)
</p>

<p>
\[ \alpha^* = \argmin_\alpha E_{\phi \sim \hat{p}(\phi)}[f(h_\alpha(\phi), \phi)], \]
</p>

<p>
where \(\hat{p}(\phi)\) denotes the empirical distribution of \(\phi\) in
the training data. The function \(h_\alpha\) amortizes inference over the
training data examples by coupling the optimization problems together, and
indeed amortizes inference over unseen examples also.
</p>

<p>
As a concrete example, NMF
(<a href="http://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization">Lee
and Seung 2001</a>, <a href="https://dx.doi.org/10.1155/2009/785152">Cemgil 2009</a>)
can be written
</p>

\begin{align*}
  \vl_i^* &= \argmin_{\vl_i} f(\vl_i, \vx_i, \mf)\\
  f(\vl_i, \vx_i, \mf) &\triangleq \sum_j \operatorname{Poisson}(x_{ij}; \textstyle\sum_k l_{ik} f_{jk}),
\end{align*}

<p>
where \(\vx_i\) is the context variable, and the goal is to learn
\(h_\alpha\) which maps observations \(\vx_i\) to loadings \(\vl_i\). (Here,
we are simplifying by holding \(\mf\) fixed. In this setup, we treat the
\(\vl_i\) as local latent variables, and \(\mf\) as a global latent
variable. These can be optimized in alternating phases.) The resulting
optimization problem can be solved by introducing an <i>encoder network</i>
\(h_\alpha\), which has been previously proposed
(<a href="10.1038/s41592-018-0229-2">Lopez et al. 2018</a>,
<a href="10.1038/s41467-018-07931-2">Eraslan et al. 2018</a>).
</p>

<p>
Existing methods have been introduced with the motivation that auto-encoding
networks can represent non-linear mappings into latent spaces; however, the
gain in explanatory power of such methods is unclear. Amortized inference
suggests a simpler, more compelling motivation to explore these methods:
they enable the use of stochastic optimization methods to analyze large data
sets (for example, those which do not fit in memory). However, existing
software implementations have a major limitation: they do not support sparse
matrices on the GPU, making it either impossible to analyze complete data
sets, or introducing a major bottleneck in moving minibatches to the GPU. We
implement this functionality in the Python package <code>anmf</code>.
</p>
</div>
</div>

<div id="outline-container-org59bb306" class="outline-3">
<h3 id="org59bb306">Amortized LDA</h3>
<div class="outline-text-3" id="text-org59bb306">
<p>
NMF is intimately connected to LDA via the Multinomial-Poisson transform
(<a href="http://www.jstor.org/stable/2348134">Baker 1994</a>). Briefly, if we have
an MLE for NMF and scale \(\ml\) and \(\mf\) to satisfy the constraints
\(\sum_k l_{ik} = 1\), \(\sum_k f_{jk} = 1\), we recover an MLE for the
Multinomial likelihood underlying LDA. This fact suggests an amortized
inference scheme for maximum likelihood estimation of topic models:
</p>

\begin{align*}
  x_{ij} \mid s_i, \vl_i, \mf &\sim \operatorname{Poisson}(s_i \sum_k l_{ik} f_{jk})\\
  \vl_i &= h(\vx_i)
\end{align*}

<p>
where \(h\) is a neural network with softmax output. Unlike previous
approaches for amortized inference in topic models
(<a href="https://arxiv.org/pdf/1703.01488">Srivastava et al. 2017</a>), we are not
concerned with recovering an approximate posterior over \(\mathbf{L},
   \mathbf{F}\), simplifying the problem.
</p>
</div>
</div>

<div id="outline-container-orgb998252" class="outline-3">
<h3 id="orgb998252">iPSC data</h3>
<div class="outline-text-3" id="text-orgb998252">
<p>
Sarkar et al. 2019 generated scRNA-seq data for 9,957 genes in 5,597 cells
derived from 53 donors. Read the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">keep_samples</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/quality-single-cells.txt'</span>, index_col=0, header=<span class="org-constant">None</span>)
<span class="org-variable-name">keep_genes</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/genes-pass-filter.txt'</span>, index_col=0, header=<span class="org-constant">None</span>)
<span class="org-variable-name">annotations</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-annotation.txt'</span>)
<span class="org-variable-name">annotations</span> = annotations.loc[keep_samples.values.ravel()]
<span class="org-variable-name">header</span> = <span class="org-builtin">sorted</span>(<span class="org-builtin">set</span>(annotations[<span class="org-string">'chip_id'</span>]))
<span class="org-variable-name">umi</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-counts.txt.gz'</span>, index_col=0).loc[keep_genes.values.ravel(),keep_samples.values.ravel()]
<span class="org-variable-name">gene_info</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-genes.txt.gz'</span>, index_col=0)
</pre>
</div>

<p>
Convert to sparse <code>h5ad</code>.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">del</span> annotations[<span class="org-string">"index"</span>]
<span class="org-variable-name">x</span> = anndata.AnnData(ss.csr_matrix(umi.values.T), obs=annotations, var=gene_info.loc[umi.index])
x.write(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/ipsc/ipsc.h5ad'</span>, compression=<span class="org-constant">None</span>, force_dense=<span class="org-constant">False</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgf25e3a5" class="outline-3">
<h3 id="orgf25e3a5">iPSC CM data</h3>
<div class="outline-text-3" id="text-orgf25e3a5">
<p>
<a href="https://www.nature.com/articles/s41598-020-58327-6">Selewa et al. 2019</a>
generated scRNA-seq for a time course differentiating iPSCs into
cardiomyocytes.
</p>
</div>
</div>

<div id="outline-container-org2019ba5" class="outline-3">
<h3 id="org2019ba5">10-way mixture</h3>
<div class="outline-text-3" id="text-org2019ba5">
<p>
Read the FACS sorted data sets from
<a href="https://dx.doi.org/10.1038/ncomms14049">Zheng et al 2017</a>.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">keys</span> = (
  <span class="org-string">'b_cells'</span>,
  <span class="org-string">'cd34'</span>,
  <span class="org-string">'cd4_t_helper'</span>,
  <span class="org-string">'cd56_nk'</span>,
  <span class="org-string">'cytotoxic_t'</span>,
  <span class="org-string">'memory_t'</span>,
  <span class="org-string">'naive_cytotoxic'</span>,
  <span class="org-string">'naive_t'</span>,
  <span class="org-string">'regulatory_t'</span>,
  <span class="org-string">'cd14_monocytes'</span>,
)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">data</span> = {k: scmodes.dataset.read_10x(f<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/{k}/filtered_matrices_mex/hg19/'</span>, return_adata=<span class="org-constant">True</span>, min_detect=0)
        <span class="org-keyword">for</span> k <span class="org-keyword">in</span> keys}
</pre>
</div>

<p>
Concatenate the data, then take genes with observations in at least 0.1% of
cells.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = data[keys[0]].concatenate(*[data[k] <span class="org-keyword">for</span> k <span class="org-keyword">in</span> keys[1:]], join=<span class="org-string">'inner'</span>, batch_key=<span class="org-string">'cell_type'</span>, batch_categories=keys)
sc.pp.filter_genes(x, min_cells=1)
</pre>
</div>

<p>
Report the dimensions.
</p>

<div class="org-src-container">
<pre class="src src-ipython">x.shape
</pre>
</div>

<pre class="example">
(94655, 21952)

</pre>

<p>
Write out the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x.obs</span> = x.obs.rename({0: <span class="org-string">'barcode'</span>}, axis=1)
<span class="org-variable-name">x.var</span> = x.var.rename({0: <span class="org-string">'ensg'</span>, 1: <span class="org-string">'name'</span>}, axis=1)
x.write(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way.h5ad'</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-org6f10d4c" class="outline-3">
<h3 id="org6f10d4c">Census of Immune Cells</h3>
<div class="outline-text-3" id="text-org6f10d4c">
<p>
We previously processed the Census of Immune Cells.
</p>

<p>
Read the sparse data. (20 seconds)
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">y_csr</span> = ss.load_npz(<span class="org-string">'/scratch/midway2/aksarkar/modes/immune-cell-census.npz'</span>)
</pre>
</div>

<p>
Read the metadata.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">genes</span> = pd.read_csv(<span class="org-string">'/scratch/midway2/aksarkar/modes/immune-cell-census-genes.txt.gz'</span>, sep=<span class="org-string">'\t'</span>, index_col=0)
<span class="org-variable-name">donor</span> = pd.Categorical(pd.read_csv(<span class="org-string">'/scratch/midway2/aksarkar/modes/immune-cell-census-samples.txt.gz'</span>, sep=<span class="org-string">'\t'</span>, index_col=0)[<span class="org-string">'0'</span>])
</pre>
</div>
</div>
</div>

<div id="outline-container-orga01414f" class="outline-3">
<h3 id="orga01414f">Mouse Organogenesis Cell Atlas</h3>
<div class="outline-text-3" id="text-orga01414f">
<p>
<a href="https://www.nature.com/articles/s41586-019-0969-x">Cao et al. 2019</a>
generated an atlas of 2M mouse cells, analyzed by
<a href="https://www.biorxiv.org/content/10.1101/737601v1.full.pdf">Svensson and
Pacther 2019</a>. Download the data.
</p>

<div class="org-src-container">
<pre class="src src-sh">sbatch --partition=build
<span class="org-comment-delimiter">#</span><span class="org-comment">!/bin/bash</span>
<span class="org-builtin">set</span> -e
<span class="org-variable-name">CURL</span>=<span class="org-string">"curl -sfOL"</span>
$<span class="org-variable-name">CURL</span> <span class="org-string">"https://shendure-web.gs.washington.edu/content/members/cao1025/public/mouse_embryo_atlas/gene_count.txt"</span>
$<span class="org-variable-name">CURL</span> <span class="org-string">"https://shendure-web.gs.washington.edu/content/members/cao1025/public/mouse_embryo_atlas/gene_annotate.csv"</span>
$<span class="org-variable-name">CURL</span> <span class="org-string">"https://shendure-web.gs.washington.edu/content/members/cao1025/public/mouse_embryo_atlas/cell_annotate.csv"</span>
</pre>
</div>

<pre class="example">
Submitted batch job 66386315

</pre>

<p>
Read the data. (31 mins)
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = si.mmread(<span class="org-string">'/scratch/midway2/aksarkar/ideas/gene_count.txt'</span>)
</pre>
</div>

<p>
The current implementation converting COO to CSR is
<a href="https://github.com/scipy/scipy/issues/9819">broken</a>. One possible
explanation is that the implementation of coalescing COO entries is the
culprit, which isn&rsquo;t needed for this data (there should be no duplicate
row/column entries).
</p>

<p>
Figure out whether the COO data is row-major or column-major.
</p>

<div class="org-src-container">
<pre class="src src-ipython">(x.row[:5], x.col[:5])
</pre>
</div>

<pre class="example">
(array([ 57,  94, 141, 161, 279], dtype=int32),
array([0, 0, 0, 0, 0], dtype=int32))
</pre>

<p>
Columns are samples, which means we can compress the indices and transpose in
one shot.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">indices</span> = x.row
<span class="org-variable-name">indptr</span> = np.hstack((0, 1 + np.where(np.diff(x.col))[0], x.nnz))
</pre>
</div>

<p>
Make sure the compression was correct.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">for</span> j <span class="org-keyword">in</span> <span class="org-builtin">range</span>(10):
  <span class="org-keyword">assert</span> (x.data[x.col == j] == x.data[indptr[j]:indptr[j+1]]).<span class="org-builtin">all</span>()
</pre>
</div>

<p>
We could actually get away with using <code>np.int16</code>, but we need <code>torch.int32</code>
on the GPU.
</p>

<div class="org-src-container">
<pre class="src src-ipython">x.data.<span class="org-builtin">max</span>()
</pre>
</div>

<pre class="example">
1554

</pre>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">y</span> = ss.csr_matrix((x.data.astype(np.int32), indices, indptr), shape=<span class="org-builtin">tuple</span>(<span class="org-builtin">reversed</span>(x.shape)))
</pre>
</div>

<p>
Report the dimensions of the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython">y.shape
</pre>
</div>

<pre class="example">
(2058652, 26183)

</pre>

<p>
Write out the sparse data as <code>npz</code>. (10 minutes)
</p>

<div class="org-src-container">
<pre class="src src-ipython">ss.save_npz(<span class="org-string">'/scratch/midway2/aksarkar/ideas/moca.npz'</span>, y)
</pre>
</div>

<p>
Get its size on disk.
</p>

<div class="org-src-container">
<pre class="src src-sh">ls -lh /scratch/midway2/aksarkar/ideas/moca.npz
</pre>
</div>

<pre class="example">
-rw-rw-r-- 1 aksarkar aksarkar 2.5G Mar 15 21:20 /scratch/midway2/aksarkar/ideas/moca.npz

</pre>

<p>
Read the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = ss.load_npz(<span class="org-string">'/scratch/midway2/aksarkar/ideas/moca.npz'</span>)
<span class="org-variable-name">obs</span> = pd.read_csv(<span class="org-string">'/scratch/midway2/aksarkar/ideas/cell_annotate.csv'</span>)
<span class="org-variable-name">var</span> = pd.read_csv(<span class="org-string">'/scratch/midway2/aksarkar/ideas/gene_annotate.csv'</span>)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org1f866f5" class="outline-2">
<h2 id="org1f866f5">Results</h2>
<div class="outline-text-2" id="text-org1f866f5">
</div>
<div id="outline-container-org0f4b4a8" class="outline-3">
<h3 id="org0f4b4a8">Simulation</h3>
<div class="outline-text-3" id="text-org0f4b4a8">
<p>
Simulate a simple example.
</p>

<div class="org-src-container">
<pre class="src src-ipython">np.random.seed(0)
<span class="org-variable-name">n</span> = 512
<span class="org-variable-name">p</span> = 1000
<span class="org-variable-name">k</span> = 4
<span class="org-variable-name">l</span> = np.random.lognormal(sigma=0.5, size=(n, k))
<span class="org-variable-name">f</span> = np.random.lognormal(sigma=0.5, size=(p, k))
<span class="org-variable-name">x</span> = np.random.poisson(l @ f.T)
<span class="org-variable-name">s</span> = x.<span class="org-builtin">sum</span>(axis=1)
</pre>
</div>

<p>
Fit NMF via EM. Report the time elapsed (minutes).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">start</span> = time.time()
<span class="org-variable-name">lhat0</span>, <span class="org-variable-name">fhat0</span>, <span class="org-variable-name">loss0</span> = scmodes.lra.nmf(x, rank=k, tol=1e-4, max_iters=50000, verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">elapsed</span> = time.time() - start
elapsed / 60
</pre>
</div>

<pre class="example">
5.910964751243592

</pre>

<p>
Save the fit.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">with</span> <span class="org-builtin">open</span>(<span class="org-string">'/scratch/midway2/aksarkar/ideas/anmf-sim.pkl'</span>, <span class="org-string">'wb'</span>) <span class="org-keyword">as</span> _f:
  pickle.dump((lhat0, fhat0, loss0), _f)
</pre>
</div>

<p>
Read the fit.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">with</span> <span class="org-builtin">open</span>(<span class="org-string">'/scratch/midway2/aksarkar/ideas/anmf-sim.pkl'</span>, <span class="org-string">'rb'</span>) <span class="org-keyword">as</span> _f:
  <span class="org-variable-name">lhat0</span>, <span class="org-variable-name">fhat0</span>, <span class="org-variable-name">loss0</span> = pickle.load(_f)
</pre>
</div>

<p>
Peter Carbonetto previously derived the KKT conditions for the NMF
objective. Report the maximum absolute KKT residual.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-comment-delimiter"># </span><span class="org-comment">Important: our NMF implementation does not remove the size factor</span>
<span class="org-variable-name">A</span> = x / (lhat0 @ fhat0.T)
<span class="org-variable-name">l_resid</span> = <span class="org-builtin">abs</span>(fhat0 * ((1 - A).T @ lhat0)).<span class="org-builtin">max</span>()
<span class="org-variable-name">f_resid</span> = <span class="org-builtin">abs</span>(lhat0 * ((1 - A) @ fhat0)).<span class="org-builtin">max</span>()
l_resid, f_resid
</pre>
</div>

<pre class="example">
(0.026842650024651946, 0.021118226075496564)

</pre>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">r</span> = np.corrcoef(f.T, fhat0.T)[:k,k:]
<span class="org-variable-name">order</span> = np.argmax(r, axis=1)
plt.clf()
plt.gcf().set_size_inches(3, 3)
plt.imshow(r[:,order], cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>], vmin=-1, vmax=1)
plt.xticks(np.arange(k))
plt.yticks(np.arange(k))
plt.xlabel(<span class="org-string">'True factor'</span>)
plt.ylabel(<span class="org-string">'Estimated factor'</span>)
plt.title(<span class="org-string">'EM'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/sim-em-fhat.png" alt="sim-em-fhat.png">
</p>
</div>

<p>
Fit ANMF. Report the time elapsed (seconds).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-keyword">assert</span> torch.cuda.is_available()
<span class="org-variable-name">xt</span> = torch.tensor(x, dtype=torch.<span class="org-builtin">float</span>).cuda()
<span class="org-variable-name">dense_data</span> = td.TensorDataset(xt, torch.tensor(s, dtype=torch.<span class="org-builtin">float</span>).cuda())
<span class="org-variable-name">data</span> = td.DataLoader(dense_data, batch_size=64, shuffle=<span class="org-constant">False</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">start</span> = time.time()
<span class="org-variable-name">fit</span> = (anmf.modules.ANMF(input_dim=x.shape[1], latent_dim=k)
       .fit(data, max_epochs=1000, trace=<span class="org-constant">True</span>, lr=1e-3))
<span class="org-variable-name">elapsed</span> = time.time() - start
elapsed
</pre>
</div>

<pre class="example">
36.379069805145264

</pre>

<p>
Plot the optimization trace.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(4, 2)
plt.plot(np.log(np.array(fit.trace).ravel()), lw=1, c=<span class="org-string">'k'</span>)
plt.xticks(np.arange(0, 8800, 800), np.arange(0, 1100, 100))
plt.xlabel(<span class="org-string">'Epoch'</span>)
plt.ylabel(<span class="org-string">'Neg log likelihood'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/sim-trace.png" alt="sim-trace.png">
</p>
</div>

<p>
Recover the loadings and factors. Convert the factors to topics and
correlate them to each other.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">d</span> = f / f.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">t</span> = l * f.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">t</span> /= t.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)

<span class="org-variable-name">lhat</span> = fit.loadings(xt)
<span class="org-variable-name">fhat</span> = fit.factors()
<span class="org-variable-name">dhat</span> = (fhat / fhat.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)).T
<span class="org-variable-name">that</span> = lhat * fhat.<span class="org-builtin">sum</span>(axis=1)
<span class="org-variable-name">that</span> /= that.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">r</span> = np.corrcoef(d.T, dhat.T)[:k,k:]
<span class="org-variable-name">order</span> = np.argmax(r, axis=1)
plt.clf()
plt.gcf().set_size_inches(3, 3)
plt.imshow(r[order], cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>], vmin=-1, vmax=1)
plt.xticks(np.arange(k))
plt.yticks(np.arange(k))
plt.xlabel(<span class="org-string">'True factor'</span>)
plt.ylabel(<span class="org-string">'Estimated factor'</span>)
plt.title(<span class="org-string">'ANMF'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/sim-topics.png" alt="sim-topics.png">
</p>
</div>

<p>
Report the maximum absolute KKT residual.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">A</span> = x / (s.reshape(-1, 1) * lhat.dot(fhat))
<span class="org-variable-name">l_resid</span> = <span class="org-builtin">abs</span>(fhat.T * ((1 - A).T @ lhat)).<span class="org-builtin">max</span>()
<span class="org-variable-name">f_resid</span> = <span class="org-builtin">abs</span>(lhat * ((1 - A) @ fhat.T)).<span class="org-builtin">max</span>()
l_resid, f_resid
</pre>
</div>

<pre class="example">
(0.004942970805698425, 0.0033979455942014613)

</pre>

<p>
Fit DCA optimizing Poisson loss.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">y</span> = anndata.AnnData(x)
<span class="org-comment-delimiter"># </span><span class="org-comment">This replaces the counts with fitted lambda</span>
dca.api.dca(y, mode=<span class="org-string">'denoise'</span>, ae_type=<span class="org-string">'poisson'</span>, verbose=<span class="org-constant">True</span>)
</pre>
</div>

<p>
Report the loss achieved by each algorithm.
</p>

<div class="org-src-container">
<pre class="src src-ipython">pd.Series({
  <span class="org-string">'oracle'</span>: -st.poisson(mu=l @ f.T).logpmf(x).mean(),
  <span class="org-string">'em'</span>: loss0 / np.prod(x.shape),
  <span class="org-string">'dca'</span>: -st.poisson(mu=y.X).logpmf(x).mean(),
  <span class="org-string">'anmf'</span>: -st.poisson(mu=s.reshape(-1, 1) * lhat @ fhat).logpmf(x).mean(),
})
</pre>
</div>

<pre class="example">
oracle    2.165755
em        2.159763
dca       2.106039
anmf      2.189601
dtype: float64
</pre>

<p>
Compare fitted values against each other.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 3, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(6, 2.5)

<span class="org-variable-name">anmf_lam</span> = np.sqrt(s.reshape(-1, 1) * lhat @ fhat)
ax[0].scatter(np.sqrt(l @ f.T).ravel(), anmf_lam.ravel(), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[0].set_xlabel(<span class="org-string">'Oracle sqrt val'</span>)
ax[0].set_ylabel(<span class="org-string">'ANMF sqrt fitted val'</span>)

ax[1].scatter(np.sqrt(lhat0 @ fhat0.T).ravel(), anmf_lam.ravel(), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[1].set_xlabel(<span class="org-string">'EM sqrt fitted val'</span>)

ax[2].scatter(np.sqrt(y.X).ravel(), anmf_lam.ravel(), s=1, c=<span class="org-string">'k'</span>, alpha=0.1)
ax[2].set_xlabel(<span class="org-string">'DCA sqrt fitted val'</span>)

<span class="org-variable-name">lim</span> = [0, 8]
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_xlim(lim)
  a.set_xticks(np.arange(0, 10, 2))
  a.set_ylim(lim)
  a.set_yticks(np.arange(0, 10, 2))

fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/sim-fit.png" alt="sim-fit.png">
</p>
</div>

<p>
The log likelihood achieved by ANMF is lower than the oracle. Initialize the
factors from the ground truth, and see whether ANMF recovers the loadings.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">data</span> = td.DataLoader(dense_data, batch_size=64, shuffle=<span class="org-constant">False</span>)
<span class="org-variable-name">start</span> = time.time()
<span class="org-variable-name">fit</span> = anmf.modules.ANMF(input_dim=x.shape[1], latent_dim=k)
<span class="org-comment-delimiter"># </span><span class="org-comment">y = ln(1 + exp(x))</span>
<span class="org-comment-delimiter"># </span><span class="org-comment">ln(exp(y) - 1) = x</span>
<span class="org-variable-name">fit.decoder._f.data</span> = torch.tensor(np.log(np.exp(f.T) - 1), dtype=torch.<span class="org-builtin">float</span>)
fit.fit(data, max_epochs=1000, trace=<span class="org-constant">True</span>, lr=1e-3)
<span class="org-variable-name">elapsed</span> = time.time() - start
elapsed
</pre>
</div>

<pre class="example">
25.099331617355347

</pre>

<p>
Compare the fitted log likelihood to the oracle log likelihood.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">lhat</span> = fit.loadings(xt)
<span class="org-variable-name">fhat</span> = fit.factors()
pd.Series({
  <span class="org-string">'oracle'</span>: -st.poisson(mu=l @ f.T).logpmf(x).mean(),
  <span class="org-string">'anmf'</span>: -st.poisson(mu=s.reshape(-1, 1) * lhat @ fhat).logpmf(x).mean(),
})
</pre>
</div>

<pre class="example">
oracle    2.165755
anmf      2.161778
dtype: float64
</pre>

<p>
Plot the optimization trace.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(6, 2)
plt.plot(np.log(np.array(fit.trace).ravel()), lw=1, c=<span class="org-string">'k'</span>)
plt.xticks(np.arange(0, 8800, 800), np.arange(0, 1100, 100))
plt.xlabel(<span class="org-string">'Epoch'</span>)
plt.ylabel(<span class="org-string">'Neg log likelihood'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/anmf-oracle-init-trace.png" alt="anmf-oracle-init-trace.png">
</p>
</div>

<p>
Plot the estimated loadings against the true loadings.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">d</span> = f / f.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">t</span> = l * f.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">t</span> /= t.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)

<span class="org-variable-name">lhat</span> = fit.loadings(xt)
<span class="org-variable-name">fhat</span> = fit.factors()
<span class="org-variable-name">dhat</span> = (fhat / fhat.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)).T
<span class="org-variable-name">that</span> = lhat * fhat.<span class="org-builtin">sum</span>(axis=1)
<span class="org-variable-name">that</span> /= that.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(1, 4, sharex=<span class="org-constant">True</span>, sharey=<span class="org-constant">True</span>)
fig.set_size_inches(8, 2.5)
<span class="org-variable-name">lim</span> = [0, .15]
<span class="org-keyword">for</span> i, a <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(ax.ravel()):
  a.scatter(np.sqrt(d[:,i]), np.sqrt(dhat[:,i]), s=1, c=<span class="org-string">'k'</span>)
  a.plot(lim, lim, lw=1, ls=<span class="org-string">':'</span>, c=<span class="org-string">'r'</span>)
  a.set_title(f<span class="org-string">'Topic {i}'</span>)
  a.set_xlim(lim)
  a.set_ylim(lim)
<span class="org-keyword">for</span> a <span class="org-keyword">in</span> ax:
  a.set_xlabel(<span class="org-string">'Sqrt true weight'</span>)
ax[0].set_ylabel(<span class="org-string">'Sqrt est weight'</span>)
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/sim-lhat.png" alt="sim-lhat.png">
</p>
</div>

<p>
Report the maximum absolute KKT residual.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">A</span> = x / (s.reshape(-1, 1) * lhat.dot(fhat))
<span class="org-variable-name">l_resid</span> = <span class="org-builtin">abs</span>(fhat.T * ((1 - A).T @ lhat)).<span class="org-builtin">max</span>()
<span class="org-variable-name">f_resid</span> = <span class="org-builtin">abs</span>(lhat * ((1 - A) @ fhat.T)).<span class="org-builtin">max</span>()
l_resid, f_resid
</pre>
</div>

<pre class="example">
(0.006189874562055951, 0.014342307636255675)

</pre>
</div>
</div>

<div id="outline-container-org016b06e" class="outline-3">
<h3 id="org016b06e">ANMF on iPSC data</h3>
<div class="outline-text-3" id="text-org016b06e">
<p>
Read the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = anndata.read_h5ad(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/ipsc/ipsc.h5ad'</span>)
<span class="org-variable-name">s</span> = x.X.<span class="org-builtin">sum</span>(axis=1)
</pre>
</div>

<p>
Get the donor metadata.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">keep_samples</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/quality-single-cells.txt'</span>, index_col=0, header=<span class="org-constant">None</span>)
<span class="org-variable-name">annotations</span> = pd.read_table(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-qtl/data/scqtl-annotation.txt'</span>)
<span class="org-variable-name">annotations</span> = annotations.loc[keep_samples.values.ravel()]
<span class="org-variable-name">onehot</span> = pd.get_dummies(annotations[<span class="org-string">'chip_id'</span>])
</pre>
</div>

<p>
Fit NMF via extrapolated <code>scd</code>.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">temp</span> = x.X.tocoo()
<span class="org-variable-name">y</span> = matrix.sparseMatrix(i=pd.Series(temp.row + 1), j=pd.Series(temp.col + 1), x=pd.Series(temp.data), dims=pd.Series(temp.shape))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">start</span> = time.time()
<span class="org-variable-name">fit</span> = ft.fit_poisson_nmf(y, k=54, numiter=20, method=<span class="org-string">'scd'</span>, control=rpy2.robjects.ListVector({<span class="org-string">'extrapolate'</span>: <span class="org-constant">True</span>}), verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">elapsed</span> = time.time() - start
</pre>
</div>

<p>
Report the time elapsed.
</p>

<div class="org-src-container">
<pre class="src src-ipython">elapsed / 3600, fit[-1][<span class="org-string">'timing'</span>].values.<span class="org-builtin">sum</span>() / 3600
</pre>
</div>

<pre class="example">
(0.696154232290056, 0.602129444444445)

</pre>

<p>
Write out the fit.
</p>

<div class="org-src-container">
<pre class="src src-ipython">rpy2.robjects.r[<span class="org-string">'saveRDS'</span>](fit, <span class="org-string">'/scratch/midway2/aksarkar/singlecell/ipsc-nmf-scd.Rds'</span>)
</pre>
</div>

<pre class="example">
&lt;rpy2.rinterface.NULLType object at 0x7f8bf0af4780&gt; [RTYPES.NILSXP]

</pre>

<p>
Plot the objective function over time.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(4, 2)
plt.plot(-fit[-1][<span class="org-string">'loglik'</span>].values.astype(<span class="org-builtin">float</span>), lw=1, c=<span class="org-string">'k'</span>)
plt.xticks(np.arange(0, 20, 4))
plt.xlabel(<span class="org-string">'Epoch'</span>)
plt.ylabel(<span class="org-string">'Neg log lik'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/ipsc-scd.png" alt="ipsc-scd.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">lhat</span> = fit.rx2(<span class="org-string">'L'</span>)
<span class="org-variable-name">fhat</span> = fit.rx2(<span class="org-string">'F'</span>)
<span class="org-variable-name">s</span> = fhat.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">lhat</span> *= s
<span class="org-variable-name">fhat</span> /= s
<span class="org-variable-name">lhat</span> /= lhat.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.imshow(np.corrcoef(lhat.T, onehot.T)[:54,54:], cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>], vmin=-1, vmax=1)
<span class="org-variable-name">cb</span> = plt.colorbar()
cb.set_label(<span class="org-string">'Pearson corr'</span>)
plt.xlabel(<span class="org-string">'Donor'</span>)
plt.ylabel(<span class="org-string">'Factor'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/ipsc-scd-lhat.png" alt="ipsc-scd-lhat.png">
</p>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">sparse_data</span> = anmf.dataset.ExprDataset(x.X, s.A)
<span class="org-variable-name">data</span> = td.DataLoader(sparse_data, batch_size=64, shuffle=<span class="org-constant">False</span>, collate_fn=sparse_data.collate_fn)
</pre>
</div>

<p>
Run ANMF on the data. A priori, we might expect the data to be rank 53
(equal to the number of donor individuals). Indeed, this is the rank of the
implicit factor model we originally fit to the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">start</span> = time.time()
<span class="org-variable-name">fit</span> = (anmf.modules.ANMF(input_dim=x.shape[1], latent_dim=53)
       .fit(data, max_epochs=40, trace=<span class="org-constant">True</span>, verbose=<span class="org-constant">True</span>, lr=1e-2))
<span class="org-variable-name">elapsed</span> = time.time() - start
</pre>
</div>

<p>
Report how long the optimization took (minutes).
</p>

<div class="org-src-container">
<pre class="src src-ipython">elapsed / 60
</pre>
</div>

<pre class="example">
2.7217764496803283

</pre>

<p>
Plot the end of the optimization trace.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(4, 2)
plt.plot(np.array(fit.trace).ravel()[-100:] / (128 * x.shape[1]), lw=1, c=<span class="org-string">'k'</span>)
plt.xticks(np.arange(0, 125, 25), np.arange(-100, 25, 25))
plt.xlabel(<span class="org-string">'Minibatches before maximum'</span>)
plt.ylabel(<span class="org-string">'Neg log lik per obs'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/ipsc-trace.png" alt="ipsc-trace.png">
</p>
</div>

<p>
Save the fitted model.
</p>

<div class="org-src-container">
<pre class="src src-ipython">torch.save(fit.state_dict(), <span class="org-string">'/scratch/midway2/aksarkar/ideas/ipsc-anmf.pkl'</span>)
</pre>
</div>

<p>
Load the fitted model.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit</span> = anmf.modules.ANMF(input_dim=x.shape[1], latent_dim=53)     
fit.load_state_dict(torch.load(<span class="org-string">'/scratch/midway2/aksarkar/ideas/ipsc-anmf.pkl'</span>))
fit.cuda()
</pre>
</div>

<pre class="example">
ANMF(
(encoder): Encoder(
(net): Sequential(
(0): Linear(in_features=9957, out_features=128, bias=True)
(1): ReLU()
(2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
(3): Linear(in_features=128, out_features=53, bias=True)
(4): Softplus(beta=1, threshold=20)
)
)
(decoder): Pois()
)
</pre>

<p>
Look at the correlation between the loadings and the donor individuals.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">l</span> = np.vstack([fit.loadings(b) <span class="org-keyword">for</span> b, s <span class="org-keyword">in</span> data])
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(4, 4)
plt.imshow(r, vmin=-1, vmax=1, cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>])
plt.xlabel(<span class="org-string">'Estimated loadings'</span>)
plt.ylabel(<span class="org-string">'Donor individual'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/ipsc-loadings.png" alt="ipsc-loadings.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org5a20b29" class="outline-3">
<h3 id="org5a20b29">NMF on iPSC-CM data</h3>
<div class="outline-text-3" id="text-org5a20b29">
<p>
Read the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = anndata.read_h5ad(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/czi/drop/czi-ipsc-cm.h5ad'</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">rep1</span> = x[x.obs[<span class="org-string">'ind'</span>] == <span class="org-string">'Rep1'</span>]
sc.pp.filter_genes(rep1, min_cells=1)
<span class="org-variable-name">temp</span> = rep1.X.tocoo()
<span class="org-variable-name">y</span> = matrix.sparseMatrix(i=pd.Series(temp.row + 1), j=pd.Series(temp.col + 1), x=pd.Series(temp.data), dims=pd.Series(temp.shape))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">start</span> = time.time()
<span class="org-variable-name">fit</span> = ft.fit_poisson_nmf(y, k=50, numiter=40, method=<span class="org-string">'scd'</span>, control=rpy2.robjects.ListVector({<span class="org-string">'extrapolate'</span>: <span class="org-constant">True</span>}), verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">fit</span> = {k: v <span class="org-keyword">for</span> k, v <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(fit.names, fit)}
<span class="org-variable-name">elapsed</span> = time.time() - start
elapsed / 60
</pre>
</div>

<pre class="example">
15.252534476915995

</pre>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">l</span> = fit[<span class="org-string">'L'</span>]
<span class="org-variable-name">f</span> = fit[<span class="org-string">'F'</span>]
<span class="org-variable-name">weights</span> = l * f.<span class="org-builtin">sum</span>(axis=0)
<span class="org-variable-name">scale</span> = weights.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">weights</span> /= scale
<span class="org-variable-name">topics</span> = f / f.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">markers</span> = [
  <span class="org-comment-delimiter"># </span><span class="org-comment">iPSC</span>
  <span class="org-string">'POU5F1'</span>,  <span class="org-comment-delimiter"># </span><span class="org-comment">Oct-4</span>
  <span class="org-string">'SOX2'</span>,
  <span class="org-string">'NANOG'</span>,
  <span class="org-comment-delimiter"># </span><span class="org-comment">mesoderm formation</span>
  <span class="org-string">'T'</span>,  <span class="org-comment-delimiter"># </span><span class="org-comment">BRY/TBXT</span>
  <span class="org-string">'MIXL1'</span>,
  <span class="org-comment-delimiter"># </span><span class="org-comment">cardiogenic mesoderm</span>
  <span class="org-string">'MESP1'</span>,
  <span class="org-string">'ISL1'</span>,
  <span class="org-string">'KDR'</span>,
  <span class="org-comment-delimiter"># </span><span class="org-comment">cardiac progenitor</span>
  <span class="org-string">'NKX2-5'</span>,
  <span class="org-string">'GATA4'</span>,
  <span class="org-string">'TBX5'</span>,
  <span class="org-string">'MEF2C'</span>,
  <span class="org-string">'HAND1'</span>,
  <span class="org-string">'HAND2'</span>,
  <span class="org-comment-delimiter"># </span><span class="org-comment">cardiomyocyte</span>
  <span class="org-string">'MYL2'</span>,
  <span class="org-string">'MYL7'</span>,
  <span class="org-string">'MYH6'</span>,
  <span class="org-string">'TNNT2'</span>
  ]
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">r</span> = np.corrcoef(pd.get_dummies(rep1.obs[<span class="org-string">'day'</span>]).T, weights.T)[:4,4:]
<span class="org-variable-name">day</span> = pd.get_dummies(rep1.obs[<span class="org-string">'day'</span>]).values.T
<span class="org-variable-name">loss</span> = (day @ np.log(weights) + (1 - day) @ np.log(1 - weights)) / weights.shape[0]
<span class="org-variable-name">xorder</span> = np.argsort(np.argmax(r, axis=0))
<span class="org-variable-name">idx</span> = rep1.var[<span class="org-string">'name'</span>].isin(markers)
<span class="org-variable-name">yorder</span> = np.argsort([markers.index(k) <span class="org-keyword">for</span> k <span class="org-keyword">in</span> rep1.var.loc[idx, <span class="org-string">'name'</span>]])

plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 1, sharex=<span class="org-constant">True</span>, gridspec_kw={<span class="org-string">'height_ratios'</span>: [1, 4.5]})
fig.set_size_inches(8, 4)

<span class="org-variable-name">im</span> = ax[0].imshow(r[:,xorder], cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>], vmin=-1, vmax=1, aspect=<span class="org-string">'auto'</span>)
<span class="org-variable-name">cb</span> = fig.colorbar(im, ax=ax[0])
cb.set_label(<span class="org-string">'Correlation'</span>)
ax[0].set_yticks(np.arange(<span class="org-builtin">len</span>(rep1.obs[<span class="org-string">'day'</span>].cat.categories)))
ax[0].set_yticklabels(rep1.obs[<span class="org-string">'day'</span>].cat.categories)
ax[0].set_ylabel(<span class="org-string">'Time point'</span>)

<span class="org-variable-name">im</span> = ax[1].imshow(topics[idx][yorder][:,xorder], cmap=colorcet.cm[<span class="org-string">'fire'</span>], aspect=<span class="org-string">'auto'</span>, norm=matplotlib.colors.LogNorm())
<span class="org-variable-name">cb</span> = fig.colorbar(im, ax=ax[1])
cb.set_label(<span class="org-string">'Relative expression'</span>)
ax[1].set_xlabel(<span class="org-string">'Topic'</span>)
ax[1].set_ylabel(<span class="org-string">'Marker gene expression'</span>)
ax[1].set_yticks(np.arange(<span class="org-builtin">len</span>(markers)))
ax[1].set_yticklabels(rep1.var.loc[idx, <span class="org-string">'name'</span>][order])
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/ipsc-cm-nmf-markers.png" alt="ipsc-cm-nmf-markers.png">
</p>
</div>

<p>
Trace the expression of <i>POU5F1</i> over time.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">cm</span> = plt.get_cmap(<span class="org-string">'Dark2'</span>)
<span class="org-variable-name">days</span> = (0, 1, 3, 7)
<span class="org-variable-name">query</span> = (weights @ topics[rep1.var[<span class="org-string">'name'</span>] == <span class="org-string">'POU5F1'</span>].T).ravel()
plt.clf()
plt.gcf().set_size_inches(3, 3)
<span class="org-variable-name">grid</span> = np.linspace(0, query.<span class="org-builtin">max</span>(), 1000)
<span class="org-keyword">for</span> i, k <span class="org-keyword">in</span> <span class="org-builtin">enumerate</span>(days):
  <span class="org-variable-name">f</span> = st.gaussian_kde(query[rep1.obs[<span class="org-string">'day'</span>] == k])
  plt.plot(grid, f(grid), c=cm(i), lw=1, label=k)
plt.xlim(0, grid.<span class="org-builtin">max</span>())
plt.ylim(0, 35000)
plt.legend(frameon=<span class="org-constant">False</span>, title=<span class="org-string">'Time point'</span>)
plt.title(<span class="org-string">'POU5F1'</span>)
plt.xlabel(<span class="org-string">'Latent gene expression'</span>)
plt.ylabel(<span class="org-string">'Density'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/ipsc-cm-POU5F1.png" alt="ipsc-cm-POU5F1.png">
</p>
</div>

<p>
Repeat the analysis for replicate 2.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">rep2</span> = x[x.obs[<span class="org-string">'ind'</span>] == <span class="org-string">'Rep2'</span>]
sc.pp.filter_genes(rep2, min_cells=1)
<span class="org-variable-name">temp</span> = rep2.X.tocoo()
<span class="org-variable-name">y</span> = matrix.sparseMatrix(i=pd.Series(temp.row + 1), j=pd.Series(temp.col + 1), x=pd.Series(temp.data), dims=pd.Series(temp.shape))
<span class="org-variable-name">fit</span> = ft.fit_poisson_nmf(y, k=50, numiter=40, method=<span class="org-string">'scd'</span>, control=rpy2.robjects.ListVector({<span class="org-string">'extrapolate'</span>: <span class="org-constant">True</span>}), verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">fit</span> = {k: v <span class="org-keyword">for</span> k, v <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(fit.names, fit)}
<span class="org-variable-name">l</span> = fit[<span class="org-string">'L'</span>]
<span class="org-variable-name">f</span> = fit[<span class="org-string">'F'</span>]
<span class="org-variable-name">weights</span> = l * f.<span class="org-builtin">sum</span>(axis=0)
<span class="org-variable-name">scale</span> = weights.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">weights</span> /= scale
<span class="org-variable-name">topics</span> = f / f.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">r</span> = np.corrcoef(pd.get_dummies(rep2.obs[<span class="org-string">'day'</span>]).T, weights.T)[:5,5:]
<span class="org-variable-name">day</span> = pd.get_dummies(rep2.obs[<span class="org-string">'day'</span>]).values.T
<span class="org-variable-name">xorder</span> = np.argsort(np.argmax(r, axis=0))
<span class="org-variable-name">idx</span> = rep2.var[<span class="org-string">'name'</span>].isin(markers)
<span class="org-variable-name">yorder</span> = np.argsort([markers.index(k) <span class="org-keyword">for</span> k <span class="org-keyword">in</span> rep2.var.loc[idx, <span class="org-string">'name'</span>]])

plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(2, 1, sharex=<span class="org-constant">True</span>, gridspec_kw={<span class="org-string">'height_ratios'</span>: [1, 4.5]})
fig.set_size_inches(8, 4)

<span class="org-variable-name">im</span> = ax[0].imshow(r[:,xorder], cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>], vmin=-1, vmax=1, aspect=<span class="org-string">'auto'</span>)
<span class="org-variable-name">cb</span> = fig.colorbar(im, ax=ax[0])
cb.set_label(<span class="org-string">'Correlation'</span>)
ax[0].set_yticks(np.arange(<span class="org-builtin">len</span>(rep2.obs[<span class="org-string">'day'</span>].cat.categories)))
ax[0].set_yticklabels(rep2.obs[<span class="org-string">'day'</span>].cat.categories)
ax[0].set_ylabel(<span class="org-string">'Time point'</span>)

<span class="org-variable-name">im</span> = ax[1].imshow(topics[idx][yorder][:,xorder], cmap=colorcet.cm[<span class="org-string">'fire'</span>], aspect=<span class="org-string">'auto'</span>, norm=matplotlib.colors.LogNorm())
<span class="org-variable-name">cb</span> = fig.colorbar(im, ax=ax[1])
cb.set_label(<span class="org-string">'Relative expression'</span>)
ax[1].set_xlabel(<span class="org-string">'Topic'</span>)
ax[1].set_ylabel(<span class="org-string">'Marker gene'</span>)
ax[1].set_yticks(np.arange(<span class="org-builtin">len</span>(markers)))
ax[1].set_yticklabels(rep2.var.loc[idx, <span class="org-string">'name'</span>][order])
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/ipsc-cm-rep2-nmf-markers.png" alt="ipsc-cm-rep2-nmf-markers.png">
</p>
</div>

<p>
Try jointly analyzing everything.
</p>

<div class="org-src-container">
<pre class="src src-ipython">sc.pp.filter_genes(x, min_cells=1)
<span class="org-variable-name">temp</span> = x.X.tocoo()
<span class="org-variable-name">y</span> = matrix.sparseMatrix(i=pd.Series(temp.row + 1), j=pd.Series(temp.col + 1), x=pd.Series(temp.data), dims=pd.Series(temp.shape))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit</span> = ft.fit_poisson_nmf(y, k=11, numiter=40, method=<span class="org-string">'scd'</span>, control=rpy2.robjects.ListVector({<span class="org-string">'extrapolate'</span>: <span class="org-constant">True</span>}), verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">fit</span> = {k: v <span class="org-keyword">for</span> k, v <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(fit.names, fit)}
<span class="org-variable-name">l</span> = fit[<span class="org-string">'L'</span>]
<span class="org-variable-name">f</span> = fit[<span class="org-string">'F'</span>]
<span class="org-variable-name">weights</span> = l * f.<span class="org-builtin">sum</span>(axis=0)
<span class="org-variable-name">scale</span> = weights.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">weights</span> /= scale
<span class="org-variable-name">topics</span> = f / f.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">r0</span> = np.corrcoef(pd.get_dummies(x.obs[<span class="org-string">'day'</span>]).values.T, weights.T)[:5,5:]
<span class="org-variable-name">r1</span> = np.corrcoef(pd.get_dummies(x.obs[<span class="org-string">'ind'</span>]).values.T, weights.T)[:2,2:]
<span class="org-variable-name">xorder</span> = np.argsort(np.argmax(r0, axis=0))
<span class="org-variable-name">idx</span> = x.var[<span class="org-string">'name'</span>].isin(markers)
<span class="org-variable-name">yorder</span> = np.argsort([markers.index(k) <span class="org-keyword">for</span> k <span class="org-keyword">in</span> x.var.loc[idx, <span class="org-string">'name'</span>]])

plt.clf()
<span class="org-variable-name">fig</span>, <span class="org-variable-name">ax</span> = plt.subplots(3, 1, sharex=<span class="org-constant">True</span>, gridspec_kw={<span class="org-string">'height_ratios'</span>: [2, 5, 18]})
fig.set_size_inches(4, 6)

<span class="org-variable-name">im</span> = ax[0].imshow(r1[:,xorder], cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>], vmin=-1, vmax=1, aspect=<span class="org-string">'auto'</span>)
<span class="org-variable-name">cb</span> = fig.colorbar(im, ax=ax[0])
cb.set_label(<span class="org-string">'Correlation'</span>)
ax[0].set_ylabel(<span class="org-string">'Replicate'</span>)

<span class="org-variable-name">im</span> = ax[1].imshow(r0[:,xorder], cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>], vmin=-1, vmax=1, aspect=<span class="org-string">'auto'</span>)
<span class="org-variable-name">cb</span> = fig.colorbar(im, ax=ax[1])
cb.set_label(<span class="org-string">'Correlation'</span>)
ax[1].set_yticks(np.arange(<span class="org-builtin">len</span>(x.obs[<span class="org-string">'day'</span>].cat.categories)))
ax[1].set_yticklabels(x.obs[<span class="org-string">'day'</span>].cat.categories)
ax[1].set_ylabel(<span class="org-string">'Time point'</span>)

<span class="org-variable-name">im</span> = ax[2].imshow(topics[idx][yorder][:,xorder], cmap=colorcet.cm[<span class="org-string">'fire'</span>], aspect=<span class="org-string">'auto'</span>, norm=matplotlib.colors.LogNorm())
<span class="org-variable-name">cb</span> = fig.colorbar(im, ax=ax[2])
cb.set_label(<span class="org-string">'Relative expression'</span>)
ax[2].set_xlabel(<span class="org-string">'Topic'</span>)
ax[2].set_ylabel(<span class="org-string">'Marker gene'</span>)
ax[2].set_yticks(np.arange(<span class="org-builtin">len</span>(markers)))
ax[2].set_yticklabels(x.var.loc[idx, <span class="org-string">'name'</span>][yorder])
fig.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/ipsc-cm-joint-nmf-markers.png" alt="ipsc-cm-joint-nmf-markers.png">
</p>
</div>

<p>
Look at replicate 1, day 7.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">query</span> = x[np.logical_and(x.obs[<span class="org-string">'ind'</span>] == <span class="org-string">'Rep1'</span>, x.obs[<span class="org-string">'day'</span>] == 7)]
sc.pp.filter_genes(query, min_cells=1)
<span class="org-variable-name">temp</span> = query.X.tocoo()
<span class="org-variable-name">y</span> = matrix.sparseMatrix(i=pd.Series(temp.row + 1), j=pd.Series(temp.col + 1), x=pd.Series(temp.data), dims=pd.Series(temp.shape))
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit</span> = ft.fit_poisson_nmf(y, k=11, numiter=40, method=<span class="org-string">'scd'</span>, control=rpy2.robjects.ListVector({<span class="org-string">'extrapolate'</span>: <span class="org-constant">True</span>}), verbose=<span class="org-constant">True</span>)
<span class="org-variable-name">fit</span> = {k: v <span class="org-keyword">for</span> k, v <span class="org-keyword">in</span> <span class="org-builtin">zip</span>(fit.names, fit)}
<span class="org-variable-name">l</span> = fit[<span class="org-string">'L'</span>]
<span class="org-variable-name">f</span> = fit[<span class="org-string">'F'</span>]
<span class="org-variable-name">weights</span> = l * f.<span class="org-builtin">sum</span>(axis=0)
<span class="org-variable-name">scale</span> = weights.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
<span class="org-variable-name">weights</span> /= scale
<span class="org-variable-name">topics</span> = f / f.<span class="org-builtin">sum</span>(axis=0, keepdims=<span class="org-constant">True</span>)
</pre>
</div>
</div>
</div>

<div id="outline-container-orgca6e596" class="outline-3">
<h3 id="orgca6e596">ANMF on 68K PBMCs</h3>
<div class="outline-text-3" id="text-orgca6e596">
<p>
Read the data, restricting to genes with non-zero observations in at least 1
cell.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = scmodes.dataset.read_10x(<span class="org-string">'/project2/mstephens/aksarkar/projects/singlecell-ideas/data/10xgenomics/fresh_68k_pbmc_donor_a/filtered_matrices_mex/hg19/'</span>, min_detect=0, return_adata=<span class="org-constant">True</span>)
sc.pp.filter_genes(x, min_cells=1)
<span class="org-variable-name">s</span> = x.X.<span class="org-builtin">sum</span>(axis=1)
</pre>
</div>

<p>
Report the dimensions.
</p>

<div class="org-src-container">
<pre class="src src-ipython">x.shape
</pre>
</div>

<pre class="example">
(68579, 20387)

</pre>

<p>
Fit rank 10 ANMF.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">sparse_data</span> = anmf.dataset.ExprDataset(x.X, s.A)
<span class="org-variable-name">data</span> = td.DataLoader(sparse_data, batch_size=128, shuffle=<span class="org-constant">False</span>, collate_fn=sparse_data.collate_fn)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">start</span> = time.time()
<span class="org-variable-name">fit</span> = (anmf.modules.ANMF(input_dim=x.shape[1], latent_dim=10)
       .fit(data, max_epochs=15, trace=<span class="org-constant">True</span>, verbose=<span class="org-constant">True</span>, lr=1e-2))
<span class="org-variable-name">elapsed</span> = time.time() - start
</pre>
</div>

<p>
Report how long the optimization took (minutes).
</p>

<div class="org-src-container">
<pre class="src src-ipython">elapsed / 60
</pre>
</div>

<pre class="example">
5.1033944328626

</pre>

<p>
Plot the optimization trace, focusing on the tail.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(4, 2)
plt.plot(np.array(fit.trace).ravel()[-2000:] / (128 * x.shape[1]), lw=1, c=<span class="org-string">'k'</span>)
plt.xticks(np.arange(0, 2500, 500), np.arange(-2000, 500, 500))
plt.xlabel(<span class="org-string">'Minibatches before maximum'</span>)
plt.ylabel(<span class="org-string">'Neg log lik per obs'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/pbmc-trace.png" alt="pbmc-trace.png">
</p>
</div>
</div>
</div>

<div id="outline-container-org8fe675b" class="outline-3">
<h3 id="org8fe675b">ANMF on 10-way mixture</h3>
<div class="outline-text-3" id="text-org8fe675b">
<p>
Read the data.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">x</span> = anndata.read_h5ad(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way.h5ad'</span>)
<span class="org-variable-name">s</span> = x.X.<span class="org-builtin">sum</span>(axis=1)
</pre>
</div>

<p>
Fit ANMF. Report how long the optimization took (minutes).
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">sparse_data</span> = anmf.dataset.ExprDataset(x.X, s.A)
<span class="org-variable-name">data</span> = td.DataLoader(sparse_data, batch_size=64, shuffle=<span class="org-constant">False</span>, collate_fn=sparse_data.collate_fn)
</pre>
</div>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">start</span> = time.time()
<span class="org-variable-name">fit</span> = (anmf.modules.ANMF(input_dim=x.shape[1])
       .fit(data, max_epochs=10, trace=<span class="org-constant">True</span>, verbose=<span class="org-constant">True</span>, lr=5e-3))
<span class="org-variable-name">elapsed</span> = time.time() - start
elapsed / 60
</pre>
</div>

<pre class="example">
5.154516808191935

</pre>

<p>
Save the fitted model.
</p>

<div class="org-src-container">
<pre class="src src-ipython">torch.save(fit.state_dict(), <span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way-anmf.pkl'</span>)
</pre>
</div>

<p>
Load the fitted model.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">fit</span> = anmf.modules.ANMF(input_dim=x.shape[1])
fit.load_state_dict(torch.load(<span class="org-string">'/scratch/midway2/aksarkar/ideas/zheng-10-way-anmf.pkl'</span>))
fit.cuda()
</pre>
</div>

<p>
Plot the optimization trace, focusing on the tail.
</p>

<div class="org-src-container">
<pre class="src src-ipython">plt.clf()
plt.gcf().set_size_inches(4, 2)
plt.plot(np.array(fit.trace).ravel()[-2000:] / (128 * x.shape[1]), lw=1, c=<span class="org-string">'k'</span>)
plt.xticks(np.arange(0, 2500, 500), np.arange(-2000, 500, 500))
plt.xlabel(<span class="org-string">'Minibatches before maximum'</span>)
plt.ylabel(<span class="org-string">'Neg log lik per obs'</span>)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/zheng-10-way-trace.png" alt="zheng-10-way-trace.png">
</p>
</div>

<p>
Get the loadings/factors.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">l</span> = np.vstack([fit.loadings(b) <span class="org-keyword">for</span> b, s <span class="org-keyword">in</span> data])
<span class="org-variable-name">f</span> = fit.factors()
</pre>
</div>

<p>
Normalize into a topic model.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">w</span> = l * f.<span class="org-builtin">sum</span>(axis=1)
<span class="org-variable-name">w</span> /= w.<span class="org-builtin">sum</span>(axis=1, keepdims=<span class="org-constant">True</span>)
</pre>
</div>

<p>
Get the cell type identities.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">onehot</span> = pd.get_dummies(x.obs[<span class="org-string">'cell_type'</span>])
</pre>
</div>

<p>
Estimate the correlation between the topic weights and the cell types.
</p>

<div class="org-src-container">
<pre class="src src-ipython"><span class="org-variable-name">r</span> = np.corrcoef(w.T, onehot.T)
plt.clf()
plt.gcf().set_size_inches(4, 4)
plt.imshow(r[:10,10:], cmap=colorcet.cm[<span class="org-string">'coolwarm'</span>], vmin=-1, vmax=1)
plt.tight_layout()
</pre>
</div>


<div class="figure">
<p><img src="figure/time-course.org/zheng-10-way-loadings.png" alt="zheng-10-way-loadings.png">
</p>
</div>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Abhishek Sarkar</p>
<p class="date">Created: 2020-05-14 Thu 23:52</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
